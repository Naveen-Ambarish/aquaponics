{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "As the initial step, import the required libraries that we require to perform the tasks like preprocessing, training our model and predicting the accuracy score of our model"
      ],
      "metadata": {
        "id": "EvL3z513zri9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v4yw2_1azkR3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,precision_score,recall_score,f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the dataset to the simulation software and to view the first 5 rows of our dataset we used head function in pandas dataframe"
      ],
      "metadata": {
        "id": "v8gyXhxfo8cJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/aquaponics/IoTPond3.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "jfQykPJM0RS9",
        "outputId": "3e586fce-0099-4d78-bcca-38f4c5856c37"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                created_at  entry_id  Temperature(C)  Turbidity(NTU)  \\\n",
              "0  2021-06-19 00:00:04 CET      1941           23.75              80   \n",
              "1  2021-06-19 00:00:26 CET      1942           23.75              80   \n",
              "2  2021-06-19 00:02:03 CET      1945           23.75              80   \n",
              "3  2021-06-19 00:02:26 CET      1946           23.75              81   \n",
              "4  2021-06-19 00:03:31 CET      1948           23.75              80   \n",
              "\n",
              "   Dissolved Oxygen(g/ml)       PH  Ammonia(g/ml)  Nitrate(g/ml)  Population  \\\n",
              "0                  27.736  7.04911        5.15546            114          50   \n",
              "1                   4.195  7.09450        4.53072            114          50   \n",
              "2                  10.310  7.07635        5.21473            113          50   \n",
              "3                   1.196  7.07181        5.41747            100          50   \n",
              "4                   2.338  7.08996        5.45899            112          50   \n",
              "\n",
              "   Fish_Length(cm)  Fish_Weight(g)  \n",
              "0             6.74             3.2  \n",
              "1             6.74             3.2  \n",
              "2             6.74             3.2  \n",
              "3             6.74             3.2  \n",
              "4             6.74             3.2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32b3ecc4-f4be-4ded-8249-ed39b741dcf4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>entry_id</th>\n",
              "      <th>Temperature(C)</th>\n",
              "      <th>Turbidity(NTU)</th>\n",
              "      <th>Dissolved Oxygen(g/ml)</th>\n",
              "      <th>PH</th>\n",
              "      <th>Ammonia(g/ml)</th>\n",
              "      <th>Nitrate(g/ml)</th>\n",
              "      <th>Population</th>\n",
              "      <th>Fish_Length(cm)</th>\n",
              "      <th>Fish_Weight(g)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-19 00:00:04 CET</td>\n",
              "      <td>1941</td>\n",
              "      <td>23.75</td>\n",
              "      <td>80</td>\n",
              "      <td>27.736</td>\n",
              "      <td>7.04911</td>\n",
              "      <td>5.15546</td>\n",
              "      <td>114</td>\n",
              "      <td>50</td>\n",
              "      <td>6.74</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-19 00:00:26 CET</td>\n",
              "      <td>1942</td>\n",
              "      <td>23.75</td>\n",
              "      <td>80</td>\n",
              "      <td>4.195</td>\n",
              "      <td>7.09450</td>\n",
              "      <td>4.53072</td>\n",
              "      <td>114</td>\n",
              "      <td>50</td>\n",
              "      <td>6.74</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-19 00:02:03 CET</td>\n",
              "      <td>1945</td>\n",
              "      <td>23.75</td>\n",
              "      <td>80</td>\n",
              "      <td>10.310</td>\n",
              "      <td>7.07635</td>\n",
              "      <td>5.21473</td>\n",
              "      <td>113</td>\n",
              "      <td>50</td>\n",
              "      <td>6.74</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-19 00:02:26 CET</td>\n",
              "      <td>1946</td>\n",
              "      <td>23.75</td>\n",
              "      <td>81</td>\n",
              "      <td>1.196</td>\n",
              "      <td>7.07181</td>\n",
              "      <td>5.41747</td>\n",
              "      <td>100</td>\n",
              "      <td>50</td>\n",
              "      <td>6.74</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-19 00:03:31 CET</td>\n",
              "      <td>1948</td>\n",
              "      <td>23.75</td>\n",
              "      <td>80</td>\n",
              "      <td>2.338</td>\n",
              "      <td>7.08996</td>\n",
              "      <td>5.45899</td>\n",
              "      <td>112</td>\n",
              "      <td>50</td>\n",
              "      <td>6.74</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32b3ecc4-f4be-4ded-8249-ed39b741dcf4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32b3ecc4-f4be-4ded-8249-ed39b741dcf4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32b3ecc4-f4be-4ded-8249-ed39b741dcf4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "qqFTt_lf0ol7",
        "outputId": "6764f567-bd32-438d-ecf3-f2490e6953e2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            entry_id  Temperature(C)  Turbidity(NTU)  Dissolved Oxygen(g/ml)  \\\n",
              "count  169185.000000   169185.000000   169185.000000           169185.000000   \n",
              "mean    88079.861164       23.779466       83.384898                7.456181   \n",
              "std     48888.942496        1.549207       26.651853                6.410530   \n",
              "min      1941.000000     -127.000000        8.000000                0.008000   \n",
              "25%     45813.000000       23.375000       80.000000                5.080000   \n",
              "50%     88109.000000       23.750000       98.000000                5.080000   \n",
              "75%    130405.000000       24.125000      100.000000                8.088000   \n",
              "max    172701.000000       26.562500      100.000000               41.384000   \n",
              "\n",
              "                  PH  Ammonia(g/ml)  Nitrate(g/ml)  Population  \\\n",
              "count  169185.000000   1.690780e+05  169185.000000    169185.0   \n",
              "mean        7.184931            inf     380.670804        50.0   \n",
              "std         0.629428            NaN     255.443631         0.0   \n",
              "min        -0.531800   0.000000e+00       0.000000        50.0   \n",
              "25%         7.244310   5.759120e+00     123.000000        50.0   \n",
              "50%         7.307860   2.942574e+01     417.000000        50.0   \n",
              "75%         7.344170   1.009766e+03     585.000000        50.0   \n",
              "max        11.456930            inf    3870.000000        50.0   \n",
              "\n",
              "       Fish_Length(cm)  Fish_Weight(g)  \n",
              "count    169185.000000   169185.000000  \n",
              "mean         16.058793       44.259006  \n",
              "std           5.001695       45.519340  \n",
              "min           6.740000        3.200000  \n",
              "25%          13.320000       19.380000  \n",
              "50%          15.540000       35.830000  \n",
              "75%          18.860000       46.680000  \n",
              "max          33.000000      294.920000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e52621a6-900f-452a-a5d8-1d4649e1e8c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entry_id</th>\n",
              "      <th>Temperature(C)</th>\n",
              "      <th>Turbidity(NTU)</th>\n",
              "      <th>Dissolved Oxygen(g/ml)</th>\n",
              "      <th>PH</th>\n",
              "      <th>Ammonia(g/ml)</th>\n",
              "      <th>Nitrate(g/ml)</th>\n",
              "      <th>Population</th>\n",
              "      <th>Fish_Length(cm)</th>\n",
              "      <th>Fish_Weight(g)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>169185.000000</td>\n",
              "      <td>169185.000000</td>\n",
              "      <td>169185.000000</td>\n",
              "      <td>169185.000000</td>\n",
              "      <td>169185.000000</td>\n",
              "      <td>1.690780e+05</td>\n",
              "      <td>169185.000000</td>\n",
              "      <td>169185.0</td>\n",
              "      <td>169185.000000</td>\n",
              "      <td>169185.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>88079.861164</td>\n",
              "      <td>23.779466</td>\n",
              "      <td>83.384898</td>\n",
              "      <td>7.456181</td>\n",
              "      <td>7.184931</td>\n",
              "      <td>inf</td>\n",
              "      <td>380.670804</td>\n",
              "      <td>50.0</td>\n",
              "      <td>16.058793</td>\n",
              "      <td>44.259006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>48888.942496</td>\n",
              "      <td>1.549207</td>\n",
              "      <td>26.651853</td>\n",
              "      <td>6.410530</td>\n",
              "      <td>0.629428</td>\n",
              "      <td>NaN</td>\n",
              "      <td>255.443631</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.001695</td>\n",
              "      <td>45.519340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1941.000000</td>\n",
              "      <td>-127.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.008000</td>\n",
              "      <td>-0.531800</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.0</td>\n",
              "      <td>6.740000</td>\n",
              "      <td>3.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>45813.000000</td>\n",
              "      <td>23.375000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>5.080000</td>\n",
              "      <td>7.244310</td>\n",
              "      <td>5.759120e+00</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>50.0</td>\n",
              "      <td>13.320000</td>\n",
              "      <td>19.380000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>88109.000000</td>\n",
              "      <td>23.750000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>5.080000</td>\n",
              "      <td>7.307860</td>\n",
              "      <td>2.942574e+01</td>\n",
              "      <td>417.000000</td>\n",
              "      <td>50.0</td>\n",
              "      <td>15.540000</td>\n",
              "      <td>35.830000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>130405.000000</td>\n",
              "      <td>24.125000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>8.088000</td>\n",
              "      <td>7.344170</td>\n",
              "      <td>1.009766e+03</td>\n",
              "      <td>585.000000</td>\n",
              "      <td>50.0</td>\n",
              "      <td>18.860000</td>\n",
              "      <td>46.680000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172701.000000</td>\n",
              "      <td>26.562500</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>41.384000</td>\n",
              "      <td>11.456930</td>\n",
              "      <td>inf</td>\n",
              "      <td>3870.000000</td>\n",
              "      <td>50.0</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>294.920000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e52621a6-900f-452a-a5d8-1d4649e1e8c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e52621a6-900f-452a-a5d8-1d4649e1e8c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e52621a6-900f-452a-a5d8-1d4649e1e8c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check for the null values present in our dataset we use isnull() function\n"
      ],
      "metadata": {
        "id": "_LUw9JyE02pR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFl6gJni0rko",
        "outputId": "c707f8b0-388f-4c1c-dab2-4e50044a7a12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "created_at                  0\n",
              "entry_id                    0\n",
              "Temperature(C)              0\n",
              "Turbidity(NTU)              0\n",
              "Dissolved Oxygen(g/ml)      0\n",
              "PH                          0\n",
              "Ammonia(g/ml)             107\n",
              "Nitrate(g/ml)               0\n",
              "Population                  0\n",
              "Fish_Length(cm)             0\n",
              "Fish_Weight(g)              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Values to be filled with mean values"
      ],
      "metadata": {
        "id": "Am17y-Pg1A9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.fillna(df.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKSepSK_05sE",
        "outputId": "99e00d5e-ad3c-4189-9d33-e237d9109bb2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-6f8c6f28e805>:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  df=df.fillna(df.mean())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking if the numbers are within limits are having infinite"
      ],
      "metadata": {
        "id": "i5KnSfKP49_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isin([np.inf,-np.inf]).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXRKGPkZ49S-",
        "outputId": "c47b56a3-b09c-41d1-c5a0-ae53839706fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "created_at                   0\n",
              "entry_id                     0\n",
              "Temperature(C)               0\n",
              "Turbidity(NTU)               0\n",
              "Dissolved Oxygen(g/ml)       0\n",
              "PH                           0\n",
              "Ammonia(g/ml)             8155\n",
              "Nitrate(g/ml)                0\n",
              "Population                   0\n",
              "Fish_Length(cm)              0\n",
              "Fish_Weight(g)               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop all those values that are infinite"
      ],
      "metadata": {
        "id": "zGIEAMih5MRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df.dropna(axis=0,inplace=True)"
      ],
      "metadata": {
        "id": "G_MQFGcW3_b_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXQZQvb97dWg",
        "outputId": "95225331-657e-4ea5-9895-6ac34ac24a72"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "created_at                0\n",
              "entry_id                  0\n",
              "Temperature(C)            0\n",
              "Turbidity(NTU)            0\n",
              "Dissolved Oxygen(g/ml)    0\n",
              "PH                        0\n",
              "Ammonia(g/ml)             0\n",
              "Nitrate(g/ml)             0\n",
              "Population                0\n",
              "Fish_Length(cm)           0\n",
              "Fish_Weight(g)            0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop all the unnecessary columns from the dataset"
      ],
      "metadata": {
        "id": "sLref3_k1Gmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(columns='Population')\n",
        "df=df.drop(columns='created_at')\n",
        "df=df.drop(columns='entry_id')"
      ],
      "metadata": {
        "id": "xw9KqnbE093G"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the datatype of each columns in our dataset"
      ],
      "metadata": {
        "id": "CCFZIyxY1MSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dtiz5znu1DaY",
        "outputId": "be53810d-29ff-4c35-f1f9-b30f8de2e2f3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 161030 entries, 0 to 169184\n",
            "Data columns (total 8 columns):\n",
            " #   Column                  Non-Null Count   Dtype  \n",
            "---  ------                  --------------   -----  \n",
            " 0   Temperature(C)          161030 non-null  float64\n",
            " 1   Turbidity(NTU)          161030 non-null  int64  \n",
            " 2   Dissolved Oxygen(g/ml)  161030 non-null  float64\n",
            " 3   PH                      161030 non-null  float64\n",
            " 4   Ammonia(g/ml)           161030 non-null  float64\n",
            " 5   Nitrate(g/ml)           161030 non-null  int64  \n",
            " 6   Fish_Length(cm)         161030 non-null  float64\n",
            " 7   Fish_Weight(g)          161030 non-null  float64\n",
            "dtypes: float64(6), int64(2)\n",
            "memory usage: 11.1 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that our classifications labels fish_length and fish_weight are in float variables and we need to convert them to string."
      ],
      "metadata": {
        "id": "s4TCYvDi1QwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.astype({\"Fish_Length(cm)\":'str',\"Fish_Weight(g)\":'str'})"
      ],
      "metadata": {
        "id": "TPaDvhpK1JxS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the corelation between the input variables"
      ],
      "metadata": {
        "id": "ffXmnIHl1ZXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "rLFjasZ41TVd",
        "outputId": "176d4ea7-532e-488c-9670-b047fb03832c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Temperature(C)  Turbidity(NTU)  \\\n",
              "Temperature(C)                1.000000       -0.161165   \n",
              "Turbidity(NTU)               -0.161165        1.000000   \n",
              "Dissolved Oxygen(g/ml)        0.093820       -0.365888   \n",
              "PH                            0.025462       -0.100579   \n",
              "Ammonia(g/ml)                -0.005974        0.002571   \n",
              "Nitrate(g/ml)                -0.166683        0.543625   \n",
              "\n",
              "                        Dissolved Oxygen(g/ml)        PH  Ammonia(g/ml)  \\\n",
              "Temperature(C)                        0.093820  0.025462      -0.005974   \n",
              "Turbidity(NTU)                       -0.365888 -0.100579       0.002571   \n",
              "Dissolved Oxygen(g/ml)                1.000000  0.063381      -0.005252   \n",
              "PH                                    0.063381  1.000000       0.002970   \n",
              "Ammonia(g/ml)                        -0.005252  0.002970       1.000000   \n",
              "Nitrate(g/ml)                        -0.326113 -0.018801       0.000731   \n",
              "\n",
              "                        Nitrate(g/ml)  \n",
              "Temperature(C)              -0.166683  \n",
              "Turbidity(NTU)               0.543625  \n",
              "Dissolved Oxygen(g/ml)      -0.326113  \n",
              "PH                          -0.018801  \n",
              "Ammonia(g/ml)                0.000731  \n",
              "Nitrate(g/ml)                1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd7e746a-d6c8-497b-a6ee-b9a02f4d0bdf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temperature(C)</th>\n",
              "      <th>Turbidity(NTU)</th>\n",
              "      <th>Dissolved Oxygen(g/ml)</th>\n",
              "      <th>PH</th>\n",
              "      <th>Ammonia(g/ml)</th>\n",
              "      <th>Nitrate(g/ml)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Temperature(C)</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.161165</td>\n",
              "      <td>0.093820</td>\n",
              "      <td>0.025462</td>\n",
              "      <td>-0.005974</td>\n",
              "      <td>-0.166683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Turbidity(NTU)</th>\n",
              "      <td>-0.161165</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.365888</td>\n",
              "      <td>-0.100579</td>\n",
              "      <td>0.002571</td>\n",
              "      <td>0.543625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dissolved Oxygen(g/ml)</th>\n",
              "      <td>0.093820</td>\n",
              "      <td>-0.365888</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.063381</td>\n",
              "      <td>-0.005252</td>\n",
              "      <td>-0.326113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PH</th>\n",
              "      <td>0.025462</td>\n",
              "      <td>-0.100579</td>\n",
              "      <td>0.063381</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.002970</td>\n",
              "      <td>-0.018801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ammonia(g/ml)</th>\n",
              "      <td>-0.005974</td>\n",
              "      <td>0.002571</td>\n",
              "      <td>-0.005252</td>\n",
              "      <td>0.002970</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nitrate(g/ml)</th>\n",
              "      <td>-0.166683</td>\n",
              "      <td>0.543625</td>\n",
              "      <td>-0.326113</td>\n",
              "      <td>-0.018801</td>\n",
              "      <td>0.000731</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd7e746a-d6c8-497b-a6ee-b9a02f4d0bdf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cd7e746a-d6c8-497b-a6ee-b9a02f4d0bdf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cd7e746a-d6c8-497b-a6ee-b9a02f4d0bdf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=df.drop(columns=['Fish_Length(cm)','Fish_Weight(g)'])\n",
        "y=df.drop(columns=['Temperature(C)','Turbidity(NTU)','Dissolved Oxygen(g/ml)','PH','Ammonia(g/ml)','Nitrate(g/ml)'])\n",
        "y1=y['Fish_Length(cm)']\n",
        "y2=y['Fish_Weight(g)']"
      ],
      "metadata": {
        "id": "O-1fucYC1cd-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y1 corresponds to the model for fish length label and Y2 corresponds to the model for fish weight label. Splitting the data for training and testing\n"
      ],
      "metadata": {
        "id": "FQKu6boO1pAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,Y1_train,Y1_test=train_test_split(x,y1,test_size=0.2,random_state=0)\n",
        "X_train,X_test,Y2_train,Y2_test=train_test_split(x,y2,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "COF_9D381ev4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling of data"
      ],
      "metadata": {
        "id": "p4yvYx-7XO1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "kF_maiMyXMu_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Logistic Regression"
      ],
      "metadata": {
        "id": "hT3eQCi48ggk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=LogisticRegression(multi_class='multinomial')\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "769_S8cI1r_u",
        "outputId": "451796c8-1683-478d-9cf0-dd38b5c5266d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.25       0.00      0.00      0.00       189\n",
            "       10.64       0.29      0.95      0.44       805\n",
            "       11.03       0.21      0.05      0.08       466\n",
            "       11.42       0.50      0.35      0.41       781\n",
            "       11.81       0.13      0.29      0.18       775\n",
            "       12.24       0.54      0.88      0.67       889\n",
            "       12.42       0.59      0.40      0.47       677\n",
            "       12.78       0.00      0.00      0.00         7\n",
            "       12.96       0.00      0.00      0.00       463\n",
            "       13.14       0.44      0.76      0.55       365\n",
            "       13.32       0.00      0.00      0.00       548\n",
            "        13.5       0.21      0.39      0.27       840\n",
            "       13.68       0.00      0.00      0.00       660\n",
            "       13.86       0.27      0.01      0.01       552\n",
            "       14.04       0.10      0.01      0.02       587\n",
            "       14.22       0.22      0.05      0.09       550\n",
            "        14.4       0.25      0.01      0.02       540\n",
            "       14.58       0.00      0.00      0.00       209\n",
            "       14.77       0.27      0.20      0.23       629\n",
            "       14.88       0.20      0.38      0.26       571\n",
            "       14.99       0.00      0.00      0.00       380\n",
            "        15.1       0.00      0.00      0.00        11\n",
            "       15.21       0.00      0.00      0.00       111\n",
            "       15.32       0.50      0.01      0.01       163\n",
            "       15.43       0.00      0.00      0.00       371\n",
            "       15.54       0.52      0.03      0.06       678\n",
            "       15.65       0.15      0.41      0.22       836\n",
            "       15.76       0.06      0.00      0.01       780\n",
            "       15.87       0.26      0.46      0.33       681\n",
            "       15.98       0.33      0.01      0.01       729\n",
            "       16.09       0.01      0.01      0.01       722\n",
            "        16.2       0.18      0.00      0.01       683\n",
            "       16.25       0.38      0.42      0.40       562\n",
            "       16.54       0.00      0.00      0.00       125\n",
            "       16.83       0.04      0.00      0.00       378\n",
            "       17.12       0.58      0.06      0.11       446\n",
            "       17.41       0.04      0.01      0.02       348\n",
            "        17.7       0.16      0.06      0.09       742\n",
            "       18.28       0.00      0.00      0.00       338\n",
            "       18.57       0.00      0.00      0.00       464\n",
            "       18.86       0.00      0.00      0.00       426\n",
            "       19.15       0.12      0.89      0.21       871\n",
            "       19.44       0.20      0.31      0.24       775\n",
            "       19.73       0.22      0.93      0.36       709\n",
            "       20.02       0.00      0.00      0.00       617\n",
            "       20.31       0.24      0.01      0.02       631\n",
            "       20.74       0.00      0.00      0.00       455\n",
            "       21.17       0.00      0.00      0.00       420\n",
            "        21.6       0.00      0.00      0.00       312\n",
            "       22.03       0.00      0.00      0.00        92\n",
            "       22.89       0.00      0.00      0.00        75\n",
            "       23.32       0.00      0.00      0.00       109\n",
            "       23.75       0.00      0.00      0.00       127\n",
            "       24.18       0.00      0.00      0.00         2\n",
            "        25.9       0.00      0.00      0.00       114\n",
            "       26.33       0.00      0.00      0.00       260\n",
            "       26.42       0.00      0.00      0.00       279\n",
            "       26.51       0.55      0.57      0.56       534\n",
            "        26.6       0.00      0.00      0.00       112\n",
            "       26.69       0.00      0.00      0.00       110\n",
            "       26.87       0.00      0.00      0.00       109\n",
            "       26.96       0.00      0.00      0.00       265\n",
            "       27.05       0.00      0.00      0.00       190\n",
            "       28.88       1.00      0.19      0.32       181\n",
            "       29.21       0.63      0.99      0.77       668\n",
            "       29.54       0.00      0.00      0.00       240\n",
            "        33.0       0.00      0.00      0.00         5\n",
            "        6.74       0.21      0.26      0.23       611\n",
            "        7.17       0.22      0.34      0.27       642\n",
            "        7.52       0.36      0.47      0.41       248\n",
            "        7.91       0.00      0.00      0.00       267\n",
            "         8.3       0.40      0.59      0.47       505\n",
            "        8.69       0.00      0.00      0.00       339\n",
            "        9.08       0.00      0.00      0.00       255\n",
            "\n",
            "    accuracy                           0.24     32206\n",
            "   macro avg       0.16      0.16      0.12     32206\n",
            "weighted avg       0.20      0.24      0.17     32206\n",
            "\n",
            "The confusion matrix for Fish Length is: [[  0 111   0 ...   0   0   0]\n",
            " [  0 761  17 ...   0   0   0]\n",
            " [  0 373  24 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ... 296   0   0]\n",
            " [  0 127   8 ...  61   0   0]\n",
            " [  0  49   5 ...   0   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.52       0.50      0.35      0.41       781\n",
            "      103.27       0.00      0.00      0.00       109\n",
            "       11.13       0.13      0.29      0.18       775\n",
            "        11.7       0.54      0.88      0.67       889\n",
            "      110.98       0.00      0.00      0.00       127\n",
            "      118.69       0.00      0.00      0.00         2\n",
            "       12.98       0.59      0.40      0.47       677\n",
            "      149.53       0.00      0.00      0.00       114\n",
            "       15.54       0.00      0.00      0.00         7\n",
            "       157.3       0.00      0.00      0.00       260\n",
            "      158.15       0.00      0.00      0.00       279\n",
            "       159.0       0.55      0.57      0.56       534\n",
            "      159.85       0.00      0.00      0.00       112\n",
            "       16.82       0.00      0.00      0.00       463\n",
            "       160.7       0.00      0.00      0.00       110\n",
            "       162.4       0.00      0.00      0.00       109\n",
            "      163.25       0.00      0.00      0.00       265\n",
            "       164.1       0.00      0.00      0.00       190\n",
            "        18.1       0.44      0.76      0.55       365\n",
            "       19.38       0.00      0.00      0.00       548\n",
            "       20.66       0.21      0.39      0.27       840\n",
            "      200.52       1.00      0.19      0.32       181\n",
            "      208.35       0.63      0.99      0.77       668\n",
            "       21.94       0.00      0.00      0.00       660\n",
            "      216.18       0.00      0.00      0.00       240\n",
            "       23.22       0.27      0.01      0.01       552\n",
            "        24.5       0.10      0.01      0.02       587\n",
            "       25.78       0.22      0.05      0.09       550\n",
            "       27.06       0.25      0.01      0.02       540\n",
            "       28.34       0.00      0.00      0.00       209\n",
            "        29.6       0.27      0.20      0.23       629\n",
            "      294.92       0.00      0.00      0.00         5\n",
            "         3.2       0.21      0.26      0.23       611\n",
            "        3.81       0.22      0.34      0.27       642\n",
            "       30.49       0.20      0.38      0.26       571\n",
            "       31.38       0.00      0.00      0.00       380\n",
            "       32.27       0.00      0.00      0.00        11\n",
            "       33.16       0.00      0.00      0.00       111\n",
            "       34.05       0.50      0.01      0.01       163\n",
            "       34.94       0.00      0.00      0.00       371\n",
            "       35.83       0.52      0.03      0.06       678\n",
            "       36.72       0.15      0.41      0.22       836\n",
            "       37.61       0.06      0.00      0.01       780\n",
            "        38.5       0.26      0.46      0.33       681\n",
            "       39.39       0.33      0.01      0.01       729\n",
            "        4.42       0.36      0.47      0.41       248\n",
            "       40.28       0.01      0.01      0.01       722\n",
            "       41.11       0.18      0.00      0.01       683\n",
            "        42.0       0.38      0.42      0.40       562\n",
            "       42.52       0.00      0.00      0.00       125\n",
            "       43.04       0.04      0.00      0.00       378\n",
            "       43.56       0.58      0.06      0.11       446\n",
            "       44.08       0.04      0.01      0.02       348\n",
            "        44.6       0.16      0.06      0.09       742\n",
            "       45.64       0.00      0.00      0.00       338\n",
            "       46.16       0.00      0.00      0.00       464\n",
            "       46.68       0.00      0.00      0.00       426\n",
            "        47.2       0.12      0.89      0.21       871\n",
            "       47.72       0.20      0.31      0.24       775\n",
            "       48.24       0.22      0.93      0.36       709\n",
            "       48.76       0.00      0.00      0.00       617\n",
            "        49.3       0.24      0.01      0.02       631\n",
            "        5.03       0.00      0.00      0.00       267\n",
            "        5.64       0.40      0.59      0.47       505\n",
            "       57.01       0.00      0.00      0.00       455\n",
            "        6.25       0.00      0.00      0.00       339\n",
            "        6.86       0.00      0.00      0.00       255\n",
            "       64.72       0.00      0.00      0.00       420\n",
            "       72.43       0.00      0.00      0.00       312\n",
            "        8.69       0.00      0.00      0.00       189\n",
            "       80.14       0.00      0.00      0.00        92\n",
            "         9.3       0.29      0.95      0.44       805\n",
            "        9.91       0.21      0.05      0.08       466\n",
            "       95.56       0.00      0.00      0.00        75\n",
            "\n",
            "    accuracy                           0.24     32206\n",
            "   macro avg       0.16      0.16      0.12     32206\n",
            "weighted avg       0.20      0.24      0.17     32206\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[273   0 121 ... 305  12   0]\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [128   0 226 ...  30   2   0]\n",
            " ...\n",
            " [  1   0  21 ... 761  17   0]\n",
            " [  0   0  54 ... 373  24   0]\n",
            " [  0   0   0 ...   0   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Decision Tree Classifier"
      ],
      "metadata": {
        "id": "tovQ7RHN82tC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=DecisionTreeClassifier()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8aDXOlK8q-W",
        "outputId": "57958954-2c0f-4cd1-c8a7-c13e89c37880"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.25       0.67      0.57      0.62       189\n",
            "       10.64       0.77      0.73      0.75       805\n",
            "       11.03       0.63      0.65      0.64       466\n",
            "       11.42       0.76      0.78      0.77       781\n",
            "       11.81       0.97      0.97      0.97       775\n",
            "       12.24       0.97      0.97      0.97       889\n",
            "       12.42       0.97      0.98      0.98       677\n",
            "       12.78       0.00      0.00      0.00         7\n",
            "       12.96       0.69      0.70      0.69       463\n",
            "       13.14       0.84      0.85      0.84       365\n",
            "       13.32       0.64      0.61      0.62       548\n",
            "        13.5       0.75      0.76      0.75       840\n",
            "       13.68       0.57      0.54      0.55       660\n",
            "       13.86       0.57      0.60      0.58       552\n",
            "       14.04       0.76      0.76      0.76       587\n",
            "       14.22       0.64      0.65      0.64       550\n",
            "        14.4       0.60      0.56      0.58       540\n",
            "       14.58       0.90      0.93      0.91       209\n",
            "       14.77       0.79      0.80      0.80       629\n",
            "       14.88       0.60      0.62      0.61       571\n",
            "       14.99       0.64      0.67      0.66       380\n",
            "        15.1       0.90      0.82      0.86        11\n",
            "       15.21       0.98      0.99      0.99       111\n",
            "       15.32       0.95      0.94      0.95       163\n",
            "       15.43       0.96      0.96      0.96       371\n",
            "       15.54       0.97      0.97      0.97       678\n",
            "       15.65       0.95      0.96      0.96       836\n",
            "       15.76       0.89      0.88      0.89       780\n",
            "       15.87       0.94      0.94      0.94       681\n",
            "       15.98       0.86      0.86      0.86       729\n",
            "       16.09       0.80      0.83      0.81       722\n",
            "        16.2       0.76      0.78      0.77       683\n",
            "       16.25       0.80      0.78      0.79       562\n",
            "       16.54       0.77      0.68      0.72       125\n",
            "       16.83       0.87      0.83      0.85       378\n",
            "       17.12       0.94      0.91      0.93       446\n",
            "       17.41       0.92      0.91      0.92       348\n",
            "        17.7       0.80      0.77      0.78       742\n",
            "       18.28       0.71      0.75      0.73       338\n",
            "       18.57       0.77      0.75      0.76       464\n",
            "       18.86       0.58      0.61      0.59       426\n",
            "       19.15       0.88      0.87      0.87       871\n",
            "       19.44       0.91      0.92      0.92       775\n",
            "       19.73       0.94      0.92      0.93       709\n",
            "       20.02       0.78      0.77      0.77       617\n",
            "       20.31       0.71      0.75      0.73       631\n",
            "       20.74       0.67      0.59      0.63       455\n",
            "       21.17       0.63      0.67      0.65       420\n",
            "        21.6       0.77      0.78      0.77       312\n",
            "       22.03       0.53      0.43      0.48        92\n",
            "       22.89       0.38      0.36      0.37        75\n",
            "       23.32       0.60      0.54      0.57       109\n",
            "       23.75       0.57      0.63      0.60       127\n",
            "       24.18       0.29      1.00      0.44         2\n",
            "        25.9       0.78      0.88      0.82       114\n",
            "       26.33       0.54      0.55      0.55       260\n",
            "       26.42       0.51      0.52      0.51       279\n",
            "       26.51       0.91      0.91      0.91       534\n",
            "        26.6       0.74      0.88      0.80       112\n",
            "       26.69       0.82      0.75      0.79       110\n",
            "       26.87       0.64      0.52      0.58       109\n",
            "       26.96       0.88      0.85      0.86       265\n",
            "       27.05       0.64      0.67      0.65       190\n",
            "       28.88       0.90      0.94      0.92       181\n",
            "       29.21       0.95      0.94      0.95       668\n",
            "       29.54       0.93      0.92      0.92       240\n",
            "        33.0       1.00      1.00      1.00         5\n",
            "        6.74       0.97      0.97      0.97       611\n",
            "        7.17       0.96      0.97      0.97       642\n",
            "        7.52       0.94      0.92      0.93       248\n",
            "        7.91       0.93      0.98      0.96       267\n",
            "         8.3       0.95      0.94      0.94       505\n",
            "        8.69       0.72      0.69      0.71       339\n",
            "        9.08       0.80      0.84      0.82       255\n",
            "\n",
            "    accuracy                           0.81     32206\n",
            "   macro avg       0.77      0.78      0.77     32206\n",
            "weighted avg       0.81      0.81      0.81     32206\n",
            "\n",
            "The confusion matrix for Fish Length is: [[108  17  13 ...   0   8   3]\n",
            " [ 20 590  98 ...   0  11  19]\n",
            " [  5  97 304 ...   0  12   2]\n",
            " ...\n",
            " [  0   0   0 ... 474   5   0]\n",
            " [  6  12  22 ...  10 234   3]\n",
            " [  2  11   4 ...   0   4 214]]\n",
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.52       0.75      0.79      0.77       781\n",
            "      103.27       0.61      0.52      0.56       109\n",
            "       11.13       0.97      0.97      0.97       775\n",
            "        11.7       0.97      0.97      0.97       889\n",
            "      110.98       0.58      0.64      0.61       127\n",
            "      118.69       0.17      0.50      0.25         2\n",
            "       12.98       0.98      0.98      0.98       677\n",
            "      149.53       0.78      0.88      0.82       114\n",
            "       15.54       0.00      0.00      0.00         7\n",
            "       157.3       0.53      0.59      0.56       260\n",
            "      158.15       0.49      0.53      0.51       279\n",
            "       159.0       0.92      0.91      0.91       534\n",
            "      159.85       0.73      0.87      0.79       112\n",
            "       16.82       0.68      0.71      0.69       463\n",
            "       160.7       0.81      0.75      0.78       110\n",
            "       162.4       0.65      0.56      0.60       109\n",
            "      163.25       0.86      0.85      0.85       265\n",
            "       164.1       0.62      0.67      0.64       190\n",
            "        18.1       0.84      0.84      0.84       365\n",
            "       19.38       0.62      0.60      0.61       548\n",
            "       20.66       0.74      0.76      0.75       840\n",
            "      200.52       0.89      0.96      0.93       181\n",
            "      208.35       0.96      0.94      0.95       668\n",
            "       21.94       0.56      0.53      0.55       660\n",
            "      216.18       0.92      0.92      0.92       240\n",
            "       23.22       0.57      0.59      0.58       552\n",
            "        24.5       0.77      0.75      0.76       587\n",
            "       25.78       0.64      0.64      0.64       550\n",
            "       27.06       0.60      0.56      0.58       540\n",
            "       28.34       0.89      0.93      0.91       209\n",
            "        29.6       0.80      0.80      0.80       629\n",
            "      294.92       1.00      1.00      1.00         5\n",
            "         3.2       0.96      0.96      0.96       611\n",
            "        3.81       0.96      0.98      0.97       642\n",
            "       30.49       0.60      0.63      0.61       571\n",
            "       31.38       0.65      0.67      0.66       380\n",
            "       32.27       0.90      0.82      0.86        11\n",
            "       33.16       0.98      0.99      0.99       111\n",
            "       34.05       0.94      0.95      0.95       163\n",
            "       34.94       0.97      0.96      0.96       371\n",
            "       35.83       0.97      0.97      0.97       678\n",
            "       36.72       0.95      0.96      0.95       836\n",
            "       37.61       0.89      0.88      0.88       780\n",
            "        38.5       0.94      0.94      0.94       681\n",
            "       39.39       0.86      0.87      0.86       729\n",
            "        4.42       0.95      0.92      0.93       248\n",
            "       40.28       0.81      0.82      0.81       722\n",
            "       41.11       0.76      0.78      0.77       683\n",
            "        42.0       0.80      0.77      0.78       562\n",
            "       42.52       0.75      0.67      0.71       125\n",
            "       43.04       0.86      0.82      0.84       378\n",
            "       43.56       0.94      0.91      0.92       446\n",
            "       44.08       0.92      0.92      0.92       348\n",
            "        44.6       0.79      0.78      0.79       742\n",
            "       45.64       0.71      0.75      0.73       338\n",
            "       46.16       0.77      0.76      0.77       464\n",
            "       46.68       0.58      0.60      0.59       426\n",
            "        47.2       0.88      0.87      0.87       871\n",
            "       47.72       0.91      0.92      0.92       775\n",
            "       48.24       0.94      0.92      0.93       709\n",
            "       48.76       0.78      0.77      0.77       617\n",
            "        49.3       0.70      0.74      0.72       631\n",
            "        5.03       0.94      0.97      0.96       267\n",
            "        5.64       0.95      0.95      0.95       505\n",
            "       57.01       0.66      0.59      0.62       455\n",
            "        6.25       0.71      0.70      0.70       339\n",
            "        6.86       0.81      0.84      0.82       255\n",
            "       64.72       0.63      0.66      0.65       420\n",
            "       72.43       0.77      0.78      0.77       312\n",
            "        8.69       0.67      0.58      0.62       189\n",
            "       80.14       0.56      0.43      0.49        92\n",
            "         9.3       0.78      0.74      0.76       805\n",
            "        9.91       0.64      0.65      0.65       466\n",
            "       95.56       0.38      0.35      0.36        75\n",
            "\n",
            "    accuracy                           0.81     32206\n",
            "   macro avg       0.77      0.77      0.77     32206\n",
            "weighted avg       0.81      0.81      0.81     32206\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[617   0   0 ...  27  24   0]\n",
            " [  0  57   0 ...   0   0   1]\n",
            " [  4   0 748 ...   0   0   0]\n",
            " ...\n",
            " [ 45   0   2 ... 593  95   0]\n",
            " [ 33   0   0 ...  93 305   0]\n",
            " [  0   1   0 ...   0   0  26]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Support Vector Machines"
      ],
      "metadata": {
        "id": "oqE5ZAMk87CY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=SVC()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9LUUNbG9BWJ",
        "outputId": "876aa317-e00d-45af-97b0-907ed14d64b4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.25       0.00      0.00      0.00       189\n",
            "       10.64       0.29      0.95      0.44       805\n",
            "       11.03       0.15      0.06      0.09       466\n",
            "       11.42       0.47      0.36      0.41       781\n",
            "       11.81       0.26      0.57      0.36       775\n",
            "       12.24       0.63      0.88      0.73       889\n",
            "       12.42       0.88      0.49      0.63       677\n",
            "       12.78       0.00      0.00      0.00         7\n",
            "       12.96       0.19      0.01      0.02       463\n",
            "       13.14       0.42      0.75      0.54       365\n",
            "       13.32       0.22      0.40      0.28       548\n",
            "        13.5       0.34      0.33      0.34       840\n",
            "       13.68       0.00      0.00      0.00       660\n",
            "       13.86       0.28      0.04      0.07       552\n",
            "       14.04       0.16      0.02      0.04       587\n",
            "       14.22       0.22      0.10      0.14       550\n",
            "        14.4       0.22      0.21      0.22       540\n",
            "       14.58       1.00      0.07      0.13       209\n",
            "       14.77       0.36      0.35      0.35       629\n",
            "       14.88       0.32      0.54      0.40       571\n",
            "       14.99       0.00      0.00      0.00       380\n",
            "        15.1       0.00      0.00      0.00        11\n",
            "       15.21       0.74      0.77      0.75       111\n",
            "       15.32       0.00      0.00      0.00       163\n",
            "       15.43       0.88      0.17      0.29       371\n",
            "       15.54       0.56      0.44      0.49       678\n",
            "       15.65       0.43      0.61      0.51       836\n",
            "       15.76       0.49      0.37      0.42       780\n",
            "       15.87       0.41      0.72      0.52       681\n",
            "       15.98       0.44      0.46      0.45       729\n",
            "       16.09       0.18      0.71      0.28       722\n",
            "        16.2       0.08      0.00      0.00       683\n",
            "       16.25       0.73      0.40      0.52       562\n",
            "       16.54       0.57      0.24      0.34       125\n",
            "       16.83       0.40      0.29      0.34       378\n",
            "       17.12       0.48      0.41      0.44       446\n",
            "       17.41       0.85      0.03      0.06       348\n",
            "        17.7       0.38      0.36      0.37       742\n",
            "       18.28       0.00      0.00      0.00       338\n",
            "       18.57       0.00      0.00      0.00       464\n",
            "       18.86       0.00      0.00      0.00       426\n",
            "       19.15       0.26      0.66      0.37       871\n",
            "       19.44       0.20      0.77      0.32       775\n",
            "       19.73       0.30      0.77      0.43       709\n",
            "       20.02       0.00      0.00      0.00       617\n",
            "       20.31       0.05      0.01      0.01       631\n",
            "       20.74       0.00      0.00      0.00       455\n",
            "       21.17       0.00      0.00      0.00       420\n",
            "        21.6       0.00      0.00      0.00       312\n",
            "       22.03       0.00      0.00      0.00        92\n",
            "       22.89       0.00      0.00      0.00        75\n",
            "       23.32       0.00      0.00      0.00       109\n",
            "       23.75       0.00      0.00      0.00       127\n",
            "       24.18       0.00      0.00      0.00         2\n",
            "        25.9       0.00      0.00      0.00       114\n",
            "       26.33       0.00      0.00      0.00       260\n",
            "       26.42       0.00      0.00      0.00       279\n",
            "       26.51       0.54      0.71      0.61       534\n",
            "        26.6       0.00      0.00      0.00       112\n",
            "       26.69       0.00      0.00      0.00       110\n",
            "       26.87       0.00      0.00      0.00       109\n",
            "       26.96       0.00      0.00      0.00       265\n",
            "       27.05       0.00      0.00      0.00       190\n",
            "       28.88       0.88      0.37      0.52       181\n",
            "       29.21       0.77      0.97      0.86       668\n",
            "       29.54       0.60      0.43      0.50       240\n",
            "        33.0       1.00      0.20      0.33         5\n",
            "        6.74       0.31      0.19      0.24       611\n",
            "        7.17       0.33      0.34      0.33       642\n",
            "        7.52       0.37      0.60      0.46       248\n",
            "        7.91       0.51      0.68      0.58       267\n",
            "         8.3       0.56      0.86      0.68       505\n",
            "        8.69       0.00      0.00      0.00       339\n",
            "        9.08       0.53      0.04      0.07       255\n",
            "\n",
            "    accuracy                           0.36     32206\n",
            "   macro avg       0.29      0.27      0.23     32206\n",
            "weighted avg       0.32      0.36      0.30     32206\n",
            "\n",
            "The confusion matrix for Fish Length is: [[  0 111   0 ...   0   0   0]\n",
            " [  0 763  17 ...   0   0   0]\n",
            " [  0 372  29 ...   0   0   1]\n",
            " ...\n",
            " [  0   0   0 ... 433   0   0]\n",
            " [  0 126  12 ...   7   0   0]\n",
            " [  0  50   6 ...   0   0   9]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.52       0.41      0.38      0.39       781\n",
            "      103.27       0.00      0.00      0.00       109\n",
            "       11.13       0.26      0.57      0.36       775\n",
            "        11.7       0.63      0.88      0.73       889\n",
            "      110.98       0.00      0.00      0.00       127\n",
            "      118.69       0.00      0.00      0.00         2\n",
            "       12.98       0.88      0.49      0.63       677\n",
            "      149.53       0.00      0.00      0.00       114\n",
            "       15.54       0.00      0.00      0.00         7\n",
            "       157.3       0.00      0.00      0.00       260\n",
            "      158.15       0.00      0.00      0.00       279\n",
            "       159.0       0.53      0.75      0.62       534\n",
            "      159.85       0.00      0.00      0.00       112\n",
            "       16.82       0.19      0.01      0.02       463\n",
            "       160.7       0.00      0.00      0.00       110\n",
            "       162.4       0.00      0.00      0.00       109\n",
            "      163.25       0.00      0.00      0.00       265\n",
            "       164.1       0.00      0.00      0.00       190\n",
            "        18.1       0.42      0.75      0.54       365\n",
            "       19.38       0.22      0.40      0.28       548\n",
            "       20.66       0.34      0.33      0.34       840\n",
            "      200.52       0.88      0.37      0.52       181\n",
            "      208.35       0.77      0.97      0.86       668\n",
            "       21.94       0.00      0.00      0.00       660\n",
            "      216.18       0.60      0.43      0.50       240\n",
            "       23.22       0.28      0.04      0.07       552\n",
            "        24.5       0.16      0.02      0.04       587\n",
            "       25.78       0.22      0.10      0.14       550\n",
            "       27.06       0.22      0.21      0.22       540\n",
            "       28.34       1.00      0.07      0.13       209\n",
            "        29.6       0.36      0.35      0.35       629\n",
            "      294.92       1.00      0.20      0.33         5\n",
            "         3.2       0.31      0.19      0.24       611\n",
            "        3.81       0.33      0.34      0.33       642\n",
            "       30.49       0.32      0.54      0.40       571\n",
            "       31.38       0.00      0.00      0.00       380\n",
            "       32.27       0.00      0.00      0.00        11\n",
            "       33.16       0.74      0.77      0.75       111\n",
            "       34.05       0.00      0.00      0.00       163\n",
            "       34.94       0.88      0.17      0.29       371\n",
            "       35.83       0.56      0.44      0.49       678\n",
            "       36.72       0.43      0.61      0.51       836\n",
            "       37.61       0.49      0.37      0.42       780\n",
            "        38.5       0.41      0.72      0.52       681\n",
            "       39.39       0.44      0.46      0.45       729\n",
            "        4.42       0.37      0.60      0.46       248\n",
            "       40.28       0.18      0.71      0.28       722\n",
            "       41.11       0.08      0.00      0.00       683\n",
            "        42.0       0.73      0.40      0.52       562\n",
            "       42.52       0.57      0.24      0.34       125\n",
            "       43.04       0.40      0.29      0.34       378\n",
            "       43.56       0.48      0.41      0.44       446\n",
            "       44.08       0.85      0.03      0.06       348\n",
            "        44.6       0.38      0.35      0.36       742\n",
            "       45.64       0.00      0.00      0.00       338\n",
            "       46.16       0.00      0.00      0.00       464\n",
            "       46.68       0.00      0.00      0.00       426\n",
            "        47.2       0.26      0.66      0.37       871\n",
            "       47.72       0.21      0.77      0.32       775\n",
            "       48.24       0.30      0.77      0.43       709\n",
            "       48.76       0.00      0.00      0.00       617\n",
            "        49.3       0.05      0.01      0.01       631\n",
            "        5.03       0.51      0.68      0.58       267\n",
            "        5.64       0.56      0.86      0.68       505\n",
            "       57.01       0.00      0.00      0.00       455\n",
            "        6.25       0.00      0.00      0.00       339\n",
            "        6.86       0.53      0.04      0.07       255\n",
            "       64.72       0.00      0.00      0.00       420\n",
            "       72.43       0.00      0.00      0.00       312\n",
            "        8.69       0.00      0.00      0.00       189\n",
            "       80.14       0.00      0.00      0.00        92\n",
            "         9.3       0.29      0.94      0.45       805\n",
            "        9.91       0.20      0.06      0.09       466\n",
            "       95.56       0.00      0.00      0.00        75\n",
            "\n",
            "    accuracy                           0.36     32206\n",
            "   macro avg       0.29      0.27      0.23     32206\n",
            "weighted avg       0.32      0.36      0.30     32206\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[295   0 111 ... 298  18   0]\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [ 93   0 443 ...  28   6   0]\n",
            " ...\n",
            " [  7   0  18 ... 759  17   0]\n",
            " [ 21   0  43 ... 363  27   0]\n",
            " [  0   0   0 ...   0   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Random Forest Classifier"
      ],
      "metadata": {
        "id": "9udIGY-N9FrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=RandomForestClassifier()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7dYyEXR9DNN",
        "outputId": "214cbc1a-6b01-4392-cfba-76b2c026c536"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.25       0.73      0.64      0.68       189\n",
            "       10.64       0.78      0.85      0.82       805\n",
            "       11.03       0.78      0.68      0.73       466\n",
            "       11.42       0.81      0.83      0.82       781\n",
            "       11.81       0.98      0.98      0.98       775\n",
            "       12.24       0.98      0.99      0.98       889\n",
            "       12.42       0.99      0.99      0.99       677\n",
            "       12.78       0.00      0.00      0.00         7\n",
            "       12.96       0.77      0.75      0.76       463\n",
            "       13.14       0.88      0.88      0.88       365\n",
            "       13.32       0.69      0.74      0.72       548\n",
            "        13.5       0.81      0.82      0.82       840\n",
            "       13.68       0.67      0.64      0.65       660\n",
            "       13.86       0.70      0.66      0.68       552\n",
            "       14.04       0.87      0.81      0.84       587\n",
            "       14.22       0.71      0.69      0.70       550\n",
            "        14.4       0.68      0.71      0.69       540\n",
            "       14.58       0.94      0.92      0.93       209\n",
            "       14.77       0.90      0.83      0.86       629\n",
            "       14.88       0.69      0.77      0.73       571\n",
            "       14.99       0.74      0.77      0.75       380\n",
            "        15.1       0.90      0.82      0.86        11\n",
            "       15.21       0.99      1.00      1.00       111\n",
            "       15.32       0.98      0.96      0.97       163\n",
            "       15.43       0.98      0.98      0.98       371\n",
            "       15.54       0.99      0.97      0.98       678\n",
            "       15.65       0.97      0.98      0.97       836\n",
            "       15.76       0.91      0.92      0.92       780\n",
            "       15.87       0.96      0.96      0.96       681\n",
            "       15.98       0.90      0.88      0.89       729\n",
            "       16.09       0.82      0.88      0.85       722\n",
            "        16.2       0.78      0.82      0.80       683\n",
            "       16.25       0.82      0.82      0.82       562\n",
            "       16.54       0.86      0.76      0.81       125\n",
            "       16.83       0.92      0.87      0.90       378\n",
            "       17.12       0.94      0.95      0.94       446\n",
            "       17.41       0.92      0.95      0.93       348\n",
            "        17.7       0.82      0.83      0.83       742\n",
            "       18.28       0.76      0.80      0.78       338\n",
            "       18.57       0.81      0.81      0.81       464\n",
            "       18.86       0.66      0.62      0.64       426\n",
            "       19.15       0.88      0.91      0.89       871\n",
            "       19.44       0.93      0.94      0.94       775\n",
            "       19.73       0.95      0.95      0.95       709\n",
            "       20.02       0.81      0.79      0.80       617\n",
            "       20.31       0.74      0.78      0.76       631\n",
            "       20.74       0.73      0.68      0.70       455\n",
            "       21.17       0.68      0.72      0.70       420\n",
            "        21.6       0.79      0.84      0.81       312\n",
            "       22.03       0.73      0.39      0.51        92\n",
            "       22.89       0.46      0.37      0.41        75\n",
            "       23.32       0.72      0.55      0.62       109\n",
            "       23.75       0.61      0.64      0.63       127\n",
            "       24.18       1.00      0.50      0.67         2\n",
            "        25.9       0.87      0.89      0.88       114\n",
            "       26.33       0.64      0.60      0.62       260\n",
            "       26.42       0.61      0.55      0.58       279\n",
            "       26.51       0.94      0.93      0.93       534\n",
            "        26.6       0.80      0.87      0.83       112\n",
            "       26.69       0.88      0.84      0.86       110\n",
            "       26.87       0.66      0.63      0.65       109\n",
            "       26.96       0.90      0.88      0.89       265\n",
            "       27.05       0.71      0.72      0.72       190\n",
            "       28.88       0.91      0.97      0.94       181\n",
            "       29.21       0.96      0.95      0.96       668\n",
            "       29.54       0.94      0.90      0.92       240\n",
            "        33.0       1.00      1.00      1.00         5\n",
            "        6.74       0.97      0.97      0.97       611\n",
            "        7.17       0.97      0.98      0.98       642\n",
            "        7.52       0.96      0.97      0.96       248\n",
            "        7.91       0.98      0.97      0.98       267\n",
            "         8.3       0.94      0.98      0.96       505\n",
            "        8.69       0.79      0.73      0.76       339\n",
            "        9.08       0.85      0.86      0.86       255\n",
            "\n",
            "    accuracy                           0.85     32206\n",
            "   macro avg       0.83      0.81      0.81     32206\n",
            "weighted avg       0.85      0.85      0.85     32206\n",
            "\n",
            "The confusion matrix for Fish Length is: [[121  20  11 ...   0   4   0]\n",
            " [ 11 685  42 ...   0   7  10]\n",
            " [  2 109 317 ...   0   7   1]\n",
            " ...\n",
            " [  0   0   0 ... 493   3   0]\n",
            " [  8  14  12 ...  11 247   3]\n",
            " [  1  16   2 ...   0   4 220]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.52       0.80      0.84      0.82       781\n",
            "      103.27       0.76      0.53      0.63       109\n",
            "       11.13       0.98      0.98      0.98       775\n",
            "        11.7       0.98      0.98      0.98       889\n",
            "      110.98       0.64      0.65      0.65       127\n",
            "      118.69       1.00      0.50      0.67         2\n",
            "       12.98       0.98      0.99      0.98       677\n",
            "      149.53       0.87      0.89      0.88       114\n",
            "       15.54       0.00      0.00      0.00         7\n",
            "       157.3       0.63      0.59      0.61       260\n",
            "      158.15       0.60      0.56      0.58       279\n",
            "       159.0       0.95      0.92      0.94       534\n",
            "      159.85       0.80      0.88      0.84       112\n",
            "       16.82       0.77      0.76      0.76       463\n",
            "       160.7       0.87      0.86      0.87       110\n",
            "       162.4       0.68      0.65      0.66       109\n",
            "      163.25       0.89      0.87      0.88       265\n",
            "       164.1       0.71      0.74      0.72       190\n",
            "        18.1       0.88      0.88      0.88       365\n",
            "       19.38       0.71      0.74      0.72       548\n",
            "       20.66       0.80      0.82      0.81       840\n",
            "      200.52       0.91      0.97      0.94       181\n",
            "      208.35       0.96      0.96      0.96       668\n",
            "       21.94       0.68      0.63      0.65       660\n",
            "      216.18       0.95      0.90      0.93       240\n",
            "       23.22       0.67      0.65      0.66       552\n",
            "        24.5       0.87      0.81      0.84       587\n",
            "       25.78       0.72      0.69      0.70       550\n",
            "       27.06       0.68      0.73      0.71       540\n",
            "       28.34       0.94      0.93      0.93       209\n",
            "        29.6       0.89      0.84      0.87       629\n",
            "      294.92       1.00      1.00      1.00         5\n",
            "         3.2       0.97      0.98      0.97       611\n",
            "        3.81       0.98      0.98      0.98       642\n",
            "       30.49       0.70      0.77      0.73       571\n",
            "       31.38       0.74      0.79      0.77       380\n",
            "       32.27       0.90      0.82      0.86        11\n",
            "       33.16       0.99      0.99      0.99       111\n",
            "       34.05       0.98      0.96      0.97       163\n",
            "       34.94       0.98      0.98      0.98       371\n",
            "       35.83       0.99      0.97      0.98       678\n",
            "       36.72       0.97      0.98      0.97       836\n",
            "       37.61       0.91      0.92      0.92       780\n",
            "        38.5       0.96      0.96      0.96       681\n",
            "       39.39       0.90      0.89      0.90       729\n",
            "        4.42       0.96      0.97      0.96       248\n",
            "       40.28       0.82      0.87      0.84       722\n",
            "       41.11       0.79      0.83      0.81       683\n",
            "        42.0       0.83      0.81      0.82       562\n",
            "       42.52       0.87      0.78      0.82       125\n",
            "       43.04       0.92      0.87      0.90       378\n",
            "       43.56       0.95      0.96      0.95       446\n",
            "       44.08       0.93      0.95      0.94       348\n",
            "        44.6       0.83      0.84      0.83       742\n",
            "       45.64       0.77      0.80      0.79       338\n",
            "       46.16       0.80      0.82      0.81       464\n",
            "       46.68       0.66      0.63      0.64       426\n",
            "        47.2       0.88      0.91      0.90       871\n",
            "       47.72       0.93      0.94      0.94       775\n",
            "       48.24       0.95      0.95      0.95       709\n",
            "       48.76       0.82      0.79      0.80       617\n",
            "        49.3       0.74      0.78      0.76       631\n",
            "        5.03       0.97      0.97      0.97       267\n",
            "        5.64       0.94      0.97      0.96       505\n",
            "       57.01       0.75      0.68      0.71       455\n",
            "        6.25       0.80      0.74      0.77       339\n",
            "        6.86       0.86      0.85      0.86       255\n",
            "       64.72       0.66      0.71      0.69       420\n",
            "       72.43       0.79      0.85      0.82       312\n",
            "        8.69       0.73      0.63      0.68       189\n",
            "       80.14       0.69      0.39      0.50        92\n",
            "         9.3       0.79      0.85      0.82       805\n",
            "        9.91       0.78      0.69      0.73       466\n",
            "       95.56       0.50      0.41      0.45        75\n",
            "\n",
            "    accuracy                           0.85     32206\n",
            "   macro avg       0.83      0.81      0.82     32206\n",
            "weighted avg       0.85      0.85      0.85     32206\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[657   0   0 ...  21  17   0]\n",
            " [  0  58   0 ...   0   0   0]\n",
            " [  3   0 760 ...   0   0   0]\n",
            " ...\n",
            " [ 37   0   2 ... 682  43   0]\n",
            " [ 22   0   0 ... 104 323   0]\n",
            " [  0   0   0 ...   0   0  31]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) K Nearest Neighbors"
      ],
      "metadata": {
        "id": "nDpHE_9V9TWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=KNeighborsClassifier()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1geqwSj9OzJ",
        "outputId": "18eece33-5dd4-4aa9-a441-94774f3c4cea"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.25       0.30      0.41      0.35       189\n",
            "       10.64       0.63      0.76      0.69       805\n",
            "       11.03       0.41      0.36      0.38       466\n",
            "       11.42       0.61      0.63      0.62       781\n",
            "       11.81       0.89      0.85      0.87       775\n",
            "       12.24       0.88      0.89      0.89       889\n",
            "       12.42       0.86      0.88      0.87       677\n",
            "       12.78       0.14      0.14      0.14         7\n",
            "       12.96       0.37      0.52      0.43       463\n",
            "       13.14       0.63      0.72      0.67       365\n",
            "       13.32       0.40      0.51      0.45       548\n",
            "        13.5       0.54      0.53      0.54       840\n",
            "       13.68       0.38      0.33      0.35       660\n",
            "       13.86       0.35      0.30      0.32       552\n",
            "       14.04       0.46      0.39      0.43       587\n",
            "       14.22       0.41      0.37      0.39       550\n",
            "        14.4       0.38      0.40      0.39       540\n",
            "       14.58       0.78      0.47      0.59       209\n",
            "       14.77       0.54      0.49      0.51       629\n",
            "       14.88       0.42      0.53      0.47       571\n",
            "       14.99       0.52      0.43      0.47       380\n",
            "        15.1       0.82      0.82      0.82        11\n",
            "       15.21       0.83      0.86      0.84       111\n",
            "       15.32       0.85      0.75      0.79       163\n",
            "       15.43       0.82      0.86      0.84       371\n",
            "       15.54       0.89      0.90      0.89       678\n",
            "       15.65       0.77      0.87      0.82       836\n",
            "       15.76       0.71      0.74      0.73       780\n",
            "       15.87       0.82      0.75      0.78       681\n",
            "       15.98       0.75      0.68      0.72       729\n",
            "       16.09       0.69      0.79      0.74       722\n",
            "        16.2       0.67      0.76      0.71       683\n",
            "       16.25       0.70      0.78      0.74       562\n",
            "       16.54       0.68      0.61      0.64       125\n",
            "       16.83       0.69      0.72      0.70       378\n",
            "       17.12       0.80      0.81      0.81       446\n",
            "       17.41       0.84      0.74      0.79       348\n",
            "        17.7       0.72      0.75      0.73       742\n",
            "       18.28       0.64      0.71      0.67       338\n",
            "       18.57       0.74      0.71      0.73       464\n",
            "       18.86       0.63      0.57      0.59       426\n",
            "       19.15       0.81      0.86      0.83       871\n",
            "       19.44       0.86      0.91      0.88       775\n",
            "       19.73       0.87      0.90      0.88       709\n",
            "       20.02       0.70      0.68      0.69       617\n",
            "       20.31       0.63      0.68      0.65       631\n",
            "       20.74       0.61      0.55      0.58       455\n",
            "       21.17       0.60      0.60      0.60       420\n",
            "        21.6       0.71      0.78      0.74       312\n",
            "       22.03       0.75      0.20      0.31        92\n",
            "       22.89       0.37      0.20      0.26        75\n",
            "       23.32       0.49      0.39      0.44       109\n",
            "       23.75       0.52      0.59      0.55       127\n",
            "       24.18       0.00      0.00      0.00         2\n",
            "        25.9       0.74      0.68      0.71       114\n",
            "       26.33       0.54      0.38      0.45       260\n",
            "       26.42       0.48      0.35      0.40       279\n",
            "       26.51       0.86      0.89      0.88       534\n",
            "        26.6       0.66      0.55      0.60       112\n",
            "       26.69       0.78      0.65      0.71       110\n",
            "       26.87       0.56      0.45      0.50       109\n",
            "       26.96       0.81      0.69      0.75       265\n",
            "       27.05       0.61      0.45      0.52       190\n",
            "       28.88       0.84      0.84      0.84       181\n",
            "       29.21       0.94      0.93      0.93       668\n",
            "       29.54       0.83      0.85      0.84       240\n",
            "        33.0       1.00      0.40      0.57         5\n",
            "        6.74       0.75      0.70      0.73       611\n",
            "        7.17       0.73      0.69      0.71       642\n",
            "        7.52       0.80      0.73      0.76       248\n",
            "        7.91       0.72      0.76      0.74       267\n",
            "         8.3       0.82      0.85      0.83       505\n",
            "        8.69       0.62      0.40      0.48       339\n",
            "        9.08       0.61      0.58      0.59       255\n",
            "\n",
            "    accuracy                           0.68     32206\n",
            "   macro avg       0.66      0.62      0.63     32206\n",
            "weighted avg       0.68      0.68      0.68     32206\n",
            "\n",
            "The confusion matrix for Fish Length is: [[ 77  35  14 ...   0   3  10]\n",
            " [ 32 613  77 ...   0  13   9]\n",
            " [ 28 169 166 ...   0  12   3]\n",
            " ...\n",
            " [  0   0   0 ... 427   3   0]\n",
            " [ 14  46  27 ...   5 134  14]\n",
            " [ 16  22   8 ...   0   6 147]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.52       0.55      0.67      0.61       781\n",
            "      103.27       0.47      0.44      0.45       109\n",
            "       11.13       0.89      0.86      0.87       775\n",
            "        11.7       0.88      0.89      0.89       889\n",
            "      110.98       0.52      0.64      0.57       127\n",
            "      118.69       0.00      0.00      0.00         2\n",
            "       12.98       0.86      0.88      0.87       677\n",
            "      149.53       0.71      0.70      0.71       114\n",
            "       15.54       0.14      0.14      0.14         7\n",
            "       157.3       0.49      0.46      0.47       260\n",
            "      158.15       0.43      0.42      0.43       279\n",
            "       159.0       0.84      0.89      0.86       534\n",
            "      159.85       0.66      0.56      0.61       112\n",
            "       16.82       0.37      0.52      0.43       463\n",
            "       160.7       0.76      0.65      0.70       110\n",
            "       162.4       0.54      0.45      0.49       109\n",
            "      163.25       0.77      0.71      0.74       265\n",
            "       164.1       0.54      0.48      0.51       190\n",
            "        18.1       0.63      0.72      0.67       365\n",
            "       19.38       0.40      0.51      0.45       548\n",
            "       20.66       0.54      0.53      0.53       840\n",
            "      200.52       0.84      0.84      0.84       181\n",
            "      208.35       0.94      0.93      0.93       668\n",
            "       21.94       0.37      0.33      0.35       660\n",
            "      216.18       0.83      0.85      0.84       240\n",
            "       23.22       0.34      0.30      0.32       552\n",
            "        24.5       0.46      0.40      0.43       587\n",
            "       25.78       0.41      0.37      0.39       550\n",
            "       27.06       0.38      0.40      0.39       540\n",
            "       28.34       0.78      0.47      0.59       209\n",
            "        29.6       0.54      0.49      0.51       629\n",
            "      294.92       1.00      0.40      0.57         5\n",
            "         3.2       0.75      0.71      0.73       611\n",
            "        3.81       0.73      0.69      0.71       642\n",
            "       30.49       0.42      0.53      0.47       571\n",
            "       31.38       0.52      0.43      0.47       380\n",
            "       32.27       0.64      0.82      0.72        11\n",
            "       33.16       0.83      0.86      0.84       111\n",
            "       34.05       0.85      0.75      0.79       163\n",
            "       34.94       0.82      0.86      0.84       371\n",
            "       35.83       0.89      0.90      0.89       678\n",
            "       36.72       0.77      0.87      0.82       836\n",
            "       37.61       0.71      0.74      0.73       780\n",
            "        38.5       0.82      0.75      0.78       681\n",
            "       39.39       0.76      0.68      0.72       729\n",
            "        4.42       0.80      0.73      0.76       248\n",
            "       40.28       0.70      0.78      0.74       722\n",
            "       41.11       0.68      0.76      0.72       683\n",
            "        42.0       0.70      0.78      0.74       562\n",
            "       42.52       0.69      0.60      0.64       125\n",
            "       43.04       0.69      0.71      0.70       378\n",
            "       43.56       0.80      0.81      0.81       446\n",
            "       44.08       0.86      0.74      0.80       348\n",
            "        44.6       0.72      0.75      0.74       742\n",
            "       45.64       0.64      0.71      0.67       338\n",
            "       46.16       0.75      0.71      0.73       464\n",
            "       46.68       0.63      0.57      0.60       426\n",
            "        47.2       0.81      0.86      0.84       871\n",
            "       47.72       0.86      0.91      0.88       775\n",
            "       48.24       0.87      0.90      0.88       709\n",
            "       48.76       0.72      0.68      0.70       617\n",
            "        49.3       0.63      0.68      0.65       631\n",
            "        5.03       0.72      0.76      0.74       267\n",
            "        5.64       0.82      0.85      0.83       505\n",
            "       57.01       0.63      0.55      0.58       455\n",
            "        6.25       0.56      0.43      0.49       339\n",
            "        6.86       0.58      0.60      0.59       255\n",
            "       64.72       0.62      0.58      0.60       420\n",
            "       72.43       0.74      0.74      0.74       312\n",
            "        8.69       0.37      0.33      0.35       189\n",
            "       80.14       0.84      0.17      0.29        92\n",
            "         9.3       0.68      0.73      0.70       805\n",
            "        9.91       0.45      0.28      0.35       466\n",
            "       95.56       0.42      0.15      0.22        75\n",
            "\n",
            "    accuracy                           0.68     32206\n",
            "   macro avg       0.65      0.63      0.63     32206\n",
            "weighted avg       0.68      0.68      0.68     32206\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[525   0  23 ...  32  41   0]\n",
            " [  0  48   0 ...   0   0   0]\n",
            " [ 28   0 664 ...   0   2   0]\n",
            " ...\n",
            " [ 83   0   2 ... 585  58   0]\n",
            " [ 83   0   0 ... 150 132   0]\n",
            " [  0   1   0 ...   0   0  11]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Adam Boost Classifier"
      ],
      "metadata": {
        "id": "PlOAPzcP9fjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=AdaBoostClassifier()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lu9xjfMG9aCX",
        "outputId": "1a1cec18-26e2-4a5e-8694-6b9ab3329471"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.25       0.00      0.00      0.00       189\n",
            "       10.64       0.00      0.00      0.00       805\n",
            "       11.03       0.00      0.00      0.00       466\n",
            "       11.42       0.00      0.00      0.00       781\n",
            "       11.81       0.05      1.00      0.10       775\n",
            "       12.24       0.00      0.00      0.00       889\n",
            "       12.42       0.00      0.00      0.00       677\n",
            "       12.78       0.00      0.00      0.00         7\n",
            "       12.96       0.00      0.00      0.00       463\n",
            "       13.14       0.00      0.00      0.00       365\n",
            "       13.32       0.00      0.00      0.00       548\n",
            "        13.5       0.00      0.00      0.00       840\n",
            "       13.68       0.00      0.00      0.00       660\n",
            "       13.86       0.00      0.00      0.00       552\n",
            "       14.04       0.00      0.00      0.00       587\n",
            "       14.22       0.00      0.00      0.00       550\n",
            "        14.4       0.00      0.00      0.00       540\n",
            "       14.58       0.00      0.00      0.00       209\n",
            "       14.77       0.00      0.00      0.00       629\n",
            "       14.88       0.00      0.00      0.00       571\n",
            "       14.99       0.00      0.00      0.00       380\n",
            "        15.1       0.00      0.00      0.00        11\n",
            "       15.21       0.00      0.00      0.00       111\n",
            "       15.32       0.00      0.00      0.00       163\n",
            "       15.43       0.00      0.00      0.00       371\n",
            "       15.54       0.00      0.00      0.00       678\n",
            "       15.65       0.05      1.00      0.09       836\n",
            "       15.76       0.00      0.00      0.00       780\n",
            "       15.87       0.00      0.00      0.00       681\n",
            "       15.98       0.00      0.00      0.00       729\n",
            "       16.09       0.00      0.00      0.00       722\n",
            "        16.2       0.00      0.00      0.00       683\n",
            "       16.25       0.00      0.00      0.00       562\n",
            "       16.54       0.00      0.00      0.00       125\n",
            "       16.83       0.00      0.00      0.00       378\n",
            "       17.12       0.00      0.00      0.00       446\n",
            "       17.41       0.00      0.00      0.00       348\n",
            "        17.7       0.00      0.00      0.00       742\n",
            "       18.28       0.00      0.00      0.00       338\n",
            "       18.57       0.00      0.00      0.00       464\n",
            "       18.86       0.00      0.00      0.00       426\n",
            "       19.15       0.00      0.00      0.00       871\n",
            "       19.44       0.00      0.00      0.00       775\n",
            "       19.73       0.00      0.00      0.00       709\n",
            "       20.02       0.00      0.00      0.00       617\n",
            "       20.31       0.00      0.00      0.00       631\n",
            "       20.74       0.00      0.00      0.00       455\n",
            "       21.17       0.00      0.00      0.00       420\n",
            "        21.6       0.00      0.00      0.00       312\n",
            "       22.03       0.00      0.00      0.00        92\n",
            "       22.89       0.00      0.00      0.00        75\n",
            "       23.32       0.00      0.00      0.00       109\n",
            "       23.75       0.00      0.00      0.00       127\n",
            "       24.18       0.00      0.00      0.00         2\n",
            "        25.9       0.00      0.00      0.00       114\n",
            "       26.33       0.00      0.00      0.00       260\n",
            "       26.42       0.00      0.00      0.00       279\n",
            "       26.51       0.00      0.00      0.00       534\n",
            "        26.6       0.00      0.00      0.00       112\n",
            "       26.69       0.00      0.00      0.00       110\n",
            "       26.87       0.00      0.00      0.00       109\n",
            "       26.96       0.00      0.00      0.00       265\n",
            "       27.05       0.00      0.00      0.00       190\n",
            "       28.88       0.00      0.00      0.00       181\n",
            "       29.21       0.61      1.00      0.76       668\n",
            "       29.54       0.00      0.00      0.00       240\n",
            "       32.45       0.00      0.00      0.00         0\n",
            "        33.0       1.00      0.40      0.57         5\n",
            "        6.74       0.00      0.00      0.00       611\n",
            "        7.17       0.00      0.00      0.00       642\n",
            "        7.52       0.00      0.00      0.00       248\n",
            "        7.91       0.00      0.00      0.00       267\n",
            "         8.3       0.00      0.00      0.00       505\n",
            "        8.69       0.00      0.00      0.00       339\n",
            "        9.08       0.00      0.00      0.00       255\n",
            "\n",
            "    accuracy                           0.07     32206\n",
            "   macro avg       0.02      0.05      0.02     32206\n",
            "weighted avg       0.02      0.07      0.02     32206\n",
            "\n",
            "The confusion matrix for Fish Length is: [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.52       0.00      0.00      0.00       781\n",
            "      103.27       0.00      0.00      0.00       109\n",
            "       11.13       0.05      1.00      0.10       775\n",
            "        11.7       0.00      0.00      0.00       889\n",
            "      110.98       0.00      0.00      0.00       127\n",
            "      118.69       0.00      0.00      0.00         2\n",
            "       12.98       0.00      0.00      0.00       677\n",
            "      149.53       0.00      0.00      0.00       114\n",
            "       15.54       0.00      0.00      0.00         7\n",
            "       157.3       0.00      0.00      0.00       260\n",
            "      158.15       0.00      0.00      0.00       279\n",
            "       159.0       0.00      0.00      0.00       534\n",
            "      159.85       0.00      0.00      0.00       112\n",
            "       16.82       0.00      0.00      0.00       463\n",
            "       160.7       0.00      0.00      0.00       110\n",
            "       162.4       0.00      0.00      0.00       109\n",
            "      163.25       0.00      0.00      0.00       265\n",
            "       164.1       0.00      0.00      0.00       190\n",
            "        18.1       0.00      0.00      0.00       365\n",
            "       19.38       0.00      0.00      0.00       548\n",
            "       20.66       0.00      0.00      0.00       840\n",
            "      200.52       0.00      0.00      0.00       181\n",
            "      208.35       0.61      1.00      0.76       668\n",
            "       21.94       0.00      0.00      0.00       660\n",
            "      216.18       0.00      0.00      0.00       240\n",
            "       23.22       0.00      0.00      0.00       552\n",
            "        24.5       0.00      0.00      0.00       587\n",
            "       25.78       0.00      0.00      0.00       550\n",
            "       27.06       0.00      0.00      0.00       540\n",
            "       28.34       0.00      0.00      0.00       209\n",
            "      280.96       0.00      0.00      0.00         0\n",
            "        29.6       0.00      0.00      0.00       629\n",
            "      294.92       1.00      0.40      0.57         5\n",
            "         3.2       0.00      0.00      0.00       611\n",
            "        3.81       0.00      0.00      0.00       642\n",
            "       30.49       0.00      0.00      0.00       571\n",
            "       31.38       0.00      0.00      0.00       380\n",
            "       32.27       0.00      0.00      0.00        11\n",
            "       33.16       0.00      0.00      0.00       111\n",
            "       34.05       0.00      0.00      0.00       163\n",
            "       34.94       0.00      0.00      0.00       371\n",
            "       35.83       0.00      0.00      0.00       678\n",
            "       36.72       0.05      1.00      0.09       836\n",
            "       37.61       0.00      0.00      0.00       780\n",
            "        38.5       0.00      0.00      0.00       681\n",
            "       39.39       0.00      0.00      0.00       729\n",
            "        4.42       0.00      0.00      0.00       248\n",
            "       40.28       0.00      0.00      0.00       722\n",
            "       41.11       0.00      0.00      0.00       683\n",
            "        42.0       0.00      0.00      0.00       562\n",
            "       42.52       0.00      0.00      0.00       125\n",
            "       43.04       0.00      0.00      0.00       378\n",
            "       43.56       0.00      0.00      0.00       446\n",
            "       44.08       0.00      0.00      0.00       348\n",
            "        44.6       0.00      0.00      0.00       742\n",
            "       45.64       0.00      0.00      0.00       338\n",
            "       46.16       0.00      0.00      0.00       464\n",
            "       46.68       0.00      0.00      0.00       426\n",
            "        47.2       0.00      0.00      0.00       871\n",
            "       47.72       0.00      0.00      0.00       775\n",
            "       48.24       0.00      0.00      0.00       709\n",
            "       48.76       0.00      0.00      0.00       617\n",
            "        49.3       0.00      0.00      0.00       631\n",
            "        5.03       0.00      0.00      0.00       267\n",
            "        5.64       0.00      0.00      0.00       505\n",
            "       57.01       0.00      0.00      0.00       455\n",
            "        6.25       0.00      0.00      0.00       339\n",
            "        6.86       0.00      0.00      0.00       255\n",
            "       64.72       0.00      0.00      0.00       420\n",
            "       72.43       0.00      0.00      0.00       312\n",
            "        8.69       0.00      0.00      0.00       189\n",
            "       80.14       0.00      0.00      0.00        92\n",
            "         9.3       0.00      0.00      0.00       805\n",
            "        9.91       0.00      0.00      0.00       466\n",
            "       95.56       0.00      0.00      0.00        75\n",
            "\n",
            "    accuracy                           0.07     32206\n",
            "   macro avg       0.02      0.05      0.02     32206\n",
            "weighted avg       0.02      0.07      0.02     32206\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[  0   0 645 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [  0   0 774 ...   0   0   0]\n",
            " ...\n",
            " [  0   0 805 ...   0   0   0]\n",
            " [  0   0 466 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7) Extra Trees Classifier"
      ],
      "metadata": {
        "id": "hNE3ERw49mgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=ExtraTreesClassifier()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqQjKUtp9etF",
        "outputId": "0ed0fbcc-c89e-4dc9-8d62-09df2339513f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.25       0.70      0.66      0.68       189\n",
            "       10.64       0.77      0.83      0.80       805\n",
            "       11.03       0.75      0.69      0.72       466\n",
            "       11.42       0.82      0.84      0.83       781\n",
            "       11.81       0.98      0.98      0.98       775\n",
            "       12.24       0.98      0.98      0.98       889\n",
            "       12.42       0.98      0.99      0.98       677\n",
            "       12.78       0.00      0.00      0.00         7\n",
            "       12.96       0.77      0.77      0.77       463\n",
            "       13.14       0.89      0.87      0.88       365\n",
            "       13.32       0.68      0.76      0.72       548\n",
            "        13.5       0.81      0.83      0.82       840\n",
            "       13.68       0.68      0.61      0.64       660\n",
            "       13.86       0.67      0.65      0.66       552\n",
            "       14.04       0.87      0.80      0.83       587\n",
            "       14.22       0.74      0.70      0.72       550\n",
            "        14.4       0.70      0.70      0.70       540\n",
            "       14.58       0.97      0.93      0.95       209\n",
            "       14.77       0.89      0.84      0.86       629\n",
            "       14.88       0.69      0.78      0.73       571\n",
            "       14.99       0.73      0.78      0.76       380\n",
            "        15.1       0.91      0.91      0.91        11\n",
            "       15.21       0.99      0.98      0.99       111\n",
            "       15.32       0.97      0.96      0.97       163\n",
            "       15.43       0.98      0.98      0.98       371\n",
            "       15.54       0.99      0.98      0.99       678\n",
            "       15.65       0.96      0.98      0.97       836\n",
            "       15.76       0.91      0.92      0.92       780\n",
            "       15.87       0.96      0.96      0.96       681\n",
            "       15.98       0.90      0.89      0.89       729\n",
            "       16.09       0.88      0.90      0.89       722\n",
            "        16.2       0.81      0.83      0.82       683\n",
            "       16.25       0.83      0.83      0.83       562\n",
            "       16.54       0.86      0.84      0.85       125\n",
            "       16.83       0.91      0.89      0.90       378\n",
            "       17.12       0.94      0.94      0.94       446\n",
            "       17.41       0.95      0.95      0.95       348\n",
            "        17.7       0.81      0.82      0.82       742\n",
            "       18.28       0.75      0.80      0.78       338\n",
            "       18.57       0.83      0.83      0.83       464\n",
            "       18.86       0.66      0.65      0.65       426\n",
            "       19.15       0.88      0.91      0.90       871\n",
            "       19.44       0.92      0.94      0.93       775\n",
            "       19.73       0.94      0.94      0.94       709\n",
            "       20.02       0.80      0.77      0.79       617\n",
            "       20.31       0.73      0.77      0.75       631\n",
            "       20.74       0.71      0.66      0.68       455\n",
            "       21.17       0.65      0.69      0.67       420\n",
            "        21.6       0.78      0.83      0.80       312\n",
            "       22.03       0.65      0.39      0.49        92\n",
            "       22.89       0.44      0.39      0.41        75\n",
            "       23.32       0.74      0.54      0.62       109\n",
            "       23.75       0.62      0.61      0.62       127\n",
            "       24.18       1.00      0.50      0.67         2\n",
            "        25.9       0.89      0.91      0.90       114\n",
            "       26.33       0.68      0.63      0.65       260\n",
            "       26.42       0.60      0.55      0.57       279\n",
            "       26.51       0.93      0.93      0.93       534\n",
            "        26.6       0.84      0.87      0.85       112\n",
            "       26.69       0.90      0.88      0.89       110\n",
            "       26.87       0.66      0.61      0.64       109\n",
            "       26.96       0.87      0.88      0.87       265\n",
            "       27.05       0.69      0.72      0.70       190\n",
            "       28.88       0.90      0.97      0.93       181\n",
            "       29.21       0.96      0.95      0.96       668\n",
            "       29.54       0.95      0.90      0.93       240\n",
            "        33.0       1.00      1.00      1.00         5\n",
            "        6.74       0.97      0.98      0.98       611\n",
            "        7.17       0.97      0.99      0.98       642\n",
            "        7.52       0.95      0.96      0.95       248\n",
            "        7.91       0.98      0.97      0.97       267\n",
            "         8.3       0.94      0.97      0.95       505\n",
            "        8.69       0.79      0.73      0.76       339\n",
            "        9.08       0.83      0.85      0.84       255\n",
            "\n",
            "    accuracy                           0.85     32206\n",
            "   macro avg       0.82      0.81      0.82     32206\n",
            "weighted avg       0.85      0.85      0.85     32206\n",
            "\n",
            "The confusion matrix for Fish Length is: [[124  22   9 ...   0   5   0]\n",
            " [ 14 667  54 ...   0   6  16]\n",
            " [  4 106 320 ...   0   9   1]\n",
            " ...\n",
            " [  0   0   0 ... 491   4   0]\n",
            " [  7  16  17 ...  10 246   4]\n",
            " [  2  17   3 ...   0   2 217]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.52       0.81      0.83      0.82       781\n",
            "      103.27       0.71      0.52      0.60       109\n",
            "       11.13       0.98      0.98      0.98       775\n",
            "        11.7       0.98      0.98      0.98       889\n",
            "      110.98       0.62      0.62      0.62       127\n",
            "      118.69       1.00      0.50      0.67         2\n",
            "       12.98       0.98      0.99      0.98       677\n",
            "      149.53       0.87      0.89      0.88       114\n",
            "       15.54       0.00      0.00      0.00         7\n",
            "       157.3       0.69      0.63      0.66       260\n",
            "      158.15       0.62      0.56      0.59       279\n",
            "       159.0       0.93      0.93      0.93       534\n",
            "      159.85       0.80      0.86      0.83       112\n",
            "       16.82       0.77      0.77      0.77       463\n",
            "       160.7       0.90      0.85      0.87       110\n",
            "       162.4       0.66      0.61      0.64       109\n",
            "      163.25       0.88      0.87      0.87       265\n",
            "       164.1       0.69      0.72      0.70       190\n",
            "        18.1       0.90      0.87      0.88       365\n",
            "       19.38       0.69      0.76      0.73       548\n",
            "       20.66       0.82      0.83      0.82       840\n",
            "      200.52       0.90      0.97      0.93       181\n",
            "      208.35       0.96      0.95      0.95       668\n",
            "       21.94       0.68      0.61      0.64       660\n",
            "      216.18       0.94      0.92      0.93       240\n",
            "       23.22       0.68      0.66      0.67       552\n",
            "        24.5       0.88      0.80      0.83       587\n",
            "       25.78       0.72      0.70      0.71       550\n",
            "       27.06       0.69      0.70      0.69       540\n",
            "       28.34       0.94      0.91      0.93       209\n",
            "        29.6       0.88      0.83      0.85       629\n",
            "      294.92       1.00      1.00      1.00         5\n",
            "         3.2       0.98      0.98      0.98       611\n",
            "        3.81       0.97      0.99      0.98       642\n",
            "       30.49       0.69      0.78      0.74       571\n",
            "       31.38       0.71      0.78      0.74       380\n",
            "       32.27       0.90      0.82      0.86        11\n",
            "       33.16       0.99      0.98      0.99       111\n",
            "       34.05       0.97      0.96      0.97       163\n",
            "       34.94       0.98      0.98      0.98       371\n",
            "       35.83       0.99      0.98      0.99       678\n",
            "       36.72       0.96      0.98      0.97       836\n",
            "       37.61       0.92      0.92      0.92       780\n",
            "        38.5       0.96      0.96      0.96       681\n",
            "       39.39       0.90      0.90      0.90       729\n",
            "        4.42       0.95      0.95      0.95       248\n",
            "       40.28       0.88      0.91      0.90       722\n",
            "       41.11       0.82      0.83      0.82       683\n",
            "        42.0       0.82      0.83      0.83       562\n",
            "       42.52       0.88      0.80      0.84       125\n",
            "       43.04       0.91      0.88      0.89       378\n",
            "       43.56       0.94      0.95      0.94       446\n",
            "       44.08       0.93      0.95      0.94       348\n",
            "        44.6       0.81      0.83      0.82       742\n",
            "       45.64       0.76      0.83      0.79       338\n",
            "       46.16       0.84      0.82      0.83       464\n",
            "       46.68       0.68      0.64      0.66       426\n",
            "        47.2       0.88      0.91      0.89       871\n",
            "       47.72       0.92      0.94      0.93       775\n",
            "       48.24       0.94      0.94      0.94       709\n",
            "       48.76       0.81      0.78      0.79       617\n",
            "        49.3       0.73      0.78      0.75       631\n",
            "        5.03       0.98      0.97      0.97       267\n",
            "        5.64       0.94      0.97      0.96       505\n",
            "       57.01       0.71      0.65      0.68       455\n",
            "        6.25       0.79      0.72      0.75       339\n",
            "        6.86       0.85      0.87      0.86       255\n",
            "       64.72       0.64      0.68      0.66       420\n",
            "       72.43       0.78      0.83      0.80       312\n",
            "        8.69       0.71      0.66      0.69       189\n",
            "       80.14       0.65      0.38      0.48        92\n",
            "         9.3       0.77      0.82      0.79       805\n",
            "        9.91       0.74      0.68      0.71       466\n",
            "       95.56       0.47      0.40      0.43        75\n",
            "\n",
            "    accuracy                           0.85     32206\n",
            "   macro avg       0.82      0.81      0.81     32206\n",
            "weighted avg       0.85      0.85      0.85     32206\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[649   0   4 ...  21  19   0]\n",
            " [  0  57   0 ...   0   0   0]\n",
            " [  3   0 759 ...   0   0   0]\n",
            " ...\n",
            " [ 38   0   1 ... 658  59   0]\n",
            " [ 22   0   0 ... 108 316   0]\n",
            " [  0   0   0 ...   0   0  30]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8) Gradient boosting Classifier"
      ],
      "metadata": {
        "id": "8Tx17xez9tXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=GradientBoostingClassifier()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20vN8g2r9qHa",
        "outputId": "bebf5792-406d-464c-c752-b7f3c61e231d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.25       0.64      0.65      0.64       189\n",
            "       10.64       0.75      0.86      0.80       805\n",
            "       11.03       0.77      0.60      0.68       466\n",
            "       11.42       0.77      0.81      0.79       781\n",
            "       11.81       0.99      0.98      0.98       775\n",
            "       12.24       0.98      0.99      0.99       889\n",
            "       12.42       0.99      0.99      0.99       677\n",
            "       12.78       0.04      0.71      0.07         7\n",
            "       12.96       0.73      0.73      0.73       463\n",
            "       13.14       0.87      0.85      0.86       365\n",
            "       13.32       0.65      0.73      0.68       548\n",
            "        13.5       0.79      0.62      0.70       840\n",
            "       13.68       0.60      0.54      0.57       660\n",
            "       13.86       0.59      0.63      0.61       552\n",
            "       14.04       0.86      0.77      0.82       587\n",
            "       14.22       0.71      0.66      0.69       550\n",
            "        14.4       0.63      0.68      0.66       540\n",
            "       14.58       0.88      0.90      0.89       209\n",
            "       14.77       0.86      0.80      0.83       629\n",
            "       14.88       0.65      0.74      0.69       571\n",
            "       14.99       0.73      0.76      0.74       380\n",
            "        15.1       0.91      0.91      0.91        11\n",
            "       15.21       0.98      0.93      0.95       111\n",
            "       15.32       0.95      0.93      0.94       163\n",
            "       15.43       0.97      0.96      0.96       371\n",
            "       15.54       0.98      0.95      0.96       678\n",
            "       15.65       0.96      0.97      0.96       836\n",
            "       15.76       0.87      0.88      0.88       780\n",
            "       15.87       0.92      0.93      0.92       681\n",
            "       15.98       0.85      0.84      0.84       729\n",
            "       16.09       0.75      0.89      0.81       722\n",
            "        16.2       0.80      0.81      0.80       683\n",
            "       16.25       0.82      0.78      0.80       562\n",
            "       16.54       0.83      0.70      0.76       125\n",
            "       16.83       0.85      0.80      0.82       378\n",
            "       17.12       0.93      0.93      0.93       446\n",
            "       17.41       0.88      0.91      0.89       348\n",
            "        17.7       0.76      0.84      0.80       742\n",
            "       17.99       0.00      0.00      0.00         0\n",
            "       18.28       0.77      0.81      0.79       338\n",
            "       18.57       0.81      0.84      0.82       464\n",
            "       18.86       0.65      0.57      0.61       426\n",
            "       19.15       0.88      0.93      0.90       871\n",
            "       19.44       0.92      0.95      0.94       775\n",
            "       19.73       0.94      0.95      0.95       709\n",
            "       20.02       0.86      0.71      0.78       617\n",
            "       20.31       0.70      0.79      0.74       631\n",
            "       20.74       0.70      0.65      0.67       455\n",
            "       21.17       0.61      0.73      0.67       420\n",
            "        21.6       0.77      0.84      0.81       312\n",
            "       22.03       0.97      0.37      0.54        92\n",
            "       22.89       0.53      0.37      0.44        75\n",
            "       23.32       0.74      0.50      0.60       109\n",
            "       23.75       0.60      0.72      0.65       127\n",
            "       24.18       0.00      0.00      0.00         2\n",
            "        25.9       0.79      0.83      0.81       114\n",
            "       26.33       0.57      0.43      0.49       260\n",
            "       26.42       0.55      0.36      0.43       279\n",
            "       26.51       0.91      0.92      0.91       534\n",
            "        26.6       0.75      0.79      0.77       112\n",
            "       26.69       0.81      0.77      0.79       110\n",
            "       26.87       0.65      0.60      0.62       109\n",
            "       26.96       0.89      0.84      0.86       265\n",
            "       27.05       0.67      0.63      0.65       190\n",
            "       28.88       0.87      0.98      0.92       181\n",
            "       29.21       0.96      0.94      0.95       668\n",
            "       29.54       0.96      0.89      0.92       240\n",
            "       32.45       0.00      0.00      0.00         0\n",
            "        33.0       1.00      0.40      0.57         5\n",
            "        6.74       0.96      0.96      0.96       611\n",
            "        7.17       0.97      0.98      0.97       642\n",
            "        7.52       0.93      0.62      0.74       248\n",
            "        7.91       0.98      0.95      0.97       267\n",
            "         8.3       0.94      0.97      0.95       505\n",
            "        8.69       0.55      0.55      0.55       339\n",
            "        9.08       0.84      0.85      0.85       255\n",
            "\n",
            "    accuracy                           0.82     32206\n",
            "   macro avg       0.77      0.75      0.75     32206\n",
            "weighted avg       0.82      0.82      0.82     32206\n",
            "\n",
            "The confusion matrix for Fish Length is: [[122  21   7 ...   0   4   2]\n",
            " [ 15 695  31 ...   0   3   9]\n",
            " [  2 136 280 ...   0   9   1]\n",
            " ...\n",
            " [  0   0   0 ... 491   2   0]\n",
            " [ 12  21  13 ...   8 188   2]\n",
            " [  2  22   0 ...   0   4 218]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.52       0.77      0.81      0.79       781\n",
            "      103.27       0.74      0.50      0.60       109\n",
            "       11.13       0.99      0.98      0.98       775\n",
            "        11.7       0.98      0.99      0.99       889\n",
            "      110.98       0.60      0.72      0.65       127\n",
            "      118.69       0.00      0.00      0.00         2\n",
            "       12.98       0.99      0.99      0.99       677\n",
            "      149.53       0.79      0.83      0.81       114\n",
            "       15.54       0.04      0.71      0.07         7\n",
            "       157.3       0.57      0.43      0.49       260\n",
            "      158.15       0.55      0.36      0.43       279\n",
            "       159.0       0.91      0.92      0.91       534\n",
            "      159.85       0.75      0.79      0.77       112\n",
            "       16.82       0.73      0.73      0.73       463\n",
            "       160.7       0.81      0.77      0.79       110\n",
            "       162.4       0.65      0.60      0.62       109\n",
            "      163.25       0.89      0.84      0.86       265\n",
            "       164.1       0.67      0.63      0.65       190\n",
            "        18.1       0.87      0.85      0.86       365\n",
            "       19.38       0.65      0.73      0.68       548\n",
            "       20.66       0.79      0.62      0.70       840\n",
            "      200.52       0.87      0.98      0.92       181\n",
            "      208.35       0.96      0.94      0.95       668\n",
            "       21.94       0.60      0.54      0.57       660\n",
            "      216.18       0.96      0.89      0.92       240\n",
            "       23.22       0.59      0.63      0.61       552\n",
            "        24.5       0.86      0.77      0.81       587\n",
            "       25.78       0.71      0.66      0.69       550\n",
            "       27.06       0.63      0.68      0.66       540\n",
            "       28.34       0.88      0.90      0.89       209\n",
            "      280.96       0.00      0.00      0.00         0\n",
            "        29.6       0.85      0.80      0.83       629\n",
            "      294.92       1.00      0.40      0.57         5\n",
            "         3.2       0.96      0.96      0.96       611\n",
            "        3.81       0.97      0.98      0.97       642\n",
            "       30.49       0.65      0.74      0.69       571\n",
            "       31.38       0.73      0.76      0.74       380\n",
            "       32.27       0.91      0.91      0.91        11\n",
            "       33.16       0.98      0.93      0.95       111\n",
            "       34.05       0.95      0.93      0.94       163\n",
            "       34.94       0.97      0.96      0.96       371\n",
            "       35.83       0.98      0.95      0.96       678\n",
            "       36.72       0.96      0.97      0.96       836\n",
            "       37.61       0.87      0.88      0.88       780\n",
            "        38.5       0.92      0.93      0.92       681\n",
            "       39.39       0.85      0.84      0.84       729\n",
            "        4.42       0.93      0.62      0.74       248\n",
            "       40.28       0.75      0.89      0.81       722\n",
            "       41.11       0.80      0.81      0.80       683\n",
            "        42.0       0.82      0.78      0.80       562\n",
            "       42.52       0.83      0.70      0.76       125\n",
            "       43.04       0.85      0.80      0.82       378\n",
            "       43.56       0.93      0.93      0.93       446\n",
            "       44.08       0.88      0.91      0.89       348\n",
            "        44.6       0.76      0.84      0.80       742\n",
            "       45.12       0.00      0.00      0.00         0\n",
            "       45.64       0.77      0.81      0.79       338\n",
            "       46.16       0.81      0.84      0.82       464\n",
            "       46.68       0.65      0.57      0.61       426\n",
            "        47.2       0.88      0.93      0.90       871\n",
            "       47.72       0.92      0.95      0.94       775\n",
            "       48.24       0.94      0.95      0.95       709\n",
            "       48.76       0.86      0.71      0.78       617\n",
            "        49.3       0.70      0.79      0.74       631\n",
            "        5.03       0.98      0.95      0.97       267\n",
            "        5.64       0.94      0.97      0.95       505\n",
            "       57.01       0.70      0.65      0.67       455\n",
            "        6.25       0.55      0.55      0.55       339\n",
            "        6.86       0.84      0.85      0.85       255\n",
            "       64.72       0.61      0.73      0.67       420\n",
            "       72.43       0.77      0.84      0.81       312\n",
            "        8.69       0.64      0.65      0.64       189\n",
            "       80.14       0.97      0.37      0.54        92\n",
            "         9.3       0.75      0.86      0.80       805\n",
            "        9.91       0.77      0.60      0.68       466\n",
            "       95.56       0.53      0.37      0.44        75\n",
            "\n",
            "    accuracy                           0.82     32206\n",
            "   macro avg       0.77      0.75      0.75     32206\n",
            "weighted avg       0.82      0.82      0.82     32206\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[635   0   0 ...  21  18   0]\n",
            " [  0  55   0 ...   0   0   1]\n",
            " [  3   0 756 ...   1   0   0]\n",
            " ...\n",
            " [ 39   0   2 ... 694  32   0]\n",
            " [ 30   0   0 ... 136 280   0]\n",
            " [  0   0   0 ...   0   0  28]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9) Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "JJMMojwr90YW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=MultinomialNB()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMOTnRG593JT",
        "outputId": "29185b88-1caa-464b-840a-de8908a6f731"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.25       0.00      0.00      0.00       189\n",
            "       10.64       0.00      0.00      0.00       805\n",
            "       11.03       0.00      0.00      0.00       466\n",
            "       11.42       0.88      0.01      0.02       781\n",
            "       11.81       0.08      0.14      0.10       775\n",
            "       12.24       0.07      0.04      0.05       889\n",
            "       12.42       0.00      0.00      0.00       677\n",
            "       12.78       0.00      0.00      0.00         7\n",
            "       12.96       0.00      0.00      0.00       463\n",
            "       13.14       0.00      0.00      0.00       365\n",
            "       13.32       0.00      0.00      0.00       548\n",
            "        13.5       0.13      0.80      0.23       840\n",
            "       13.68       0.00      0.00      0.00       660\n",
            "       13.86       0.00      0.00      0.00       552\n",
            "       14.04       0.00      0.00      0.00       587\n",
            "       14.22       0.00      0.00      0.00       550\n",
            "        14.4       0.00      0.00      0.00       540\n",
            "       14.58       0.00      0.00      0.00       209\n",
            "       14.77       0.00      0.00      0.00       629\n",
            "       14.88       0.11      0.10      0.10       571\n",
            "       14.99       0.00      0.00      0.00       380\n",
            "        15.1       0.00      0.00      0.00        11\n",
            "       15.21       0.00      0.00      0.00       111\n",
            "       15.32       0.00      0.00      0.00       163\n",
            "       15.43       0.00      0.00      0.00       371\n",
            "       15.54       0.44      0.01      0.02       678\n",
            "       15.65       0.04      0.77      0.07       836\n",
            "       15.76       0.00      0.00      0.00       780\n",
            "       15.87       0.00      0.00      0.00       681\n",
            "       15.98       0.00      0.00      0.00       729\n",
            "       16.09       0.00      0.00      0.00       722\n",
            "        16.2       0.00      0.00      0.00       683\n",
            "       16.25       0.00      0.00      0.00       562\n",
            "       16.54       0.00      0.00      0.00       125\n",
            "       16.83       0.00      0.00      0.00       378\n",
            "       17.12       0.00      0.00      0.00       446\n",
            "       17.41       0.00      0.00      0.00       348\n",
            "        17.7       0.00      0.00      0.00       742\n",
            "       18.28       0.00      0.00      0.00       338\n",
            "       18.57       0.00      0.00      0.00       464\n",
            "       18.86       0.00      0.00      0.00       426\n",
            "       19.15       0.05      0.47      0.10       871\n",
            "       19.44       0.00      0.00      0.00       775\n",
            "       19.73       0.00      0.00      0.00       709\n",
            "       20.02       0.00      0.00      0.00       617\n",
            "       20.31       0.00      0.00      0.00       631\n",
            "       20.74       0.00      0.00      0.00       455\n",
            "       21.17       0.00      0.00      0.00       420\n",
            "        21.6       0.00      0.00      0.00       312\n",
            "       22.03       0.00      0.00      0.00        92\n",
            "       22.89       0.00      0.00      0.00        75\n",
            "       23.32       0.00      0.00      0.00       109\n",
            "       23.75       0.00      0.00      0.00       127\n",
            "       24.18       0.00      0.00      0.00         2\n",
            "        25.9       0.00      0.00      0.00       114\n",
            "       26.33       0.00      0.00      0.00       260\n",
            "       26.42       0.00      0.00      0.00       279\n",
            "       26.51       0.00      0.00      0.00       534\n",
            "        26.6       0.00      0.00      0.00       112\n",
            "       26.69       0.00      0.00      0.00       110\n",
            "       26.87       0.00      0.00      0.00       109\n",
            "       26.96       0.00      0.00      0.00       265\n",
            "       27.05       0.00      0.00      0.00       190\n",
            "       28.88       0.00      0.00      0.00       181\n",
            "       29.21       0.00      0.00      0.00       668\n",
            "       29.54       0.00      0.00      0.00       240\n",
            "        33.0       0.00      0.00      0.00         5\n",
            "        6.74       0.19      0.04      0.06       611\n",
            "        7.17       0.23      0.12      0.16       642\n",
            "        7.52       0.00      0.00      0.00       248\n",
            "        7.91       0.00      0.00      0.00       267\n",
            "         8.3       0.00      0.00      0.00       505\n",
            "        8.69       0.00      0.00      0.00       339\n",
            "        9.08       0.00      0.00      0.00       255\n",
            "\n",
            "    accuracy                           0.06     32206\n",
            "   macro avg       0.03      0.03      0.01     32206\n",
            "weighted avg       0.05      0.06      0.02     32206\n",
            "\n",
            "The confusion matrix for Fish Length is: [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.52       0.88      0.01      0.02       781\n",
            "      103.27       0.00      0.00      0.00       109\n",
            "       11.13       0.08      0.14      0.10       775\n",
            "        11.7       0.07      0.04      0.05       889\n",
            "      110.98       0.00      0.00      0.00       127\n",
            "      118.69       0.00      0.00      0.00         2\n",
            "       12.98       0.00      0.00      0.00       677\n",
            "      149.53       0.00      0.00      0.00       114\n",
            "       15.54       0.00      0.00      0.00         7\n",
            "       157.3       0.00      0.00      0.00       260\n",
            "      158.15       0.00      0.00      0.00       279\n",
            "       159.0       0.00      0.00      0.00       534\n",
            "      159.85       0.00      0.00      0.00       112\n",
            "       16.82       0.00      0.00      0.00       463\n",
            "       160.7       0.00      0.00      0.00       110\n",
            "       162.4       0.00      0.00      0.00       109\n",
            "      163.25       0.00      0.00      0.00       265\n",
            "       164.1       0.00      0.00      0.00       190\n",
            "        18.1       0.00      0.00      0.00       365\n",
            "       19.38       0.00      0.00      0.00       548\n",
            "       20.66       0.13      0.80      0.23       840\n",
            "      200.52       0.00      0.00      0.00       181\n",
            "      208.35       0.00      0.00      0.00       668\n",
            "       21.94       0.00      0.00      0.00       660\n",
            "      216.18       0.00      0.00      0.00       240\n",
            "       23.22       0.00      0.00      0.00       552\n",
            "        24.5       0.00      0.00      0.00       587\n",
            "       25.78       0.00      0.00      0.00       550\n",
            "       27.06       0.00      0.00      0.00       540\n",
            "       28.34       0.00      0.00      0.00       209\n",
            "        29.6       0.00      0.00      0.00       629\n",
            "      294.92       0.00      0.00      0.00         5\n",
            "         3.2       0.19      0.04      0.06       611\n",
            "        3.81       0.23      0.12      0.16       642\n",
            "       30.49       0.11      0.10      0.10       571\n",
            "       31.38       0.00      0.00      0.00       380\n",
            "       32.27       0.00      0.00      0.00        11\n",
            "       33.16       0.00      0.00      0.00       111\n",
            "       34.05       0.00      0.00      0.00       163\n",
            "       34.94       0.00      0.00      0.00       371\n",
            "       35.83       0.44      0.01      0.02       678\n",
            "       36.72       0.04      0.77      0.07       836\n",
            "       37.61       0.00      0.00      0.00       780\n",
            "        38.5       0.00      0.00      0.00       681\n",
            "       39.39       0.00      0.00      0.00       729\n",
            "        4.42       0.00      0.00      0.00       248\n",
            "       40.28       0.00      0.00      0.00       722\n",
            "       41.11       0.00      0.00      0.00       683\n",
            "        42.0       0.00      0.00      0.00       562\n",
            "       42.52       0.00      0.00      0.00       125\n",
            "       43.04       0.00      0.00      0.00       378\n",
            "       43.56       0.00      0.00      0.00       446\n",
            "       44.08       0.00      0.00      0.00       348\n",
            "        44.6       0.00      0.00      0.00       742\n",
            "       45.64       0.00      0.00      0.00       338\n",
            "       46.16       0.00      0.00      0.00       464\n",
            "       46.68       0.00      0.00      0.00       426\n",
            "        47.2       0.05      0.47      0.10       871\n",
            "       47.72       0.00      0.00      0.00       775\n",
            "       48.24       0.00      0.00      0.00       709\n",
            "       48.76       0.00      0.00      0.00       617\n",
            "        49.3       0.00      0.00      0.00       631\n",
            "        5.03       0.00      0.00      0.00       267\n",
            "        5.64       0.00      0.00      0.00       505\n",
            "       57.01       0.00      0.00      0.00       455\n",
            "        6.25       0.00      0.00      0.00       339\n",
            "        6.86       0.00      0.00      0.00       255\n",
            "       64.72       0.00      0.00      0.00       420\n",
            "       72.43       0.00      0.00      0.00       312\n",
            "        8.69       0.00      0.00      0.00       189\n",
            "       80.14       0.00      0.00      0.00        92\n",
            "         9.3       0.00      0.00      0.00       805\n",
            "        9.91       0.00      0.00      0.00       466\n",
            "       95.56       0.00      0.00      0.00        75\n",
            "\n",
            "    accuracy                           0.06     32206\n",
            "   macro avg       0.03      0.03      0.01     32206\n",
            "weighted avg       0.05      0.06      0.02     32206\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[  7   0  62 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [  1   0 111 ...   0   0   0]\n",
            " ...\n",
            " [  0   0  55 ...   0   0   0]\n",
            " [  0   0  55 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}