{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "As the initial step, import the required libraries that we require to perform the tasks like preprocessing, training our model and predicting the accuracy score of our model"
      ],
      "metadata": {
        "id": "SEJVYM9qF6VJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0kBcj8l_F0Jq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,precision_score,recall_score,f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the dataset to the simulation software and to view the first 5 rows of our dataset we used head function in pandas dataframe"
      ],
      "metadata": {
        "id": "9uXnvSHtGNwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/aquaponics/IoTPond6.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "eGhTpJvTF4Ze",
        "outputId": "79c48451-b357-4eea-a010-22daa0ac6eb4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                created_at  entry_id  Temperature(C)  Turbidity(NTU)  \\\n",
              "0  2021-06-19 00:01:46 UTC    1972.0         23.5000            30.0   \n",
              "1  2021-06-19 00:02:05 UTC    1973.0         23.5000            29.0   \n",
              "2  2021-06-19 00:05:01 UTC    1982.0         23.4375            29.0   \n",
              "3  2021-06-19 00:10:14 UTC    1998.0         23.4375            30.0   \n",
              "4  2021-06-19 00:35:35 UTC    2072.0         23.4375            30.0   \n",
              "\n",
              "   Dissolved Oxygen(g/ml)       PH  Ammonia(g/ml)  Nitrate(g/ml)  Population  \\\n",
              "0                   0.723  9.02832        5.91560          285.0          75   \n",
              "1                   0.008  8.98746        5.80338          290.0          75   \n",
              "2                   1.365  9.04647        5.65000          302.0          75   \n",
              "3                   0.249  9.06009        5.54304          289.0          75   \n",
              "4                   1.892  9.11910        4.79604          297.0          75   \n",
              "\n",
              "   Fish_Length(cm)  Fish_Weight(g)  \n",
              "0              7.3             3.2  \n",
              "1              7.3             3.2  \n",
              "2              7.3             3.2  \n",
              "3              7.3             3.2  \n",
              "4              7.3             3.2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7e334fa-3c67-4305-a5a6-094af962834d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>entry_id</th>\n",
              "      <th>Temperature(C)</th>\n",
              "      <th>Turbidity(NTU)</th>\n",
              "      <th>Dissolved Oxygen(g/ml)</th>\n",
              "      <th>PH</th>\n",
              "      <th>Ammonia(g/ml)</th>\n",
              "      <th>Nitrate(g/ml)</th>\n",
              "      <th>Population</th>\n",
              "      <th>Fish_Length(cm)</th>\n",
              "      <th>Fish_Weight(g)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-19 00:01:46 UTC</td>\n",
              "      <td>1972.0</td>\n",
              "      <td>23.5000</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.723</td>\n",
              "      <td>9.02832</td>\n",
              "      <td>5.91560</td>\n",
              "      <td>285.0</td>\n",
              "      <td>75</td>\n",
              "      <td>7.3</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-19 00:02:05 UTC</td>\n",
              "      <td>1973.0</td>\n",
              "      <td>23.5000</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.008</td>\n",
              "      <td>8.98746</td>\n",
              "      <td>5.80338</td>\n",
              "      <td>290.0</td>\n",
              "      <td>75</td>\n",
              "      <td>7.3</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-19 00:05:01 UTC</td>\n",
              "      <td>1982.0</td>\n",
              "      <td>23.4375</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1.365</td>\n",
              "      <td>9.04647</td>\n",
              "      <td>5.65000</td>\n",
              "      <td>302.0</td>\n",
              "      <td>75</td>\n",
              "      <td>7.3</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-19 00:10:14 UTC</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>23.4375</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.249</td>\n",
              "      <td>9.06009</td>\n",
              "      <td>5.54304</td>\n",
              "      <td>289.0</td>\n",
              "      <td>75</td>\n",
              "      <td>7.3</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-19 00:35:35 UTC</td>\n",
              "      <td>2072.0</td>\n",
              "      <td>23.4375</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1.892</td>\n",
              "      <td>9.11910</td>\n",
              "      <td>4.79604</td>\n",
              "      <td>297.0</td>\n",
              "      <td>75</td>\n",
              "      <td>7.3</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7e334fa-3c67-4305-a5a6-094af962834d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b7e334fa-3c67-4305-a5a6-094af962834d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b7e334fa-3c67-4305-a5a6-094af962834d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "wb5xOWVoGUov",
        "outputId": "c2cf2f91-fcd3-41ce-8c1d-ec589b809517"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            entry_id  Temperature(C)  Turbidity(NTU)  Dissolved Oxygen(g/ml)  \\\n",
              "count   91015.000000    91015.000000    91015.000000            91015.000000   \n",
              "mean    83546.369038       24.507347       98.293193               10.406378   \n",
              "std     54460.556604        0.940586        6.093063                8.930035   \n",
              "min      1972.000000       22.562500        8.000000                0.007000   \n",
              "25%     31797.500000       23.812500       99.000000                4.401000   \n",
              "50%     77167.000000       24.312500      100.000000                7.497000   \n",
              "75%    143320.500000       25.250000      100.000000               14.225000   \n",
              "max    216075.000000       28.062500      100.000000               44.635000   \n",
              "\n",
              "                 PH  Ammonia(g/ml)  Nitrate(g/ml)  Population  \\\n",
              "count  91015.000000    91015.00000   91015.000000     91050.0   \n",
              "mean       6.192765            inf     931.126660        75.0   \n",
              "std        2.106546            NaN     758.893781         0.0   \n",
              "min       -3.137450        0.00006      89.000000        75.0   \n",
              "25%        5.355890        0.00106     272.000000        75.0   \n",
              "50%        7.167130        5.19490     432.000000        75.0   \n",
              "75%        7.566610       23.48226    1759.000000        75.0   \n",
              "max        9.146340            inf    2871.000000        75.0   \n",
              "\n",
              "       Fish_Length(cm)  Fish_Weight(g)  \n",
              "count     91050.000000    91050.000000  \n",
              "mean         18.605045       89.088857  \n",
              "std           7.872421       87.163953  \n",
              "min           7.300000        3.200000  \n",
              "25%          11.930000       15.800000  \n",
              "50%          17.360000       47.850000  \n",
              "75%          28.740000      205.550000  \n",
              "max          48.690000      786.600000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-522d288b-9aac-4a41-8e7b-23f69e6f1f3d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entry_id</th>\n",
              "      <th>Temperature(C)</th>\n",
              "      <th>Turbidity(NTU)</th>\n",
              "      <th>Dissolved Oxygen(g/ml)</th>\n",
              "      <th>PH</th>\n",
              "      <th>Ammonia(g/ml)</th>\n",
              "      <th>Nitrate(g/ml)</th>\n",
              "      <th>Population</th>\n",
              "      <th>Fish_Length(cm)</th>\n",
              "      <th>Fish_Weight(g)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>91015.000000</td>\n",
              "      <td>91015.000000</td>\n",
              "      <td>91015.000000</td>\n",
              "      <td>91015.000000</td>\n",
              "      <td>91015.000000</td>\n",
              "      <td>91015.00000</td>\n",
              "      <td>91015.000000</td>\n",
              "      <td>91050.0</td>\n",
              "      <td>91050.000000</td>\n",
              "      <td>91050.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>83546.369038</td>\n",
              "      <td>24.507347</td>\n",
              "      <td>98.293193</td>\n",
              "      <td>10.406378</td>\n",
              "      <td>6.192765</td>\n",
              "      <td>inf</td>\n",
              "      <td>931.126660</td>\n",
              "      <td>75.0</td>\n",
              "      <td>18.605045</td>\n",
              "      <td>89.088857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>54460.556604</td>\n",
              "      <td>0.940586</td>\n",
              "      <td>6.093063</td>\n",
              "      <td>8.930035</td>\n",
              "      <td>2.106546</td>\n",
              "      <td>NaN</td>\n",
              "      <td>758.893781</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.872421</td>\n",
              "      <td>87.163953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1972.000000</td>\n",
              "      <td>22.562500</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.007000</td>\n",
              "      <td>-3.137450</td>\n",
              "      <td>0.00006</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>75.0</td>\n",
              "      <td>7.300000</td>\n",
              "      <td>3.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>31797.500000</td>\n",
              "      <td>23.812500</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>4.401000</td>\n",
              "      <td>5.355890</td>\n",
              "      <td>0.00106</td>\n",
              "      <td>272.000000</td>\n",
              "      <td>75.0</td>\n",
              "      <td>11.930000</td>\n",
              "      <td>15.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>77167.000000</td>\n",
              "      <td>24.312500</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>7.497000</td>\n",
              "      <td>7.167130</td>\n",
              "      <td>5.19490</td>\n",
              "      <td>432.000000</td>\n",
              "      <td>75.0</td>\n",
              "      <td>17.360000</td>\n",
              "      <td>47.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>143320.500000</td>\n",
              "      <td>25.250000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>14.225000</td>\n",
              "      <td>7.566610</td>\n",
              "      <td>23.48226</td>\n",
              "      <td>1759.000000</td>\n",
              "      <td>75.0</td>\n",
              "      <td>28.740000</td>\n",
              "      <td>205.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>216075.000000</td>\n",
              "      <td>28.062500</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>44.635000</td>\n",
              "      <td>9.146340</td>\n",
              "      <td>inf</td>\n",
              "      <td>2871.000000</td>\n",
              "      <td>75.0</td>\n",
              "      <td>48.690000</td>\n",
              "      <td>786.600000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-522d288b-9aac-4a41-8e7b-23f69e6f1f3d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-522d288b-9aac-4a41-8e7b-23f69e6f1f3d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-522d288b-9aac-4a41-8e7b-23f69e6f1f3d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check for the null values present in our dataset we use isnull() function\n"
      ],
      "metadata": {
        "id": "dq35dCupGb7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCPOET9CGXZb",
        "outputId": "903db9c0-d326-4ee2-e19c-2f6a7085eb2e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "created_at                 1\n",
              "entry_id                  35\n",
              "Temperature(C)            35\n",
              "Turbidity(NTU)            35\n",
              "Dissolved Oxygen(g/ml)    35\n",
              "PH                        35\n",
              "Ammonia(g/ml)             35\n",
              "Nitrate(g/ml)             35\n",
              "Population                 0\n",
              "Fish_Length(cm)            0\n",
              "Fish_Weight(g)             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Values to be filled with mean values"
      ],
      "metadata": {
        "id": "3QuEVVluGfZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.fillna(df.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpgda1-6Gc_t",
        "outputId": "e7048260-3feb-4b63-85db-c9e65735af7c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-6f8c6f28e805>:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  df=df.fillna(df.mean())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking if the numbers are within limits are having infinite"
      ],
      "metadata": {
        "id": "liy_Fr3hGlZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isin([np.inf,-np.inf]).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1cL_7gzGiS-",
        "outputId": "5f8d62f6-2d68-4f71-8e4e-cd5960ca953d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "created_at                 0\n",
              "entry_id                   0\n",
              "Temperature(C)             0\n",
              "Turbidity(NTU)             0\n",
              "Dissolved Oxygen(g/ml)     0\n",
              "PH                         0\n",
              "Ammonia(g/ml)             47\n",
              "Nitrate(g/ml)              0\n",
              "Population                 0\n",
              "Fish_Length(cm)            0\n",
              "Fish_Weight(g)             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop all those values that are infinite"
      ],
      "metadata": {
        "id": "5nxnyZ2vGrln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df.dropna(axis=0,inplace=True)"
      ],
      "metadata": {
        "id": "bdCJOk1dGoxQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop all the unnecessary columns from the dataset"
      ],
      "metadata": {
        "id": "S-4k7p4_Gxwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(columns='Population')\n",
        "df=df.drop(columns='created_at')\n",
        "df=df.drop(columns='entry_id')"
      ],
      "metadata": {
        "id": "uCj6OMeoGvTw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the datatype of each columns in our dataset"
      ],
      "metadata": {
        "id": "3KyzBp-rG3O-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjUZ091BG0W2",
        "outputId": "08e2206c-0028-44a7-f8c8-a810a7c7927e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 91003 entries, 0 to 91014\n",
            "Data columns (total 8 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   Temperature(C)          91003 non-null  float64\n",
            " 1   Turbidity(NTU)          91003 non-null  float64\n",
            " 2   Dissolved Oxygen(g/ml)  91003 non-null  float64\n",
            " 3   PH                      91003 non-null  float64\n",
            " 4   Ammonia(g/ml)           91003 non-null  float64\n",
            " 5   Nitrate(g/ml)           91003 non-null  float64\n",
            " 6   Fish_Length(cm)         91003 non-null  float64\n",
            " 7   Fish_Weight(g)          91003 non-null  float64\n",
            "dtypes: float64(8)\n",
            "memory usage: 6.2 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that our classifications labels fish_length and fish_weight are in float variables and we need to convert them to string."
      ],
      "metadata": {
        "id": "Y3afmJqiG84y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.astype({\"Fish_Length(cm)\":'str',\"Fish_Weight(g)\":'str'})"
      ],
      "metadata": {
        "id": "GEPegscfG6JQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the corelation between the input variables"
      ],
      "metadata": {
        "id": "z-v-RPLBHDfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "1MhMjRlcG_Nd",
        "outputId": "114c4d39-4ce0-4821-9a55-8a188d12e6d3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Temperature(C)  Turbidity(NTU)  \\\n",
              "Temperature(C)                1.000000        0.065500   \n",
              "Turbidity(NTU)                0.065500        1.000000   \n",
              "Dissolved Oxygen(g/ml)       -0.074465       -0.154460   \n",
              "PH                           -0.494586       -0.168569   \n",
              "Ammonia(g/ml)                -0.280515       -0.170962   \n",
              "Nitrate(g/ml)                 0.420206        0.167986   \n",
              "\n",
              "                        Dissolved Oxygen(g/ml)        PH  Ammonia(g/ml)  \\\n",
              "Temperature(C)                       -0.074465 -0.494586      -0.280515   \n",
              "Turbidity(NTU)                       -0.154460 -0.168569      -0.170962   \n",
              "Dissolved Oxygen(g/ml)                1.000000  0.321131       0.134420   \n",
              "PH                                    0.321131  1.000000       0.379722   \n",
              "Ammonia(g/ml)                         0.134420  0.379722       1.000000   \n",
              "Nitrate(g/ml)                        -0.321572 -0.750934      -0.513649   \n",
              "\n",
              "                        Nitrate(g/ml)  \n",
              "Temperature(C)               0.420206  \n",
              "Turbidity(NTU)               0.167986  \n",
              "Dissolved Oxygen(g/ml)      -0.321572  \n",
              "PH                          -0.750934  \n",
              "Ammonia(g/ml)               -0.513649  \n",
              "Nitrate(g/ml)                1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9daedef2-575c-47bb-b36d-da5454d556bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temperature(C)</th>\n",
              "      <th>Turbidity(NTU)</th>\n",
              "      <th>Dissolved Oxygen(g/ml)</th>\n",
              "      <th>PH</th>\n",
              "      <th>Ammonia(g/ml)</th>\n",
              "      <th>Nitrate(g/ml)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Temperature(C)</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.065500</td>\n",
              "      <td>-0.074465</td>\n",
              "      <td>-0.494586</td>\n",
              "      <td>-0.280515</td>\n",
              "      <td>0.420206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Turbidity(NTU)</th>\n",
              "      <td>0.065500</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.154460</td>\n",
              "      <td>-0.168569</td>\n",
              "      <td>-0.170962</td>\n",
              "      <td>0.167986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dissolved Oxygen(g/ml)</th>\n",
              "      <td>-0.074465</td>\n",
              "      <td>-0.154460</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.321131</td>\n",
              "      <td>0.134420</td>\n",
              "      <td>-0.321572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PH</th>\n",
              "      <td>-0.494586</td>\n",
              "      <td>-0.168569</td>\n",
              "      <td>0.321131</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.379722</td>\n",
              "      <td>-0.750934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ammonia(g/ml)</th>\n",
              "      <td>-0.280515</td>\n",
              "      <td>-0.170962</td>\n",
              "      <td>0.134420</td>\n",
              "      <td>0.379722</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.513649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nitrate(g/ml)</th>\n",
              "      <td>0.420206</td>\n",
              "      <td>0.167986</td>\n",
              "      <td>-0.321572</td>\n",
              "      <td>-0.750934</td>\n",
              "      <td>-0.513649</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9daedef2-575c-47bb-b36d-da5454d556bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9daedef2-575c-47bb-b36d-da5454d556bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9daedef2-575c-47bb-b36d-da5454d556bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=df.drop(columns=['Fish_Length(cm)','Fish_Weight(g)'])\n",
        "y=df.drop(columns=['Temperature(C)','Turbidity(NTU)','Dissolved Oxygen(g/ml)','PH','Ammonia(g/ml)','Nitrate(g/ml)'])\n",
        "y1=y['Fish_Length(cm)']\n",
        "y2=y['Fish_Weight(g)']"
      ],
      "metadata": {
        "id": "8tg30VkUHGsx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y1 corresponds to the model for fish length label and Y2 corresponds to the model for fish weight label. Splitting the data for training and testing\n"
      ],
      "metadata": {
        "id": "rWqCSF4LHLJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,Y1_train,Y1_test=train_test_split(x,y1,test_size=0.2,random_state=0)\n",
        "X_train,X_test,Y2_train,Y2_test=train_test_split(x,y2,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "86ukUWDTHJA_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling of input data"
      ],
      "metadata": {
        "id": "TZ7JrFKBZGUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "nIrG_glBZD9m"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Logistic Regression"
      ],
      "metadata": {
        "id": "xJ2uEWDSHQ_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=LogisticRegression(multi_class='multinomial')\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt8wxCx4HNfI",
        "outputId": "932a2e1d-9df9-4830-f767-76987e4b9062"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.06       0.15      0.47      0.23       671\n",
            "       11.93       0.12      0.38      0.18       505\n",
            "        12.3       0.23      0.61      0.33       389\n",
            "       12.67       0.00      0.00      0.00         3\n",
            "       13.04       0.00      0.00      0.00       266\n",
            "       13.41       0.00      0.00      0.00       138\n",
            "       13.78       0.00      0.00      0.00       190\n",
            "       14.45       0.17      0.02      0.03       319\n",
            "       14.82       0.00      0.00      0.00       301\n",
            "       15.19       0.00      0.00      0.00       256\n",
            "       15.56       0.00      0.00      0.00       358\n",
            "       15.93       0.00      0.00      0.00       308\n",
            "        16.3       0.00      0.00      0.00       206\n",
            "       16.67       0.00      0.00      0.00        89\n",
            "       17.04       0.35      0.19      0.25       217\n",
            "       17.12       0.00      0.00      0.00       182\n",
            "        17.2       0.35      0.24      0.29       385\n",
            "       17.28       0.27      0.48      0.35       387\n",
            "       17.36       0.51      0.89      0.64       631\n",
            "       17.44       0.55      0.84      0.67       596\n",
            "       17.52       0.08      0.01      0.02       325\n",
            "        17.6       0.54      0.82      0.65       382\n",
            "       17.68       0.71      0.13      0.23       275\n",
            "       17.76       0.00      0.00      0.00        63\n",
            "       17.84       0.00      0.00      0.00        35\n",
            "       17.92       0.57      0.27      0.36        15\n",
            "        18.0       0.83      0.33      0.48        15\n",
            "       18.08       0.64      0.16      0.26       241\n",
            "       18.14       0.77      0.35      0.49       234\n",
            "       18.51       0.00      0.00      0.00         3\n",
            "       19.52       0.00      0.00      0.00         6\n",
            "       19.89       0.00      0.00      0.00        28\n",
            "       20.53       0.00      0.00      0.00         9\n",
            "        20.9       0.00      0.00      0.00        13\n",
            "       21.27       0.00      0.00      0.00        63\n",
            "       21.64       0.00      0.00      0.00        19\n",
            "       22.01       0.00      0.00      0.00         6\n",
            "       22.38       0.00      0.00      0.00        18\n",
            "       22.75       0.00      0.00      0.00        39\n",
            "       23.33       0.00      0.00      0.00         5\n",
            "       23.42       0.48      0.80      0.60       417\n",
            "       23.51       0.57      0.97      0.72       474\n",
            "        23.6       0.70      0.83      0.76       300\n",
            "       23.69       0.33      0.11      0.16        56\n",
            "       23.96       0.00      0.00      0.00         4\n",
            "       24.05       0.00      0.00      0.00        60\n",
            "       24.53       0.00      0.00      0.00        31\n",
            "       24.76       0.00      0.00      0.00        49\n",
            "       24.99       0.49      0.90      0.63        98\n",
            "       25.32       0.00      0.00      0.00        19\n",
            "       25.55       0.00      0.00      0.00        33\n",
            "       25.78       0.28      0.39      0.33        56\n",
            "       26.01       0.00      0.00      0.00        65\n",
            "       28.55       0.42      0.04      0.07       124\n",
            "       28.74       0.55      0.69      0.61       633\n",
            "       28.93       0.20      0.09      0.12       596\n",
            "       29.12       0.58      0.72      0.64       863\n",
            "       29.31       0.60      0.70      0.65       838\n",
            "        29.5       0.58      0.67      0.62       574\n",
            "       29.69       0.82      0.90      0.86       592\n",
            "       29.88       0.76      0.85      0.80       380\n",
            "       30.07       0.00      0.00      0.00        19\n",
            "       30.26       0.00      0.00      0.00        26\n",
            "       30.46       0.00      0.00      0.00        28\n",
            "       30.58       0.00      0.00      0.00        21\n",
            "       30.77       0.00      0.00      0.00        22\n",
            "       30.89       0.00      0.00      0.00        15\n",
            "       31.01       0.00      0.00      0.00        11\n",
            "       31.13       0.00      0.00      0.00        24\n",
            "       31.25       0.00      0.00      0.00        15\n",
            "       31.37       0.00      0.00      0.00         5\n",
            "       31.49       0.00      0.00      0.00         2\n",
            "       31.61       0.00      0.00      0.00         7\n",
            "       31.73       0.00      0.00      0.00         7\n",
            "       32.12       0.00      0.00      0.00         9\n",
            "       32.33       0.00      0.00      0.00         6\n",
            "       32.37       0.60      0.24      0.35        37\n",
            "         7.3       0.82      0.62      0.71       330\n",
            "        7.36       0.58      0.97      0.73       637\n",
            "        7.69       0.00      0.00      0.00       176\n",
            "        7.72       0.30      0.02      0.04       281\n",
            "        8.05       0.22      0.25      0.24       486\n",
            "        8.38       0.13      0.01      0.03       274\n",
            "        8.41       0.00      0.00      0.00       240\n",
            "        8.74       0.00      0.00      0.00        32\n",
            "        9.07       0.31      0.06      0.10       258\n",
            "         9.4       0.05      0.04      0.05       349\n",
            "        9.73       0.06      0.01      0.02       431\n",
            "\n",
            "    accuracy                           0.42     18201\n",
            "   macro avg       0.20      0.19      0.17     18201\n",
            "weighted avg       0.35      0.42      0.36     18201\n",
            "\n",
            "The confusion matrix for Fish Length is: [[315  98   0 ...  12  18   1]\n",
            " [ 97 191  71 ...   0   4   0]\n",
            " [ 20  33 236 ...   5  22   1]\n",
            " ...\n",
            " [ 17 127  20 ...  15  29   8]\n",
            " [115  80  67 ...   3  14  31]\n",
            " [189 144  14 ...   0  13   4]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "        10.5       0.05      0.04      0.05       349\n",
            "       103.4       0.00      0.00      0.00        19\n",
            "      107.53       0.00      0.00      0.00         6\n",
            "        11.4       0.06      0.01      0.02       431\n",
            "      110.66       0.00      0.00      0.00        18\n",
            "      114.79       0.00      0.00      0.00        39\n",
            "       118.0       0.00      0.00      0.00         5\n",
            "      118.66       0.48      0.80      0.60       417\n",
            "      119.32       0.57      0.97      0.72       474\n",
            "      119.98       0.70      0.83      0.76       300\n",
            "        12.3       0.15      0.47      0.23       671\n",
            "      120.64       0.33      0.11      0.16        56\n",
            "      122.58       0.00      0.00      0.00         4\n",
            "      123.24       0.00      0.00      0.00        60\n",
            "       127.2       0.00      0.00      0.00        31\n",
            "      130.98       0.00      0.00      0.00        49\n",
            "      134.76       0.49      0.90      0.63        98\n",
            "      138.54       0.00      0.00      0.00        19\n",
            "      142.32       0.00      0.00      0.00        33\n",
            "       146.1       0.28      0.39      0.33        56\n",
            "      149.88       0.00      0.00      0.00        65\n",
            "        15.8       0.12      0.38      0.18       505\n",
            "       17.68       0.23      0.61      0.33       389\n",
            "       19.56       0.00      0.00      0.00         3\n",
            "      200.46       0.42      0.04      0.07       124\n",
            "      205.55       0.55      0.69      0.61       633\n",
            "       21.44       0.00      0.00      0.00       266\n",
            "      210.64       0.20      0.09      0.12       596\n",
            "      215.73       0.58      0.72      0.64       863\n",
            "      220.82       0.60      0.70      0.65       838\n",
            "      225.91       0.58      0.67      0.62       574\n",
            "       23.32       0.00      0.00      0.00       138\n",
            "       231.0       0.82      0.90      0.86       592\n",
            "      236.09       0.76      0.85      0.80       380\n",
            "      241.18       0.00      0.00      0.00        19\n",
            "      246.27       0.00      0.00      0.00        26\n",
            "        25.2       0.00      0.00      0.00       190\n",
            "       251.4       0.00      0.00      0.00        28\n",
            "       253.9       0.00      0.00      0.00        21\n",
            "       256.4       0.00      0.00      0.00        22\n",
            "       258.9       0.00      0.00      0.00        15\n",
            "       261.4       0.00      0.00      0.00        11\n",
            "       263.9       0.00      0.00      0.00        24\n",
            "       266.4       0.00      0.00      0.00        15\n",
            "       268.9       0.00      0.00      0.00         5\n",
            "       27.08       0.17      0.02      0.03       319\n",
            "       271.4       0.00      0.00      0.00         2\n",
            "       273.9       0.00      0.00      0.00         7\n",
            "       276.4       0.00      0.00      0.00         7\n",
            "       28.96       0.00      0.00      0.00       301\n",
            "       286.4       0.00      0.00      0.00         9\n",
            "      295.58       0.60      0.24      0.35        37\n",
            "         3.2       0.82      0.62      0.71       330\n",
            "         3.3       0.58      0.97      0.73       637\n",
            "       30.84       0.00      0.00      0.00       256\n",
            "      304.76       0.00      0.00      0.00         6\n",
            "       32.72       0.00      0.00      0.00       358\n",
            "        34.6       0.00      0.00      0.00       308\n",
            "       36.48       0.00      0.00      0.00       206\n",
            "       38.36       0.00      0.00      0.00        89\n",
            "         4.2       0.00      0.00      0.00       176\n",
            "        42.1       0.35      0.19      0.25       217\n",
            "       43.39       0.00      0.00      0.00       182\n",
            "       45.27       0.35      0.24      0.29       385\n",
            "       46.56       0.27      0.48      0.35       387\n",
            "       47.85       0.51      0.89      0.64       631\n",
            "       49.14       0.55      0.84      0.67       596\n",
            "       49.43       0.08      0.01      0.02       325\n",
            "         5.1       0.30      0.02      0.04       281\n",
            "       51.72       0.54      0.82      0.65       382\n",
            "       53.01       0.71      0.13      0.23       275\n",
            "        54.3       0.00      0.00      0.00        63\n",
            "       55.59       0.00      0.00      0.00        35\n",
            "       56.88       0.57      0.27      0.36        15\n",
            "       58.17       0.83      0.33      0.48        15\n",
            "       59.46       0.64      0.16      0.26       241\n",
            "         6.0       0.22      0.25      0.24       486\n",
            "         6.9       0.13      0.01      0.03       274\n",
            "        60.2       0.77      0.35      0.49       234\n",
            "       64.33       0.00      0.00      0.00         3\n",
            "         7.8       0.00      0.00      0.00       240\n",
            "       76.72       0.00      0.00      0.00         6\n",
            "         8.7       0.00      0.00      0.00        32\n",
            "       80.85       0.00      0.00      0.00        28\n",
            "       89.01       0.00      0.00      0.00         9\n",
            "         9.6       0.31      0.06      0.10       258\n",
            "       93.14       0.00      0.00      0.00        13\n",
            "       97.27       0.00      0.00      0.00        63\n",
            "\n",
            "    accuracy                           0.42     18201\n",
            "   macro avg       0.20      0.19      0.17     18201\n",
            "weighted avg       0.35      0.42      0.36     18201\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[14  0  0 ...  3  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " ...\n",
            " [29  0  0 ... 15  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Decision Tree Classifier"
      ],
      "metadata": {
        "id": "afHIm9mIHTar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=DecisionTreeClassifier()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t84T2WoZHVmN",
        "outputId": "0d2049c4-c718-49c8-fec1-774292d0c042"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.06       0.95      0.95      0.95       671\n",
            "       11.93       0.93      0.91      0.92       505\n",
            "        12.3       0.90      0.92      0.91       389\n",
            "       12.67       0.33      0.67      0.44         3\n",
            "       13.04       0.96      0.96      0.96       266\n",
            "       13.41       0.85      0.85      0.85       138\n",
            "       13.78       0.71      0.75      0.73       190\n",
            "       14.45       0.82      0.80      0.81       319\n",
            "       14.82       0.79      0.78      0.79       301\n",
            "       15.19       0.79      0.80      0.80       256\n",
            "       15.56       0.91      0.87      0.89       358\n",
            "       15.93       0.87      0.84      0.86       308\n",
            "        16.3       0.76      0.79      0.77       206\n",
            "       16.67       0.98      0.98      0.98        89\n",
            "       17.04       0.93      0.96      0.95       217\n",
            "       17.12       0.95      0.88      0.91       182\n",
            "        17.2       0.94      0.93      0.94       385\n",
            "       17.28       0.93      0.96      0.94       387\n",
            "       17.36       0.99      0.97      0.98       631\n",
            "       17.44       0.97      0.98      0.97       596\n",
            "       17.52       0.98      0.96      0.97       325\n",
            "        17.6       0.98      0.99      0.98       382\n",
            "       17.68       0.98      0.99      0.99       275\n",
            "       17.76       1.00      0.92      0.96        63\n",
            "       17.84       0.80      1.00      0.89        35\n",
            "       17.92       0.92      0.80      0.86        15\n",
            "        18.0       0.83      1.00      0.91        15\n",
            "       18.08       0.99      0.97      0.98       241\n",
            "       18.14       0.99      1.00      0.99       234\n",
            "       18.51       1.00      1.00      1.00         3\n",
            "       19.52       1.00      1.00      1.00         6\n",
            "       19.89       0.96      0.96      0.96        28\n",
            "       20.53       0.90      1.00      0.95         9\n",
            "        20.9       1.00      0.92      0.96        13\n",
            "       21.27       0.98      1.00      0.99        63\n",
            "       21.64       0.95      1.00      0.97        19\n",
            "       22.01       0.83      0.83      0.83         6\n",
            "       22.38       1.00      0.94      0.97        18\n",
            "       22.75       0.95      0.95      0.95        39\n",
            "       23.33       0.75      0.60      0.67         5\n",
            "       23.42       0.98      0.99      0.98       417\n",
            "       23.51       0.96      0.97      0.97       474\n",
            "        23.6       0.98      0.93      0.95       300\n",
            "       23.69       0.89      0.98      0.93        56\n",
            "       23.96       0.75      0.75      0.75         4\n",
            "       24.05       0.98      1.00      0.99        60\n",
            "       24.53       0.91      0.97      0.94        31\n",
            "       24.76       0.85      0.80      0.82        49\n",
            "       24.99       0.90      0.89      0.89        98\n",
            "       25.32       0.84      0.84      0.84        19\n",
            "       25.55       0.94      0.91      0.92        33\n",
            "       25.78       0.98      0.96      0.97        56\n",
            "       26.01       0.91      0.95      0.93        65\n",
            "       28.55       0.92      0.98      0.95       124\n",
            "       28.74       0.96      0.93      0.95       633\n",
            "       28.93       0.97      0.97      0.97       596\n",
            "       29.12       0.96      0.97      0.96       863\n",
            "       29.31       0.96      0.97      0.97       838\n",
            "        29.5       0.96      0.97      0.96       574\n",
            "       29.69       0.98      0.99      0.99       592\n",
            "       29.88       0.98      0.98      0.98       380\n",
            "       30.07       0.58      0.58      0.58        19\n",
            "       30.26       0.76      0.62      0.68        26\n",
            "       30.46       0.96      0.96      0.96        28\n",
            "       30.58       0.94      0.76      0.84        21\n",
            "       30.77       0.75      0.82      0.78        22\n",
            "       30.89       0.80      0.80      0.80        15\n",
            "       31.01       1.00      0.73      0.84        11\n",
            "       31.13       0.89      0.67      0.76        24\n",
            "       31.25       0.76      0.87      0.81        15\n",
            "       31.37       0.83      1.00      0.91         5\n",
            "       31.49       0.20      0.50      0.29         2\n",
            "       31.61       0.50      0.71      0.59         7\n",
            "       31.73       1.00      0.71      0.83         7\n",
            "       32.12       1.00      0.78      0.88         9\n",
            "       32.33       0.86      1.00      0.92         6\n",
            "       32.37       1.00      0.92      0.96        37\n",
            "         7.3       0.94      0.96      0.95       330\n",
            "        7.36       0.97      0.97      0.97       637\n",
            "        7.69       0.98      0.97      0.97       176\n",
            "        7.72       0.96      0.94      0.95       281\n",
            "        8.05       0.94      0.97      0.96       486\n",
            "        8.38       0.94      0.88      0.91       274\n",
            "        8.41       0.96      0.97      0.97       240\n",
            "        8.74       0.82      0.84      0.83        32\n",
            "        9.07       0.87      0.88      0.87       258\n",
            "         9.4       0.83      0.87      0.84       349\n",
            "        9.73       0.94      0.91      0.93       431\n",
            "\n",
            "    accuracy                           0.94     18201\n",
            "   macro avg       0.89      0.89      0.89     18201\n",
            "weighted avg       0.94      0.94      0.94     18201\n",
            "\n",
            "The confusion matrix for Fish Length is: [[635   8   2 ...   1  12   7]\n",
            " [  6 462   7 ...   6  13   7]\n",
            " [  0   6 357 ...  10  15   0]\n",
            " ...\n",
            " [  2   8  12 ... 227   6   2]\n",
            " [  9  10  14 ...   5 302   4]\n",
            " [ 13   1   3 ...   3   7 392]]\n",
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "        10.5       0.84      0.87      0.85       349\n",
            "       103.4       0.95      1.00      0.97        19\n",
            "      107.53       0.83      0.83      0.83         6\n",
            "        11.4       0.94      0.91      0.92       431\n",
            "      110.66       1.00      0.94      0.97        18\n",
            "      114.79       0.95      0.95      0.95        39\n",
            "       118.0       1.00      0.60      0.75         5\n",
            "      118.66       0.98      0.99      0.98       417\n",
            "      119.32       0.96      0.98      0.97       474\n",
            "      119.98       0.98      0.93      0.96       300\n",
            "        12.3       0.95      0.94      0.95       671\n",
            "      120.64       0.90      0.98      0.94        56\n",
            "      122.58       0.75      0.75      0.75         4\n",
            "      123.24       0.97      1.00      0.98        60\n",
            "       127.2       0.85      0.90      0.88        31\n",
            "      130.98       0.84      0.78      0.81        49\n",
            "      134.76       0.91      0.90      0.90        98\n",
            "      138.54       0.80      0.84      0.82        19\n",
            "      142.32       0.91      0.94      0.93        33\n",
            "       146.1       0.96      0.96      0.96        56\n",
            "      149.88       0.94      0.94      0.94        65\n",
            "        15.8       0.93      0.92      0.93       505\n",
            "       17.68       0.90      0.92      0.91       389\n",
            "       19.56       0.33      0.67      0.44         3\n",
            "      200.46       0.94      0.98      0.96       124\n",
            "      205.55       0.96      0.93      0.95       633\n",
            "       21.44       0.95      0.96      0.96       266\n",
            "      210.64       0.97      0.97      0.97       596\n",
            "      215.73       0.95      0.97      0.96       863\n",
            "      220.82       0.97      0.97      0.97       838\n",
            "      225.91       0.96      0.97      0.96       574\n",
            "       23.32       0.85      0.86      0.86       138\n",
            "       231.0       0.99      0.99      0.99       592\n",
            "      236.09       0.98      0.98      0.98       380\n",
            "      241.18       0.63      0.63      0.63        19\n",
            "      246.27       0.78      0.69      0.73        26\n",
            "        25.2       0.73      0.73      0.73       190\n",
            "       251.4       0.96      0.96      0.96        28\n",
            "       253.9       1.00      0.71      0.83        21\n",
            "       256.4       0.79      0.86      0.83        22\n",
            "       258.9       0.72      0.87      0.79        15\n",
            "       261.4       1.00      0.73      0.84        11\n",
            "       263.9       0.95      0.75      0.84        24\n",
            "       266.4       0.59      0.87      0.70        15\n",
            "       268.9       1.00      1.00      1.00         5\n",
            "       27.08       0.80      0.82      0.81       319\n",
            "       271.4       0.00      0.00      0.00         2\n",
            "       273.9       0.45      0.71      0.56         7\n",
            "       276.4       1.00      0.71      0.83         7\n",
            "       28.96       0.81      0.79      0.80       301\n",
            "       286.4       1.00      0.78      0.88         9\n",
            "      295.58       1.00      0.92      0.96        37\n",
            "         3.2       0.95      0.97      0.96       330\n",
            "         3.3       0.97      0.97      0.97       637\n",
            "       30.84       0.78      0.80      0.79       256\n",
            "      304.76       0.86      1.00      0.92         6\n",
            "       32.72       0.90      0.86      0.88       358\n",
            "        34.6       0.87      0.83      0.85       308\n",
            "       36.48       0.74      0.78      0.76       206\n",
            "       38.36       0.98      0.97      0.97        89\n",
            "         4.2       0.98      0.97      0.98       176\n",
            "        42.1       0.95      0.98      0.96       217\n",
            "       43.39       0.93      0.88      0.91       182\n",
            "       45.27       0.95      0.94      0.94       385\n",
            "       46.56       0.91      0.96      0.93       387\n",
            "       47.85       0.99      0.97      0.98       631\n",
            "       49.14       0.97      0.98      0.98       596\n",
            "       49.43       0.97      0.96      0.96       325\n",
            "         5.1       0.95      0.94      0.94       281\n",
            "       51.72       0.99      0.99      0.99       382\n",
            "       53.01       0.98      1.00      0.99       275\n",
            "        54.3       0.98      0.89      0.93        63\n",
            "       55.59       0.73      1.00      0.84        35\n",
            "       56.88       1.00      0.80      0.89        15\n",
            "       58.17       1.00      1.00      1.00        15\n",
            "       59.46       0.99      0.96      0.98       241\n",
            "         6.0       0.95      0.97      0.96       486\n",
            "         6.9       0.94      0.89      0.91       274\n",
            "        60.2       0.98      1.00      0.99       234\n",
            "       64.33       1.00      1.00      1.00         3\n",
            "         7.8       0.98      0.98      0.98       240\n",
            "       76.72       1.00      1.00      1.00         6\n",
            "         8.7       0.93      0.81      0.87        32\n",
            "       80.85       0.96      0.96      0.96        28\n",
            "       89.01       0.90      1.00      0.95         9\n",
            "         9.6       0.86      0.88      0.87       258\n",
            "       93.14       1.00      0.92      0.96        13\n",
            "       97.27       0.98      1.00      0.99        63\n",
            "\n",
            "    accuracy                           0.94     18201\n",
            "   macro avg       0.90      0.89      0.89     18201\n",
            "weighted avg       0.94      0.94      0.94     18201\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[303   0   0 ...   7   0   0]\n",
            " [  0  19   0 ...   0   0   0]\n",
            " [  0   0   5 ...   0   0   0]\n",
            " ...\n",
            " [  6   0   0 ... 227   0   0]\n",
            " [  0   0   0 ...   0  12   0]\n",
            " [  0   0   0 ...   0   0  63]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Support Vector Machines"
      ],
      "metadata": {
        "id": "3EaqowSNHdUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=SVC()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKTnEovVHZfr",
        "outputId": "ab201fa7-adb6-46ef-ccd0-d02e67f52371"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.06       0.33      0.72      0.45       671\n",
            "       11.93       0.28      0.58      0.37       505\n",
            "        12.3       0.40      0.68      0.50       389\n",
            "       12.67       0.00      0.00      0.00         3\n",
            "       13.04       0.20      0.09      0.13       266\n",
            "       13.41       1.00      0.01      0.03       138\n",
            "       13.78       0.00      0.00      0.00       190\n",
            "       14.45       0.22      0.41      0.28       319\n",
            "       14.82       0.18      0.33      0.24       301\n",
            "       15.19       0.20      0.07      0.11       256\n",
            "       15.56       0.59      0.37      0.45       358\n",
            "       15.93       0.73      0.44      0.55       308\n",
            "        16.3       0.00      0.00      0.00       206\n",
            "       16.67       1.00      0.70      0.82        89\n",
            "       17.04       0.00      0.00      0.00       217\n",
            "       17.12       0.00      0.00      0.00       182\n",
            "        17.2       0.59      0.34      0.43       385\n",
            "       17.28       0.64      0.82      0.72       387\n",
            "       17.36       0.90      0.91      0.91       631\n",
            "       17.44       0.89      0.90      0.89       596\n",
            "       17.52       0.95      0.57      0.71       325\n",
            "        17.6       0.91      0.80      0.85       382\n",
            "       17.68       0.55      0.91      0.68       275\n",
            "       17.76       0.50      0.02      0.03        63\n",
            "       17.84       0.90      0.51      0.65        35\n",
            "       17.92       0.50      0.07      0.12        15\n",
            "        18.0       0.47      0.93      0.62        15\n",
            "       18.08       0.76      0.81      0.78       241\n",
            "       18.14       0.87      0.71      0.78       234\n",
            "       18.51       0.00      0.00      0.00         3\n",
            "       19.52       0.00      0.00      0.00         6\n",
            "       19.89       0.00      0.00      0.00        28\n",
            "       20.53       0.00      0.00      0.00         9\n",
            "        20.9       0.00      0.00      0.00        13\n",
            "       21.27       0.52      0.95      0.67        63\n",
            "       21.64       0.84      0.84      0.84        19\n",
            "       22.01       0.00      0.00      0.00         6\n",
            "       22.38       0.00      0.00      0.00        18\n",
            "       22.75       0.83      0.49      0.61        39\n",
            "       23.33       0.00      0.00      0.00         5\n",
            "       23.42       0.76      0.96      0.85       417\n",
            "       23.51       0.89      0.90      0.89       474\n",
            "        23.6       0.91      0.87      0.89       300\n",
            "       23.69       0.85      0.82      0.84        56\n",
            "       23.96       0.00      0.00      0.00         4\n",
            "       24.05       0.97      0.98      0.98        60\n",
            "       24.53       0.00      0.00      0.00        31\n",
            "       24.76       0.00      0.00      0.00        49\n",
            "       24.99       0.51      0.94      0.66        98\n",
            "       25.32       0.00      0.00      0.00        19\n",
            "       25.55       0.00      0.00      0.00        33\n",
            "       25.78       0.55      0.66      0.60        56\n",
            "       26.01       0.37      0.55      0.44        65\n",
            "       28.55       0.77      0.71      0.74       124\n",
            "       28.74       0.83      0.73      0.78       633\n",
            "       28.93       0.52      0.68      0.59       596\n",
            "       29.12       0.83      0.78      0.81       863\n",
            "       29.31       0.83      0.74      0.78       838\n",
            "        29.5       0.73      0.88      0.80       574\n",
            "       29.69       0.88      0.93      0.91       592\n",
            "       29.88       0.89      0.93      0.91       380\n",
            "       30.07       0.00      0.00      0.00        19\n",
            "       30.26       0.48      0.42      0.45        26\n",
            "       30.46       0.90      0.64      0.75        28\n",
            "       30.58       0.48      0.48      0.48        21\n",
            "       30.77       0.14      0.09      0.11        22\n",
            "       30.89       0.00      0.00      0.00        15\n",
            "       31.01       0.61      1.00      0.76        11\n",
            "       31.13       1.00      0.38      0.55        24\n",
            "       31.25       0.00      0.00      0.00        15\n",
            "       31.37       0.00      0.00      0.00         5\n",
            "       31.49       0.00      0.00      0.00         2\n",
            "       31.61       0.00      0.00      0.00         7\n",
            "       31.73       0.00      0.00      0.00         7\n",
            "       32.12       1.00      0.33      0.50         9\n",
            "       32.33       0.00      0.00      0.00         6\n",
            "       32.37       0.86      0.97      0.91        37\n",
            "         7.3       0.93      0.84      0.88       330\n",
            "        7.36       0.82      0.97      0.89       637\n",
            "        7.69       1.00      0.52      0.68       176\n",
            "        7.72       0.42      0.84      0.56       281\n",
            "        8.05       0.56      0.82      0.66       486\n",
            "        8.38       0.00      0.00      0.00       274\n",
            "        8.41       0.00      0.00      0.00       240\n",
            "        8.74       0.00      0.00      0.00        32\n",
            "        9.07       0.57      0.14      0.22       258\n",
            "         9.4       0.10      0.09      0.10       349\n",
            "        9.73       0.40      0.10      0.16       431\n",
            "\n",
            "    accuracy                           0.62     18201\n",
            "   macro avg       0.44      0.42      0.40     18201\n",
            "weighted avg       0.61      0.62      0.59     18201\n",
            "\n",
            "The confusion matrix for Fish Length is: [[482  95   1 ...   1  35   3]\n",
            " [110 293  43 ...   0  13   4]\n",
            " [ 15  39 265 ...   5  28   8]\n",
            " ...\n",
            " [ 20  46  20 ...  36  71   6]\n",
            " [ 76  80  59 ...   2  32  25]\n",
            " [182 112   9 ...   0  27  42]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "        10.5       0.10      0.12      0.11       349\n",
            "       103.4       0.84      0.84      0.84        19\n",
            "      107.53       0.00      0.00      0.00         6\n",
            "        11.4       0.34      0.10      0.15       431\n",
            "      110.66       0.00      0.00      0.00        18\n",
            "      114.79       0.83      0.49      0.61        39\n",
            "       118.0       0.00      0.00      0.00         5\n",
            "      118.66       0.75      0.97      0.84       417\n",
            "      119.32       0.89      0.90      0.89       474\n",
            "      119.98       0.91      0.87      0.89       300\n",
            "        12.3       0.33      0.72      0.45       671\n",
            "      120.64       0.85      0.82      0.84        56\n",
            "      122.58       0.00      0.00      0.00         4\n",
            "      123.24       0.97      0.98      0.98        60\n",
            "       127.2       0.00      0.00      0.00        31\n",
            "      130.98       0.00      0.00      0.00        49\n",
            "      134.76       0.51      0.94      0.66        98\n",
            "      138.54       0.00      0.00      0.00        19\n",
            "      142.32       0.00      0.00      0.00        33\n",
            "       146.1       0.55      0.66      0.60        56\n",
            "      149.88       0.37      0.55      0.44        65\n",
            "        15.8       0.28      0.58      0.38       505\n",
            "       17.68       0.40      0.68      0.50       389\n",
            "       19.56       0.00      0.00      0.00         3\n",
            "      200.46       0.77      0.71      0.74       124\n",
            "      205.55       0.83      0.73      0.78       633\n",
            "       21.44       0.20      0.09      0.13       266\n",
            "      210.64       0.52      0.68      0.59       596\n",
            "      215.73       0.83      0.78      0.81       863\n",
            "      220.82       0.83      0.74      0.78       838\n",
            "      225.91       0.73      0.88      0.80       574\n",
            "       23.32       1.00      0.01      0.03       138\n",
            "       231.0       0.88      0.93      0.91       592\n",
            "      236.09       0.89      0.93      0.91       380\n",
            "      241.18       0.00      0.00      0.00        19\n",
            "      246.27       0.48      0.42      0.45        26\n",
            "        25.2       0.00      0.00      0.00       190\n",
            "       251.4       0.90      0.64      0.75        28\n",
            "       253.9       0.48      0.48      0.48        21\n",
            "       256.4       0.14      0.09      0.11        22\n",
            "       258.9       0.00      0.00      0.00        15\n",
            "       261.4       0.61      1.00      0.76        11\n",
            "       263.9       1.00      0.38      0.55        24\n",
            "       266.4       0.00      0.00      0.00        15\n",
            "       268.9       0.00      0.00      0.00         5\n",
            "       27.08       0.22      0.41      0.29       319\n",
            "       271.4       0.00      0.00      0.00         2\n",
            "       273.9       0.00      0.00      0.00         7\n",
            "       276.4       0.00      0.00      0.00         7\n",
            "       28.96       0.19      0.33      0.24       301\n",
            "       286.4       1.00      0.33      0.50         9\n",
            "      295.58       0.86      0.97      0.91        37\n",
            "         3.2       0.93      0.84      0.88       330\n",
            "         3.3       0.82      0.97      0.89       637\n",
            "       30.84       0.20      0.07      0.11       256\n",
            "      304.76       0.00      0.00      0.00         6\n",
            "       32.72       0.59      0.37      0.45       358\n",
            "        34.6       0.73      0.44      0.55       308\n",
            "       36.48       0.00      0.00      0.00       206\n",
            "       38.36       1.00      0.70      0.82        89\n",
            "         4.2       1.00      0.52      0.68       176\n",
            "        42.1       0.00      0.00      0.00       217\n",
            "       43.39       0.00      0.00      0.00       182\n",
            "       45.27       0.59      0.34      0.43       385\n",
            "       46.56       0.64      0.82      0.72       387\n",
            "       47.85       0.90      0.91      0.91       631\n",
            "       49.14       0.89      0.90      0.89       596\n",
            "       49.43       0.95      0.57      0.71       325\n",
            "         5.1       0.44      0.81      0.57       281\n",
            "       51.72       0.91      0.80      0.85       382\n",
            "       53.01       0.55      0.91      0.69       275\n",
            "        54.3       0.50      0.02      0.03        63\n",
            "       55.59       0.90      0.51      0.65        35\n",
            "       56.88       0.50      0.07      0.12        15\n",
            "       58.17       0.47      0.93      0.62        15\n",
            "       59.46       0.76      0.79      0.77       241\n",
            "         6.0       0.56      0.82      0.67       486\n",
            "         6.9       0.00      0.00      0.00       274\n",
            "        60.2       0.88      0.71      0.78       234\n",
            "       64.33       0.00      0.00      0.00         3\n",
            "         7.8       0.00      0.00      0.00       240\n",
            "       76.72       0.00      0.00      0.00         6\n",
            "         8.7       0.00      0.00      0.00        32\n",
            "       80.85       0.00      0.00      0.00        28\n",
            "       89.01       0.00      0.00      0.00         9\n",
            "         9.6       0.58      0.07      0.12       258\n",
            "       93.14       0.00      0.00      0.00        13\n",
            "       97.27       0.53      0.95      0.68        63\n",
            "\n",
            "    accuracy                           0.62     18201\n",
            "   macro avg       0.44      0.42      0.40     18201\n",
            "weighted avg       0.61      0.62      0.59     18201\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[ 43   0   0 ...   0   0   0]\n",
            " [  0  16   0 ...   0   0   3]\n",
            " [  0   0   0 ...   0   0   0]\n",
            " ...\n",
            " [106   0   0 ...  18   0   0]\n",
            " [  0   1   0 ...   0   0   9]\n",
            " [  0   0   0 ...   0   0  60]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Random Forest Classifier"
      ],
      "metadata": {
        "id": "3vEOcbAMHjo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=RandomForestClassifier()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGA2B4U5Hcjo",
        "outputId": "08f3f849-1fc7-4c14-f96a-ba06e32090f6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.06       0.96      0.97      0.97       671\n",
            "       11.93       0.95      0.96      0.95       505\n",
            "        12.3       0.93      0.96      0.95       389\n",
            "       12.67       0.50      0.67      0.57         3\n",
            "       13.04       0.99      0.97      0.98       266\n",
            "       13.41       0.92      0.90      0.91       138\n",
            "       13.78       0.86      0.84      0.85       190\n",
            "       14.45       0.89      0.88      0.89       319\n",
            "       14.82       0.85      0.88      0.87       301\n",
            "       15.19       0.91      0.86      0.89       256\n",
            "       15.56       0.94      0.93      0.94       358\n",
            "       15.93       0.90      0.91      0.90       308\n",
            "        16.3       0.79      0.84      0.82       206\n",
            "       16.67       0.99      0.99      0.99        89\n",
            "       17.04       0.99      0.99      0.99       217\n",
            "       17.12       0.94      0.91      0.92       182\n",
            "        17.2       0.95      0.96      0.96       385\n",
            "       17.28       0.98      0.99      0.98       387\n",
            "       17.36       0.98      0.98      0.98       631\n",
            "       17.44       0.98      0.98      0.98       596\n",
            "       17.52       0.99      0.97      0.98       325\n",
            "        17.6       0.99      1.00      0.99       382\n",
            "       17.68       1.00      1.00      1.00       275\n",
            "       17.76       0.98      0.94      0.96        63\n",
            "       17.84       0.83      1.00      0.91        35\n",
            "       17.92       1.00      1.00      1.00        15\n",
            "        18.0       1.00      1.00      1.00        15\n",
            "       18.08       1.00      0.98      0.99       241\n",
            "       18.14       0.98      1.00      0.99       234\n",
            "       18.51       1.00      1.00      1.00         3\n",
            "       19.52       1.00      1.00      1.00         6\n",
            "       19.89       1.00      1.00      1.00        28\n",
            "       20.53       0.90      1.00      0.95         9\n",
            "        20.9       1.00      0.92      0.96        13\n",
            "       21.27       1.00      1.00      1.00        63\n",
            "       21.64       1.00      1.00      1.00        19\n",
            "       22.01       1.00      0.83      0.91         6\n",
            "       22.38       1.00      0.94      0.97        18\n",
            "       22.75       0.95      0.92      0.94        39\n",
            "       23.33       1.00      0.80      0.89         5\n",
            "       23.42       0.99      0.99      0.99       417\n",
            "       23.51       0.97      0.99      0.98       474\n",
            "        23.6       0.98      0.94      0.96       300\n",
            "       23.69       0.95      0.95      0.95        56\n",
            "       23.96       1.00      1.00      1.00         4\n",
            "       24.05       0.98      1.00      0.99        60\n",
            "       24.53       0.97      0.94      0.95        31\n",
            "       24.76       0.84      0.88      0.86        49\n",
            "       24.99       0.95      0.93      0.94        98\n",
            "       25.32       0.95      0.95      0.95        19\n",
            "       25.55       0.97      0.94      0.95        33\n",
            "       25.78       0.98      0.98      0.98        56\n",
            "       26.01       0.95      0.97      0.96        65\n",
            "       28.55       0.94      0.95      0.94       124\n",
            "       28.74       0.97      0.96      0.96       633\n",
            "       28.93       0.97      0.98      0.97       596\n",
            "       29.12       0.97      0.97      0.97       863\n",
            "       29.31       0.97      0.98      0.98       838\n",
            "        29.5       0.97      0.98      0.98       574\n",
            "       29.69       0.99      1.00      0.99       592\n",
            "       29.88       0.98      0.98      0.98       380\n",
            "       30.07       0.94      0.79      0.86        19\n",
            "       30.26       0.88      0.85      0.86        26\n",
            "       30.46       1.00      1.00      1.00        28\n",
            "       30.58       1.00      0.95      0.98        21\n",
            "       30.77       0.95      0.82      0.88        22\n",
            "       30.89       1.00      0.80      0.89        15\n",
            "       31.01       1.00      0.91      0.95        11\n",
            "       31.13       0.95      0.88      0.91        24\n",
            "       31.25       1.00      0.93      0.97        15\n",
            "       31.37       1.00      1.00      1.00         5\n",
            "       31.49       0.00      0.00      0.00         2\n",
            "       31.61       1.00      0.71      0.83         7\n",
            "       31.73       1.00      0.86      0.92         7\n",
            "       32.12       1.00      1.00      1.00         9\n",
            "       32.33       1.00      1.00      1.00         6\n",
            "       32.37       0.97      1.00      0.99        37\n",
            "         7.3       0.97      0.97      0.97       330\n",
            "        7.36       0.98      0.98      0.98       637\n",
            "        7.69       0.99      0.98      0.99       176\n",
            "        7.72       0.97      0.95      0.96       281\n",
            "        8.05       0.96      0.99      0.97       486\n",
            "        8.38       0.98      0.92      0.95       274\n",
            "        8.41       0.98      0.99      0.99       240\n",
            "        8.74       1.00      0.78      0.88        32\n",
            "        9.07       0.94      0.90      0.92       258\n",
            "         9.4       0.92      0.93      0.92       349\n",
            "        9.73       0.96      0.94      0.95       431\n",
            "\n",
            "    accuracy                           0.96     18201\n",
            "   macro avg       0.95      0.93      0.94     18201\n",
            "weighted avg       0.96      0.96      0.96     18201\n",
            "\n",
            "The confusion matrix for Fish Length is: [[650   7   2 ...   0   4   7]\n",
            " [  1 485   2 ...   2   8   5]\n",
            " [  0   4 373 ...   8   3   1]\n",
            " ...\n",
            " [  1   6  11 ... 233   4   2]\n",
            " [  7   7   7 ...   2 323   2]\n",
            " [ 11   1   3 ...   0   5 407]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "        10.5       0.92      0.94      0.93       349\n",
            "       103.4       1.00      1.00      1.00        19\n",
            "      107.53       1.00      0.83      0.91         6\n",
            "        11.4       0.97      0.94      0.96       431\n",
            "      110.66       1.00      0.94      0.97        18\n",
            "      114.79       0.95      0.92      0.94        39\n",
            "       118.0       1.00      0.60      0.75         5\n",
            "      118.66       0.98      1.00      0.99       417\n",
            "      119.32       0.96      0.99      0.98       474\n",
            "      119.98       0.98      0.94      0.96       300\n",
            "        12.3       0.96      0.98      0.97       671\n",
            "      120.64       0.93      0.95      0.94        56\n",
            "      122.58       0.80      1.00      0.89         4\n",
            "      123.24       0.98      1.00      0.99        60\n",
            "       127.2       0.94      0.94      0.94        31\n",
            "      130.98       0.86      0.76      0.80        49\n",
            "      134.76       0.91      0.95      0.93        98\n",
            "      138.54       0.95      0.95      0.95        19\n",
            "      142.32       0.97      0.97      0.97        33\n",
            "       146.1       0.98      0.96      0.97        56\n",
            "      149.88       0.94      0.97      0.95        65\n",
            "        15.8       0.95      0.96      0.95       505\n",
            "       17.68       0.94      0.96      0.95       389\n",
            "       19.56       0.67      0.67      0.67         3\n",
            "      200.46       0.94      0.95      0.95       124\n",
            "      205.55       0.96      0.96      0.96       633\n",
            "       21.44       0.99      0.98      0.98       266\n",
            "      210.64       0.97      0.97      0.97       596\n",
            "      215.73       0.98      0.97      0.97       863\n",
            "      220.82       0.97      0.98      0.98       838\n",
            "      225.91       0.98      0.98      0.98       574\n",
            "       23.32       0.92      0.90      0.91       138\n",
            "       231.0       0.98      1.00      0.99       592\n",
            "      236.09       0.98      0.99      0.98       380\n",
            "      241.18       0.82      0.74      0.78        19\n",
            "      246.27       0.90      0.73      0.81        26\n",
            "        25.2       0.84      0.86      0.85       190\n",
            "       251.4       0.97      1.00      0.98        28\n",
            "       253.9       0.95      0.90      0.93        21\n",
            "       256.4       0.95      0.82      0.88        22\n",
            "       258.9       0.92      0.73      0.81        15\n",
            "       261.4       1.00      0.91      0.95        11\n",
            "       263.9       0.95      0.88      0.91        24\n",
            "       266.4       1.00      0.93      0.97        15\n",
            "       268.9       1.00      1.00      1.00         5\n",
            "       27.08       0.88      0.88      0.88       319\n",
            "       271.4       0.00      0.00      0.00         2\n",
            "       273.9       1.00      0.57      0.73         7\n",
            "       276.4       1.00      0.86      0.92         7\n",
            "       28.96       0.84      0.87      0.86       301\n",
            "       286.4       1.00      1.00      1.00         9\n",
            "      295.58       0.97      1.00      0.99        37\n",
            "         3.2       0.97      0.98      0.97       330\n",
            "         3.3       0.98      0.99      0.98       637\n",
            "       30.84       0.92      0.85      0.88       256\n",
            "      304.76       1.00      1.00      1.00         6\n",
            "       32.72       0.95      0.94      0.94       358\n",
            "        34.6       0.91      0.91      0.91       308\n",
            "       36.48       0.80      0.85      0.82       206\n",
            "       38.36       0.99      0.99      0.99        89\n",
            "         4.2       0.99      0.98      0.99       176\n",
            "        42.1       0.98      0.99      0.98       217\n",
            "       43.39       0.94      0.90      0.92       182\n",
            "       45.27       0.96      0.96      0.96       385\n",
            "       46.56       0.98      0.99      0.98       387\n",
            "       47.85       0.99      0.98      0.98       631\n",
            "       49.14       0.98      0.99      0.98       596\n",
            "       49.43       0.99      0.97      0.98       325\n",
            "         5.1       0.97      0.95      0.96       281\n",
            "       51.72       0.99      1.00      0.99       382\n",
            "       53.01       1.00      1.00      1.00       275\n",
            "        54.3       1.00      0.92      0.96        63\n",
            "       55.59       0.85      1.00      0.92        35\n",
            "       56.88       1.00      0.93      0.97        15\n",
            "       58.17       1.00      1.00      1.00        15\n",
            "       59.46       1.00      0.98      0.99       241\n",
            "         6.0       0.96      0.99      0.97       486\n",
            "         6.9       0.98      0.93      0.96       274\n",
            "        60.2       0.98      1.00      0.99       234\n",
            "       64.33       1.00      1.00      1.00         3\n",
            "         7.8       0.98      0.99      0.99       240\n",
            "       76.72       1.00      1.00      1.00         6\n",
            "         8.7       1.00      0.75      0.86        32\n",
            "       80.85       1.00      1.00      1.00        28\n",
            "       89.01       0.90      1.00      0.95         9\n",
            "         9.6       0.95      0.90      0.92       258\n",
            "       93.14       1.00      0.92      0.96        13\n",
            "       97.27       1.00      1.00      1.00        63\n",
            "\n",
            "    accuracy                           0.96     18201\n",
            "   macro avg       0.94      0.92      0.93     18201\n",
            "weighted avg       0.96      0.96      0.96     18201\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[327   0   0 ...   1   0   0]\n",
            " [  0  19   0 ...   0   0   0]\n",
            " [  0   0   5 ...   0   0   0]\n",
            " ...\n",
            " [  4   0   0 ... 232   0   0]\n",
            " [  0   0   0 ...   0  12   0]\n",
            " [  0   0   0 ...   0   0  63]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) K Nearest Neighbors"
      ],
      "metadata": {
        "id": "FuZksEpaHolR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=KNeighborsClassifier()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuuhL3-8HmKH",
        "outputId": "80f5c58e-65d8-4a56-da79-7031bfff0bc4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.06       0.69      0.83      0.75       671\n",
            "       11.93       0.77      0.87      0.81       505\n",
            "        12.3       0.62      0.79      0.69       389\n",
            "       12.67       0.00      0.00      0.00         3\n",
            "       13.04       0.59      0.66      0.62       266\n",
            "       13.41       0.53      0.40      0.46       138\n",
            "       13.78       0.39      0.53      0.45       190\n",
            "       14.45       0.52      0.68      0.59       319\n",
            "       14.82       0.40      0.38      0.39       301\n",
            "       15.19       0.53      0.46      0.50       256\n",
            "       15.56       0.74      0.59      0.66       358\n",
            "       15.93       0.67      0.61      0.64       308\n",
            "        16.3       0.51      0.37      0.43       206\n",
            "       16.67       0.94      0.92      0.93        89\n",
            "       17.04       0.79      0.60      0.69       217\n",
            "       17.12       0.83      0.55      0.66       182\n",
            "        17.2       0.86      0.88      0.87       385\n",
            "       17.28       0.90      0.89      0.90       387\n",
            "       17.36       0.97      0.97      0.97       631\n",
            "       17.44       0.97      0.96      0.97       596\n",
            "       17.52       0.94      0.94      0.94       325\n",
            "        17.6       0.97      0.96      0.96       382\n",
            "       17.68       0.86      0.92      0.89       275\n",
            "       17.76       0.70      0.49      0.58        63\n",
            "       17.84       0.88      0.63      0.73        35\n",
            "       17.92       0.73      0.73      0.73        15\n",
            "        18.0       0.82      0.93      0.87        15\n",
            "       18.08       0.92      0.95      0.93       241\n",
            "       18.14       0.94      0.91      0.92       234\n",
            "       18.51       1.00      0.67      0.80         3\n",
            "       19.52       1.00      1.00      1.00         6\n",
            "       19.89       1.00      0.93      0.96        28\n",
            "       20.53       1.00      1.00      1.00         9\n",
            "        20.9       1.00      1.00      1.00        13\n",
            "       21.27       1.00      1.00      1.00        63\n",
            "       21.64       0.90      1.00      0.95        19\n",
            "       22.01       0.60      1.00      0.75         6\n",
            "       22.38       0.94      0.94      0.94        18\n",
            "       22.75       0.73      0.77      0.75        39\n",
            "       23.33       0.75      0.60      0.67         5\n",
            "       23.42       0.95      0.96      0.96       417\n",
            "       23.51       0.93      0.98      0.95       474\n",
            "        23.6       0.96      0.92      0.94       300\n",
            "       23.69       0.91      0.86      0.88        56\n",
            "       23.96       1.00      0.25      0.40         4\n",
            "       24.05       0.97      0.98      0.98        60\n",
            "       24.53       0.81      0.68      0.74        31\n",
            "       24.76       0.55      0.47      0.51        49\n",
            "       24.99       0.75      0.90      0.82        98\n",
            "       25.32       1.00      0.63      0.77        19\n",
            "       25.55       0.48      0.42      0.45        33\n",
            "       25.78       0.91      0.89      0.90        56\n",
            "       26.01       0.67      0.72      0.70        65\n",
            "       28.55       0.93      0.95      0.94       124\n",
            "       28.74       0.96      0.95      0.95       633\n",
            "       28.93       0.97      0.96      0.96       596\n",
            "       29.12       0.95      0.97      0.96       863\n",
            "       29.31       0.97      0.98      0.97       838\n",
            "        29.5       0.97      0.98      0.98       574\n",
            "       29.69       0.98      0.99      0.99       592\n",
            "       29.88       0.97      0.98      0.98       380\n",
            "       30.07       0.79      0.58      0.67        19\n",
            "       30.26       0.90      0.69      0.78        26\n",
            "       30.46       0.97      1.00      0.98        28\n",
            "       30.58       0.85      0.81      0.83        21\n",
            "       30.77       0.74      0.77      0.76        22\n",
            "       30.89       0.90      0.60      0.72        15\n",
            "       31.01       0.90      0.82      0.86        11\n",
            "       31.13       0.91      0.83      0.87        24\n",
            "       31.25       0.89      0.53      0.67        15\n",
            "       31.37       1.00      1.00      1.00         5\n",
            "       31.49       0.00      0.00      0.00         2\n",
            "       31.61       0.75      0.43      0.55         7\n",
            "       31.73       0.78      1.00      0.88         7\n",
            "       32.12       0.90      1.00      0.95         9\n",
            "       32.33       1.00      1.00      1.00         6\n",
            "       32.37       1.00      0.97      0.99        37\n",
            "         7.3       0.89      0.89      0.89       330\n",
            "        7.36       0.90      0.93      0.92       637\n",
            "        7.69       0.95      0.86      0.90       176\n",
            "        7.72       0.83      0.88      0.85       281\n",
            "        8.05       0.87      0.94      0.91       486\n",
            "        8.38       0.85      0.62      0.72       274\n",
            "        8.41       0.91      0.71      0.80       240\n",
            "        8.74       0.80      0.62      0.70        32\n",
            "        9.07       0.70      0.68      0.69       258\n",
            "         9.4       0.68      0.59      0.63       349\n",
            "        9.73       0.82      0.75      0.78       431\n",
            "\n",
            "    accuracy                           0.84     18201\n",
            "   macro avg       0.82      0.78      0.79     18201\n",
            "weighted avg       0.85      0.84      0.84     18201\n",
            "\n",
            "The confusion matrix for Fish Length is: [[559  12   7 ...   8   5  31]\n",
            " [  9 438   8 ...   5  26   8]\n",
            " [ 22  10 306 ...  12   9   7]\n",
            " ...\n",
            " [ 15   6  28 ... 175   4   5]\n",
            " [ 28  53  25 ...   3 205   3]\n",
            " [ 54   8  12 ...   9   3 322]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "        10.5       0.59      0.68      0.63       349\n",
            "       103.4       0.90      1.00      0.95        19\n",
            "      107.53       0.60      1.00      0.75         6\n",
            "        11.4       0.74      0.81      0.77       431\n",
            "      110.66       0.94      0.94      0.94        18\n",
            "      114.79       0.74      0.79      0.77        39\n",
            "       118.0       0.75      0.60      0.67         5\n",
            "      118.66       0.94      0.97      0.95       417\n",
            "      119.32       0.92      0.98      0.95       474\n",
            "      119.98       0.96      0.92      0.94       300\n",
            "        12.3       0.71      0.81      0.76       671\n",
            "      120.64       0.91      0.86      0.88        56\n",
            "      122.58       1.00      0.25      0.40         4\n",
            "      123.24       0.97      0.98      0.98        60\n",
            "       127.2       0.81      0.68      0.74        31\n",
            "      130.98       0.55      0.47      0.51        49\n",
            "      134.76       0.75      0.90      0.82        98\n",
            "      138.54       1.00      0.63      0.77        19\n",
            "      142.32       0.48      0.42      0.45        33\n",
            "       146.1       0.91      0.89      0.90        56\n",
            "      149.88       0.67      0.72      0.70        65\n",
            "        15.8       0.79      0.85      0.82       505\n",
            "       17.68       0.63      0.77      0.69       389\n",
            "       19.56       0.00      0.00      0.00         3\n",
            "      200.46       0.93      0.95      0.94       124\n",
            "      205.55       0.96      0.95      0.95       633\n",
            "       21.44       0.60      0.64      0.62       266\n",
            "      210.64       0.97      0.96      0.96       596\n",
            "      215.73       0.95      0.97      0.96       863\n",
            "      220.82       0.97      0.98      0.97       838\n",
            "      225.91       0.97      0.98      0.98       574\n",
            "       23.32       0.54      0.38      0.45       138\n",
            "       231.0       0.98      0.99      0.99       592\n",
            "      236.09       0.97      0.98      0.98       380\n",
            "      241.18       0.79      0.58      0.67        19\n",
            "      246.27       0.90      0.69      0.78        26\n",
            "        25.2       0.39      0.53      0.45       190\n",
            "       251.4       0.97      1.00      0.98        28\n",
            "       253.9       0.85      0.81      0.83        21\n",
            "       256.4       0.74      0.77      0.76        22\n",
            "       258.9       0.90      0.60      0.72        15\n",
            "       261.4       0.90      0.82      0.86        11\n",
            "       263.9       0.91      0.83      0.87        24\n",
            "       266.4       0.89      0.53      0.67        15\n",
            "       268.9       1.00      1.00      1.00         5\n",
            "       27.08       0.53      0.68      0.59       319\n",
            "       271.4       0.00      0.00      0.00         2\n",
            "       273.9       0.75      0.43      0.55         7\n",
            "       276.4       0.78      1.00      0.88         7\n",
            "       28.96       0.41      0.38      0.39       301\n",
            "       286.4       0.90      1.00      0.95         9\n",
            "      295.58       1.00      0.97      0.99        37\n",
            "         3.2       0.89      0.89      0.89       330\n",
            "         3.3       0.90      0.93      0.92       637\n",
            "       30.84       0.54      0.46      0.50       256\n",
            "      304.76       1.00      1.00      1.00         6\n",
            "       32.72       0.75      0.59      0.66       358\n",
            "        34.6       0.67      0.61      0.64       308\n",
            "       36.48       0.50      0.37      0.43       206\n",
            "       38.36       0.94      0.92      0.93        89\n",
            "         4.2       0.95      0.86      0.90       176\n",
            "        42.1       0.80      0.60      0.68       217\n",
            "       43.39       0.84      0.54      0.66       182\n",
            "       45.27       0.86      0.88      0.87       385\n",
            "       46.56       0.90      0.89      0.90       387\n",
            "       47.85       0.97      0.97      0.97       631\n",
            "       49.14       0.97      0.96      0.97       596\n",
            "       49.43       0.94      0.94      0.94       325\n",
            "         5.1       0.83      0.88      0.85       281\n",
            "       51.72       0.97      0.96      0.96       382\n",
            "       53.01       0.86      0.92      0.89       275\n",
            "        54.3       0.70      0.49      0.58        63\n",
            "       55.59       0.88      0.63      0.73        35\n",
            "       56.88       0.73      0.73      0.73        15\n",
            "       58.17       0.82      0.93      0.87        15\n",
            "       59.46       0.93      0.93      0.93       241\n",
            "         6.0       0.88      0.94      0.91       486\n",
            "         6.9       0.86      0.61      0.71       274\n",
            "        60.2       0.95      0.89      0.92       234\n",
            "       64.33       1.00      0.67      0.80         3\n",
            "         7.8       0.91      0.71      0.80       240\n",
            "       76.72       1.00      1.00      1.00         6\n",
            "         8.7       0.83      0.62      0.71        32\n",
            "       80.85       1.00      0.93      0.96        28\n",
            "       89.01       1.00      1.00      1.00         9\n",
            "         9.6       0.71      0.66      0.68       258\n",
            "       93.14       1.00      1.00      1.00        13\n",
            "       97.27       1.00      1.00      1.00        63\n",
            "\n",
            "    accuracy                           0.84     18201\n",
            "   macro avg       0.82      0.78      0.79     18201\n",
            "weighted avg       0.85      0.84      0.84     18201\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[237   0   0 ...   0   0   0]\n",
            " [  0  19   0 ...   0   0   0]\n",
            " [  0   0   6 ...   0   0   0]\n",
            " ...\n",
            " [  6   0   0 ... 170   0   0]\n",
            " [  0   0   0 ...   0  13   0]\n",
            " [  0   0   0 ...   0   0  63]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Ada Booster Classifier"
      ],
      "metadata": {
        "id": "9VIHdFztHrS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=AdaBoostClassifier()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIyEUSelHoDi",
        "outputId": "fa1a2e5e-e072-4393-ad5d-7a70979a10ac"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.06       0.00      0.00      0.00       671\n",
            "       11.93       0.00      0.00      0.00       505\n",
            "        12.3       0.34      0.06      0.10       389\n",
            "       12.67       0.00      0.00      0.00         3\n",
            "       13.04       0.00      0.00      0.00       266\n",
            "       13.41       0.00      0.00      0.00       138\n",
            "       13.78       0.00      0.00      0.00       190\n",
            "       14.45       0.00      0.00      0.00       319\n",
            "       14.82       0.00      0.00      0.00       301\n",
            "       15.19       0.00      0.00      0.00       256\n",
            "       15.56       0.90      0.03      0.05       358\n",
            "       15.93       0.11      0.97      0.20       308\n",
            "        16.3       0.00      0.00      0.00       206\n",
            "       16.67       0.00      0.00      0.00        89\n",
            "       17.04       0.00      0.00      0.00       217\n",
            "       17.12       0.00      0.00      0.00       182\n",
            "        17.2       0.00      0.00      0.00       385\n",
            "       17.28       0.21      0.06      0.09       387\n",
            "       17.36       0.00      0.00      0.00       631\n",
            "       17.44       0.00      0.00      0.00       596\n",
            "       17.52       0.00      0.00      0.00       325\n",
            "        17.6       0.92      0.44      0.60       382\n",
            "       17.68       0.00      0.00      0.00       275\n",
            "       17.76       0.00      0.00      0.00        63\n",
            "       17.84       0.00      0.00      0.00        35\n",
            "       17.92       0.00      0.00      0.00        15\n",
            "        18.0       0.50      0.93      0.65        15\n",
            "       18.08       0.09      0.85      0.17       241\n",
            "       18.14       0.00      0.00      0.00       234\n",
            "       18.51       0.00      0.00      0.00         3\n",
            "       19.52       0.00      0.00      0.00         6\n",
            "       19.89       0.00      0.00      0.00        28\n",
            "       20.53       0.00      0.00      0.00         9\n",
            "        20.9       0.00      0.00      0.00        13\n",
            "       21.27       0.00      0.00      0.00        63\n",
            "       21.64       0.00      0.00      0.00        19\n",
            "       22.01       0.00      0.00      0.00         6\n",
            "       22.38       0.00      0.00      0.00        18\n",
            "       22.75       0.00      0.00      0.00        39\n",
            "       23.33       0.00      0.00      0.00         5\n",
            "       23.42       0.00      0.00      0.00       417\n",
            "       23.51       0.27      1.00      0.42       474\n",
            "        23.6       0.00      0.00      0.00       300\n",
            "       23.69       0.00      0.00      0.00        56\n",
            "       23.96       0.00      0.00      0.00         4\n",
            "       24.05       0.00      0.00      0.00        60\n",
            "       24.53       0.00      0.00      0.00        31\n",
            "       24.76       0.00      0.00      0.00        49\n",
            "       24.99       0.00      0.00      0.00        98\n",
            "       25.32       0.00      0.00      0.00        19\n",
            "       25.55       0.00      0.00      0.00        33\n",
            "       25.78       0.00      0.00      0.00        56\n",
            "       26.01       0.00      0.00      0.00        65\n",
            "       28.55       0.00      0.00      0.00       124\n",
            "       28.74       0.00      0.00      0.00       633\n",
            "       28.93       0.00      0.00      0.00       596\n",
            "       29.12       0.16      0.97      0.28       863\n",
            "       29.31       0.00      0.00      0.00       838\n",
            "        29.5       0.00      0.00      0.00       574\n",
            "       29.69       0.00      0.00      0.00       592\n",
            "       29.88       0.00      0.00      0.00       380\n",
            "       30.07       0.00      0.00      0.00        19\n",
            "       30.26       0.00      0.00      0.00        26\n",
            "       30.46       0.00      0.00      0.00        28\n",
            "       30.58       0.00      0.00      0.00        21\n",
            "       30.77       0.00      0.00      0.00        22\n",
            "       30.89       0.00      0.00      0.00        15\n",
            "       31.01       0.00      0.00      0.00        11\n",
            "       31.13       0.00      0.00      0.00        24\n",
            "       31.25       0.00      0.00      0.00        15\n",
            "       31.37       0.00      0.00      0.00         5\n",
            "       31.49       0.00      0.00      0.00         2\n",
            "       31.61       0.00      0.00      0.00         7\n",
            "       31.73       0.00      0.00      0.00         7\n",
            "       32.12       0.00      0.00      0.00         9\n",
            "       32.33       0.00      0.00      0.00         6\n",
            "       32.37       0.00      0.00      0.00        37\n",
            "         7.3       0.05      0.98      0.10       330\n",
            "        7.36       0.00      0.00      0.00       637\n",
            "        7.69       0.00      0.00      0.00       176\n",
            "        7.72       0.00      0.00      0.00       281\n",
            "        8.05       0.00      0.00      0.00       486\n",
            "        8.38       0.00      0.00      0.00       274\n",
            "        8.41       0.00      0.00      0.00       240\n",
            "        8.74       0.00      0.00      0.00        32\n",
            "        9.07       0.56      0.02      0.04       258\n",
            "         9.4       0.00      0.00      0.00       349\n",
            "        9.73       0.00      0.00      0.00       431\n",
            "\n",
            "    accuracy                           0.13     18201\n",
            "   macro avg       0.05      0.07      0.03     18201\n",
            "weighted avg       0.08      0.13      0.05     18201\n",
            "\n",
            "The confusion matrix for Fish Length is: [[ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  8 ...  0  0  0]\n",
            " [ 0  0 22 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  5  0  0]\n",
            " [ 0  0  1 ...  2  0  0]\n",
            " [ 0  0  0 ...  0  0  0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "        10.5       0.00      0.00      0.00       349\n",
            "       103.4       0.00      0.00      0.00        19\n",
            "      107.53       0.00      0.00      0.00         6\n",
            "        11.4       0.00      0.00      0.00       431\n",
            "      110.66       0.00      0.00      0.00        18\n",
            "      114.79       0.00      0.00      0.00        39\n",
            "       118.0       0.00      0.00      0.00         5\n",
            "      118.66       0.00      0.00      0.00       417\n",
            "      119.32       0.27      1.00      0.42       474\n",
            "      119.98       0.00      0.00      0.00       300\n",
            "        12.3       0.00      0.00      0.00       671\n",
            "      120.64       0.00      0.00      0.00        56\n",
            "      122.58       0.00      0.00      0.00         4\n",
            "      123.24       0.00      0.00      0.00        60\n",
            "       127.2       0.00      0.00      0.00        31\n",
            "      130.98       0.00      0.00      0.00        49\n",
            "      134.76       0.00      0.00      0.00        98\n",
            "      138.54       0.00      0.00      0.00        19\n",
            "      142.32       0.00      0.00      0.00        33\n",
            "       146.1       0.00      0.00      0.00        56\n",
            "      149.88       0.00      0.00      0.00        65\n",
            "        15.8       0.00      0.00      0.00       505\n",
            "       17.68       0.34      0.06      0.10       389\n",
            "       19.56       0.00      0.00      0.00         3\n",
            "      200.46       0.00      0.00      0.00       124\n",
            "      205.55       0.00      0.00      0.00       633\n",
            "       21.44       0.00      0.00      0.00       266\n",
            "      210.64       0.00      0.00      0.00       596\n",
            "      215.73       0.16      0.97      0.28       863\n",
            "      220.82       0.00      0.00      0.00       838\n",
            "      225.91       0.00      0.00      0.00       574\n",
            "       23.32       0.00      0.00      0.00       138\n",
            "       231.0       0.00      0.00      0.00       592\n",
            "      236.09       0.00      0.00      0.00       380\n",
            "      241.18       0.00      0.00      0.00        19\n",
            "      246.27       0.00      0.00      0.00        26\n",
            "        25.2       0.00      0.00      0.00       190\n",
            "       251.4       0.00      0.00      0.00        28\n",
            "       253.9       0.00      0.00      0.00        21\n",
            "       256.4       0.00      0.00      0.00        22\n",
            "       258.9       0.00      0.00      0.00        15\n",
            "       261.4       0.00      0.00      0.00        11\n",
            "       263.9       0.00      0.00      0.00        24\n",
            "       266.4       0.00      0.00      0.00        15\n",
            "       268.9       0.00      0.00      0.00         5\n",
            "       27.08       0.00      0.00      0.00       319\n",
            "       271.4       0.00      0.00      0.00         2\n",
            "       273.9       0.00      0.00      0.00         7\n",
            "       276.4       0.00      0.00      0.00         7\n",
            "       28.96       0.00      0.00      0.00       301\n",
            "       286.4       0.00      0.00      0.00         9\n",
            "      295.58       0.00      0.00      0.00        37\n",
            "         3.2       0.05      0.98      0.10       330\n",
            "         3.3       0.00      0.00      0.00       637\n",
            "       30.84       0.00      0.00      0.00       256\n",
            "      304.76       0.00      0.00      0.00         6\n",
            "       32.72       0.90      0.03      0.05       358\n",
            "        34.6       0.11      0.97      0.20       308\n",
            "       36.48       0.00      0.00      0.00       206\n",
            "       38.36       0.00      0.00      0.00        89\n",
            "         4.2       0.00      0.00      0.00       176\n",
            "        42.1       0.00      0.00      0.00       217\n",
            "       43.39       0.00      0.00      0.00       182\n",
            "       45.27       0.00      0.00      0.00       385\n",
            "       46.56       0.21      0.06      0.09       387\n",
            "       47.85       0.00      0.00      0.00       631\n",
            "       49.14       0.00      0.00      0.00       596\n",
            "       49.43       0.00      0.00      0.00       325\n",
            "         5.1       0.00      0.00      0.00       281\n",
            "       51.72       0.92      0.44      0.60       382\n",
            "       53.01       0.00      0.00      0.00       275\n",
            "        54.3       0.00      0.00      0.00        63\n",
            "       55.59       0.00      0.00      0.00        35\n",
            "       56.88       0.00      0.00      0.00        15\n",
            "       58.17       0.50      0.93      0.65        15\n",
            "       59.46       0.09      0.85      0.17       241\n",
            "         6.0       0.00      0.00      0.00       486\n",
            "         6.9       0.00      0.00      0.00       274\n",
            "        60.2       0.00      0.00      0.00       234\n",
            "       64.33       0.00      0.00      0.00         3\n",
            "         7.8       0.00      0.00      0.00       240\n",
            "       76.72       0.00      0.00      0.00         6\n",
            "         8.7       0.00      0.00      0.00        32\n",
            "       80.85       0.00      0.00      0.00        28\n",
            "       89.01       0.00      0.00      0.00         9\n",
            "         9.6       0.56      0.02      0.04       258\n",
            "       93.14       0.00      0.00      0.00        13\n",
            "       97.27       0.00      0.00      0.00        63\n",
            "\n",
            "    accuracy                           0.13     18201\n",
            "   macro avg       0.05      0.07      0.03     18201\n",
            "weighted avg       0.08      0.13      0.05     18201\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[0 0 0 ... 2 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 5 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7) Extra Trees Classifier"
      ],
      "metadata": {
        "id": "J3nZt3g0HzuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=ExtraTreesClassifier()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QycjdadGHxIX",
        "outputId": "652ae503-a91a-4f44-9980-60b46badd60c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.06       0.96      0.98      0.97       671\n",
            "       11.93       0.95      0.96      0.96       505\n",
            "        12.3       0.94      0.96      0.95       389\n",
            "       12.67       1.00      0.33      0.50         3\n",
            "       13.04       0.98      0.98      0.98       266\n",
            "       13.41       0.96      0.91      0.93       138\n",
            "       13.78       0.87      0.88      0.87       190\n",
            "       14.45       0.88      0.92      0.90       319\n",
            "       14.82       0.83      0.89      0.86       301\n",
            "       15.19       0.91      0.82      0.86       256\n",
            "       15.56       0.95      0.92      0.93       358\n",
            "       15.93       0.93      0.90      0.91       308\n",
            "        16.3       0.77      0.83      0.80       206\n",
            "       16.67       1.00      0.99      0.99        89\n",
            "       17.04       0.98      0.99      0.99       217\n",
            "       17.12       0.96      0.92      0.94       182\n",
            "        17.2       0.97      0.97      0.97       385\n",
            "       17.28       0.98      0.99      0.98       387\n",
            "       17.36       0.99      0.99      0.99       631\n",
            "       17.44       0.99      0.99      0.99       596\n",
            "       17.52       0.99      0.98      0.98       325\n",
            "        17.6       0.99      1.00      0.99       382\n",
            "       17.68       1.00      1.00      1.00       275\n",
            "       17.76       0.98      0.92      0.95        63\n",
            "       17.84       0.89      0.94      0.92        35\n",
            "       17.92       1.00      0.93      0.97        15\n",
            "        18.0       0.94      1.00      0.97        15\n",
            "       18.08       0.99      0.98      0.99       241\n",
            "       18.14       0.98      1.00      0.99       234\n",
            "       18.51       1.00      1.00      1.00         3\n",
            "       19.52       1.00      1.00      1.00         6\n",
            "       19.89       1.00      1.00      1.00        28\n",
            "       20.53       0.90      1.00      0.95         9\n",
            "        20.9       1.00      0.92      0.96        13\n",
            "       21.27       1.00      1.00      1.00        63\n",
            "       21.64       1.00      1.00      1.00        19\n",
            "       22.01       1.00      0.83      0.91         6\n",
            "       22.38       1.00      0.94      0.97        18\n",
            "       22.75       0.95      1.00      0.97        39\n",
            "       23.33       1.00      0.80      0.89         5\n",
            "       23.42       0.99      1.00      1.00       417\n",
            "       23.51       0.97      0.99      0.98       474\n",
            "        23.6       0.98      0.95      0.96       300\n",
            "       23.69       0.93      0.98      0.96        56\n",
            "       23.96       1.00      1.00      1.00         4\n",
            "       24.05       0.98      1.00      0.99        60\n",
            "       24.53       0.94      0.97      0.95        31\n",
            "       24.76       0.90      0.78      0.84        49\n",
            "       24.99       0.92      0.97      0.95        98\n",
            "       25.32       1.00      0.95      0.97        19\n",
            "       25.55       0.97      0.94      0.95        33\n",
            "       25.78       0.96      0.96      0.96        56\n",
            "       26.01       0.93      0.95      0.94        65\n",
            "       28.55       0.94      0.97      0.96       124\n",
            "       28.74       0.98      0.98      0.98       633\n",
            "       28.93       0.99      0.99      0.99       596\n",
            "       29.12       0.99      0.99      0.99       863\n",
            "       29.31       0.99      0.99      0.99       838\n",
            "        29.5       0.99      0.99      0.99       574\n",
            "       29.69       0.99      1.00      0.99       592\n",
            "       29.88       0.99      0.99      0.99       380\n",
            "       30.07       1.00      0.84      0.91        19\n",
            "       30.26       0.88      0.81      0.84        26\n",
            "       30.46       1.00      1.00      1.00        28\n",
            "       30.58       0.90      0.90      0.90        21\n",
            "       30.77       0.87      0.91      0.89        22\n",
            "       30.89       1.00      0.87      0.93        15\n",
            "       31.01       1.00      0.91      0.95        11\n",
            "       31.13       0.95      0.88      0.91        24\n",
            "       31.25       1.00      0.93      0.97        15\n",
            "       31.37       1.00      1.00      1.00         5\n",
            "       31.49       1.00      0.50      0.67         2\n",
            "       31.61       1.00      0.71      0.83         7\n",
            "       31.73       1.00      0.86      0.92         7\n",
            "       32.12       1.00      1.00      1.00         9\n",
            "       32.33       1.00      1.00      1.00         6\n",
            "       32.37       1.00      1.00      1.00        37\n",
            "         7.3       0.97      0.97      0.97       330\n",
            "        7.36       0.98      0.98      0.98       637\n",
            "        7.69       0.98      0.97      0.98       176\n",
            "        7.72       0.97      0.97      0.97       281\n",
            "        8.05       0.97      0.99      0.98       486\n",
            "        8.38       0.96      0.94      0.95       274\n",
            "        8.41       0.98      0.99      0.99       240\n",
            "        8.74       1.00      0.81      0.90        32\n",
            "        9.07       0.93      0.92      0.92       258\n",
            "         9.4       0.93      0.92      0.92       349\n",
            "        9.73       0.96      0.95      0.95       431\n",
            "\n",
            "    accuracy                           0.97     18201\n",
            "   macro avg       0.97      0.93      0.95     18201\n",
            "weighted avg       0.97      0.97      0.97     18201\n",
            "\n",
            "The confusion matrix for Fish Length is: [[657   6   1 ...   0   2   4]\n",
            " [  1 485   2 ...   3   7   5]\n",
            " [  0   2 375 ...   8   3   1]\n",
            " ...\n",
            " [  0   3  10 ... 237   3   3]\n",
            " [  6   9   7 ...   2 320   3]\n",
            " [ 13   1   2 ...   0   5 408]]\n",
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "        10.5       0.93      0.91      0.92       349\n",
            "       103.4       1.00      1.00      1.00        19\n",
            "      107.53       1.00      0.83      0.91         6\n",
            "        11.4       0.95      0.95      0.95       431\n",
            "      110.66       1.00      0.94      0.97        18\n",
            "      114.79       0.95      1.00      0.97        39\n",
            "       118.0       1.00      0.80      0.89         5\n",
            "      118.66       0.99      1.00      0.99       417\n",
            "      119.32       0.97      0.99      0.98       474\n",
            "      119.98       0.98      0.95      0.96       300\n",
            "        12.3       0.97      0.98      0.97       671\n",
            "      120.64       0.93      0.98      0.96        56\n",
            "      122.58       1.00      1.00      1.00         4\n",
            "      123.24       0.98      1.00      0.99        60\n",
            "       127.2       0.97      0.97      0.97        31\n",
            "      130.98       0.89      0.80      0.84        49\n",
            "      134.76       0.92      0.95      0.93        98\n",
            "      138.54       0.95      1.00      0.97        19\n",
            "      142.32       0.97      0.94      0.95        33\n",
            "       146.1       0.98      0.96      0.97        56\n",
            "      149.88       0.94      0.97      0.95        65\n",
            "        15.8       0.95      0.96      0.96       505\n",
            "       17.68       0.94      0.96      0.95       389\n",
            "       19.56       0.50      0.33      0.40         3\n",
            "      200.46       0.94      0.98      0.96       124\n",
            "      205.55       0.99      0.98      0.98       633\n",
            "       21.44       0.97      0.98      0.98       266\n",
            "      210.64       0.99      0.99      0.99       596\n",
            "      215.73       0.98      0.99      0.99       863\n",
            "      220.82       0.99      0.99      0.99       838\n",
            "      225.91       0.98      0.99      0.99       574\n",
            "       23.32       0.95      0.89      0.92       138\n",
            "       231.0       0.99      1.00      1.00       592\n",
            "      236.09       0.98      0.99      0.99       380\n",
            "      241.18       1.00      0.84      0.91        19\n",
            "      246.27       0.92      0.88      0.90        26\n",
            "        25.2       0.87      0.87      0.87       190\n",
            "       251.4       1.00      1.00      1.00        28\n",
            "       253.9       0.95      1.00      0.98        21\n",
            "       256.4       0.95      0.91      0.93        22\n",
            "       258.9       1.00      0.87      0.93        15\n",
            "       261.4       1.00      0.91      0.95        11\n",
            "       263.9       0.95      0.88      0.91        24\n",
            "       266.4       1.00      0.93      0.97        15\n",
            "       268.9       1.00      1.00      1.00         5\n",
            "       27.08       0.86      0.90      0.88       319\n",
            "       271.4       1.00      0.50      0.67         2\n",
            "       273.9       1.00      0.71      0.83         7\n",
            "       276.4       1.00      0.86      0.92         7\n",
            "       28.96       0.83      0.88      0.85       301\n",
            "       286.4       1.00      1.00      1.00         9\n",
            "      295.58       1.00      1.00      1.00        37\n",
            "         3.2       0.98      0.97      0.97       330\n",
            "         3.3       0.98      0.98      0.98       637\n",
            "       30.84       0.90      0.82      0.86       256\n",
            "      304.76       1.00      1.00      1.00         6\n",
            "       32.72       0.95      0.93      0.94       358\n",
            "        34.6       0.91      0.89      0.90       308\n",
            "       36.48       0.77      0.84      0.80       206\n",
            "       38.36       0.99      0.98      0.98        89\n",
            "         4.2       0.98      0.97      0.98       176\n",
            "        42.1       0.98      0.98      0.98       217\n",
            "       43.39       0.95      0.91      0.93       182\n",
            "       45.27       0.96      0.96      0.96       385\n",
            "       46.56       0.98      0.99      0.99       387\n",
            "       47.85       0.99      0.99      0.99       631\n",
            "       49.14       0.99      0.99      0.99       596\n",
            "       49.43       0.99      0.98      0.99       325\n",
            "         5.1       0.97      0.96      0.97       281\n",
            "       51.72       0.99      1.00      0.99       382\n",
            "       53.01       1.00      1.00      1.00       275\n",
            "        54.3       0.98      0.94      0.96        63\n",
            "       55.59       0.92      0.94      0.93        35\n",
            "       56.88       1.00      0.87      0.93        15\n",
            "       58.17       0.88      1.00      0.94        15\n",
            "       59.46       0.99      0.99      0.99       241\n",
            "         6.0       0.96      0.99      0.97       486\n",
            "         6.9       0.97      0.93      0.95       274\n",
            "        60.2       0.98      0.99      0.99       234\n",
            "       64.33       1.00      1.00      1.00         3\n",
            "         7.8       0.98      0.99      0.99       240\n",
            "       76.72       1.00      1.00      1.00         6\n",
            "         8.7       1.00      0.84      0.92        32\n",
            "       80.85       1.00      1.00      1.00        28\n",
            "       89.01       0.90      1.00      0.95         9\n",
            "         9.6       0.93      0.92      0.93       258\n",
            "       93.14       1.00      0.92      0.96        13\n",
            "       97.27       1.00      1.00      1.00        63\n",
            "\n",
            "    accuracy                           0.96     18201\n",
            "   macro avg       0.96      0.94      0.95     18201\n",
            "weighted avg       0.97      0.96      0.96     18201\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[318   0   0 ...   2   0   0]\n",
            " [  0  19   0 ...   0   0   0]\n",
            " [  0   0   5 ...   0   0   0]\n",
            " ...\n",
            " [  1   0   0 ... 238   0   0]\n",
            " [  0   0   0 ...   0  12   0]\n",
            " [  0   0   0 ...   0   0  63]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8) Gradient Boosting Classifier"
      ],
      "metadata": {
        "id": "aQuSP14FH5SJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=GradientBoostingClassifier()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSgTgOOaHy5B",
        "outputId": "08790f9e-0afd-4c35-e3d7-87be8364ea7d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.06       0.28      0.01      0.02       671\n",
            "       11.93       0.37      0.35      0.36       505\n",
            "        12.3       0.17      0.07      0.10       389\n",
            "       12.67       0.00      0.00      0.00         3\n",
            "       13.04       0.25      0.01      0.01       266\n",
            "       13.41       0.05      0.07      0.06       138\n",
            "       13.78       0.03      0.01      0.01       190\n",
            "       14.45       0.00      0.00      0.00       319\n",
            "       14.82       0.00      0.00      0.00       301\n",
            "       15.19       0.11      0.18      0.14       256\n",
            "       15.56       0.00      0.00      0.00       358\n",
            "       15.93       0.13      0.02      0.03       308\n",
            "        16.3       0.09      0.01      0.03       206\n",
            "       16.67       0.00      0.00      0.00        89\n",
            "       17.04       0.00      0.00      0.00       217\n",
            "       17.12       0.00      0.00      0.00       182\n",
            "        17.2       0.53      0.38      0.44       385\n",
            "       17.28       0.00      0.00      0.00       387\n",
            "       17.36       0.62      0.01      0.02       631\n",
            "       17.44       0.87      0.26      0.40       596\n",
            "       17.52       0.27      0.18      0.22       325\n",
            "        17.6       0.20      0.52      0.29       382\n",
            "       17.68       0.00      0.00      0.00       275\n",
            "       17.76       0.00      0.00      0.00        63\n",
            "       17.84       0.00      0.00      0.00        35\n",
            "       17.92       0.00      0.07      0.00        15\n",
            "        18.0       0.12      0.20      0.15        15\n",
            "       18.08       0.00      0.00      0.00       241\n",
            "       18.14       0.04      0.10      0.06       234\n",
            "       18.51       0.00      0.00      0.00         3\n",
            "       19.52       0.00      0.00      0.00         6\n",
            "       19.89       0.00      0.00      0.00        28\n",
            "       20.53       0.00      0.00      0.00         9\n",
            "        20.9       0.00      0.00      0.00        13\n",
            "       21.27       0.01      0.17      0.02        63\n",
            "       21.64       0.00      0.00      0.00        19\n",
            "       22.01       0.00      0.00      0.00         6\n",
            "       22.38       0.06      0.39      0.11        18\n",
            "       22.75       0.00      0.00      0.00        39\n",
            "       23.33       0.03      0.80      0.06         5\n",
            "       23.42       0.35      0.59      0.44       417\n",
            "       23.51       0.00      0.00      0.00       474\n",
            "        23.6       0.00      0.00      0.00       300\n",
            "       23.69       0.00      0.00      0.00        56\n",
            "       23.96       0.00      0.00      0.00         4\n",
            "       24.05       0.00      0.00      0.00        60\n",
            "       24.53       0.00      0.00      0.00        31\n",
            "       24.76       0.00      0.00      0.00        49\n",
            "       24.99       0.00      0.00      0.00        98\n",
            "       25.32       0.02      0.42      0.03        19\n",
            "       25.55       0.00      0.00      0.00        33\n",
            "       25.78       0.00      0.00      0.00        56\n",
            "       26.01       0.00      0.00      0.00        65\n",
            "       28.55       0.02      0.05      0.02       124\n",
            "       28.74       0.01      0.01      0.01       633\n",
            "       28.93       0.03      0.00      0.01       596\n",
            "       29.12       0.07      0.26      0.11       863\n",
            "       29.31       0.20      0.06      0.09       838\n",
            "        29.5       0.00      0.00      0.00       574\n",
            "       29.69       0.05      0.04      0.04       592\n",
            "       29.88       0.00      0.00      0.00       380\n",
            "       30.07       0.01      0.05      0.02        19\n",
            "       30.26       0.00      0.00      0.00        26\n",
            "       30.46       0.00      0.00      0.00        28\n",
            "       30.58       0.00      0.00      0.00        21\n",
            "       30.77       0.00      0.00      0.00        22\n",
            "       30.89       0.00      0.00      0.00        15\n",
            "       31.01       0.00      0.00      0.00        11\n",
            "       31.13       0.00      0.00      0.00        24\n",
            "       31.25       0.00      0.00      0.00        15\n",
            "       31.37       0.00      0.00      0.00         5\n",
            "       31.49       0.00      0.00      0.00         2\n",
            "       31.61       0.00      0.00      0.00         7\n",
            "       31.73       0.00      0.00      0.00         7\n",
            "       32.12       0.00      0.00      0.00         9\n",
            "       32.33       0.00      0.00      0.00         6\n",
            "       32.37       0.60      0.08      0.14        37\n",
            "         7.3       0.00      0.00      0.00       330\n",
            "        7.36       0.77      0.70      0.73       637\n",
            "        7.69       0.05      0.06      0.06       176\n",
            "        7.72       0.00      0.00      0.00       281\n",
            "        8.05       0.00      0.00      0.00       486\n",
            "        8.38       0.00      0.00      0.00       274\n",
            "        8.41       0.00      0.00      0.00       240\n",
            "        8.74       0.00      0.00      0.00        32\n",
            "        9.07       0.00      0.00      0.00       258\n",
            "         9.4       0.01      0.01      0.01       349\n",
            "        9.73       0.02      0.07      0.03       431\n",
            "\n",
            "    accuracy                           0.11     18201\n",
            "   macro avg       0.07      0.07      0.05     18201\n",
            "weighted avg       0.16      0.11      0.10     18201\n",
            "\n",
            "The confusion matrix for Fish Length is: [[  7 117   0 ...   0   0 182]\n",
            " [  4 179   6 ...   0  25  64]\n",
            " [  0  55  27 ...   0 143  40]\n",
            " ...\n",
            " [  1   2   0 ...   0   0 125]\n",
            " [  4  22  13 ...   0   3 125]\n",
            " [  1  63   0 ...   0   0  30]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "        10.5       0.00      0.00      0.00       349\n",
            "       103.4       0.00      0.00      0.00        19\n",
            "      107.53       0.00      0.00      0.00         6\n",
            "        11.4       0.35      0.16      0.22       431\n",
            "      110.66       0.00      0.00      0.00        18\n",
            "      114.79       0.00      0.00      0.00        39\n",
            "       118.0       0.00      0.00      0.00         5\n",
            "      118.66       0.00      0.00      0.00       417\n",
            "      119.32       0.00      0.00      0.00       474\n",
            "      119.98       0.00      0.00      0.00       300\n",
            "        12.3       0.13      0.36      0.19       671\n",
            "      120.64       0.00      0.00      0.00        56\n",
            "      122.58       0.00      0.00      0.00         4\n",
            "      123.24       0.03      0.57      0.05        60\n",
            "       127.2       0.00      0.00      0.00        31\n",
            "      130.98       0.00      0.00      0.00        49\n",
            "      134.76       0.00      0.00      0.00        98\n",
            "      138.54       0.00      0.00      0.00        19\n",
            "      142.32       0.00      0.00      0.00        33\n",
            "       146.1       0.00      0.00      0.00        56\n",
            "      149.88       0.00      0.00      0.00        65\n",
            "        15.8       0.11      0.17      0.13       505\n",
            "       17.68       0.00      0.00      0.00       389\n",
            "       19.56       0.00      0.00      0.00         3\n",
            "      200.46       0.00      0.00      0.00       124\n",
            "      205.55       0.07      0.03      0.04       633\n",
            "       21.44       0.00      0.00      0.00       266\n",
            "      210.64       0.16      0.18      0.17       596\n",
            "      215.73       0.43      0.03      0.06       863\n",
            "      220.82       0.00      0.00      0.00       838\n",
            "      225.91       0.91      0.23      0.37       574\n",
            "       23.32       0.00      0.00      0.00       138\n",
            "       231.0       0.62      0.01      0.02       592\n",
            "      236.09       0.00      0.00      0.00       380\n",
            "      241.18       0.00      0.00      0.00        19\n",
            "      246.27       0.00      0.00      0.00        26\n",
            "        25.2       0.44      0.04      0.07       190\n",
            "       251.4       0.00      0.00      0.00        28\n",
            "       253.9       0.00      0.00      0.00        21\n",
            "       256.4       0.00      0.00      0.00        22\n",
            "       258.9       0.00      0.00      0.00        15\n",
            "       261.4       0.00      0.00      0.00        11\n",
            "       263.9       0.00      0.00      0.00        24\n",
            "       266.4       0.00      0.00      0.00        15\n",
            "       268.9       0.00      0.00      0.00         5\n",
            "       27.08       0.22      0.09      0.13       319\n",
            "       271.4       0.00      0.00      0.00         2\n",
            "       273.9       0.00      0.00      0.00         7\n",
            "       276.4       0.00      0.00      0.00         7\n",
            "       28.96       0.40      0.06      0.11       301\n",
            "       286.4       0.00      0.00      0.00         9\n",
            "      295.58       0.00      0.00      0.00        37\n",
            "         3.2       0.90      0.06      0.11       330\n",
            "         3.3       0.84      0.86      0.85       637\n",
            "       30.84       0.33      0.00      0.01       256\n",
            "      304.76       0.00      0.00      0.00         6\n",
            "       32.72       0.17      0.07      0.10       358\n",
            "        34.6       0.00      0.00      0.00       308\n",
            "       36.48       0.02      0.01      0.01       206\n",
            "       38.36       0.00      0.00      0.00        89\n",
            "         4.2       0.54      0.89      0.68       176\n",
            "        42.1       0.00      0.00      0.00       217\n",
            "       43.39       0.05      0.04      0.04       182\n",
            "       45.27       0.09      0.04      0.05       385\n",
            "       46.56       0.65      0.47      0.54       387\n",
            "       47.85       0.80      0.60      0.68       631\n",
            "       49.14       0.00      0.00      0.00       596\n",
            "       49.43       0.00      0.00      0.00       325\n",
            "         5.1       0.22      0.20      0.21       281\n",
            "       51.72       0.00      0.00      0.00       382\n",
            "       53.01       0.00      0.00      0.00       275\n",
            "        54.3       0.00      0.00      0.00        63\n",
            "       55.59       0.00      0.11      0.00        35\n",
            "       56.88       0.00      0.00      0.00        15\n",
            "       58.17       0.00      0.00      0.00        15\n",
            "       59.46       0.62      0.43      0.51       241\n",
            "         6.0       0.35      0.03      0.05       486\n",
            "         6.9       0.01      0.07      0.02       274\n",
            "        60.2       0.00      0.00      0.00       234\n",
            "       64.33       0.00      0.00      0.00         3\n",
            "         7.8       0.30      0.51      0.38       240\n",
            "       76.72       0.00      0.00      0.00         6\n",
            "         8.7       0.01      0.03      0.02        32\n",
            "       80.85       0.00      0.00      0.00        28\n",
            "       89.01       0.00      0.00      0.00         9\n",
            "         9.6       0.00      0.00      0.00       258\n",
            "       93.14       0.00      0.00      0.00        13\n",
            "       97.27       0.00      0.00      0.00        63\n",
            "\n",
            "    accuracy                           0.13     18201\n",
            "   macro avg       0.11      0.07      0.07     18201\n",
            "weighted avg       0.24      0.13      0.14     18201\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9) Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "VEJoRilYH8W6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=MultinomialNB()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm2vqmDBH4kI",
        "outputId": "f542086f-fdf4-4d39-b393-ee2ae7567007"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.06       0.10      0.66      0.18       671\n",
            "       11.93       0.00      0.00      0.00       505\n",
            "        12.3       0.00      0.00      0.00       389\n",
            "       12.67       0.00      0.00      0.00         3\n",
            "       13.04       0.00      0.00      0.00       266\n",
            "       13.41       0.00      0.00      0.00       138\n",
            "       13.78       0.00      0.00      0.00       190\n",
            "       14.45       0.00      0.00      0.00       319\n",
            "       14.82       0.00      0.00      0.00       301\n",
            "       15.19       0.00      0.00      0.00       256\n",
            "       15.56       0.00      0.00      0.00       358\n",
            "       15.93       0.00      0.00      0.00       308\n",
            "        16.3       0.00      0.00      0.00       206\n",
            "       16.67       0.00      0.00      0.00        89\n",
            "       17.04       0.00      0.00      0.00       217\n",
            "       17.12       0.00      0.00      0.00       182\n",
            "        17.2       0.00      0.00      0.00       385\n",
            "       17.28       0.00      0.00      0.00       387\n",
            "       17.36       0.13      0.99      0.23       631\n",
            "       17.44       0.00      0.00      0.00       596\n",
            "       17.52       0.00      0.00      0.00       325\n",
            "        17.6       0.00      0.00      0.00       382\n",
            "       17.68       0.00      0.00      0.00       275\n",
            "       17.76       0.00      0.00      0.00        63\n",
            "       17.84       0.00      0.00      0.00        35\n",
            "       17.92       0.00      0.00      0.00        15\n",
            "        18.0       0.00      0.00      0.00        15\n",
            "       18.08       0.00      0.00      0.00       241\n",
            "       18.14       0.00      0.00      0.00       234\n",
            "       18.51       0.00      0.00      0.00         3\n",
            "       19.52       0.00      0.00      0.00         6\n",
            "       19.89       0.00      0.00      0.00        28\n",
            "       20.53       0.00      0.00      0.00         9\n",
            "        20.9       0.00      0.00      0.00        13\n",
            "       21.27       0.00      0.00      0.00        63\n",
            "       21.64       0.00      0.00      0.00        19\n",
            "       22.01       0.00      0.00      0.00         6\n",
            "       22.38       0.00      0.00      0.00        18\n",
            "       22.75       0.00      0.00      0.00        39\n",
            "       23.33       0.00      0.00      0.00         5\n",
            "       23.42       0.00      0.00      0.00       417\n",
            "       23.51       0.00      0.00      0.00       474\n",
            "        23.6       0.00      0.00      0.00       300\n",
            "       23.69       0.00      0.00      0.00        56\n",
            "       23.96       0.00      0.00      0.00         4\n",
            "       24.05       0.00      0.00      0.00        60\n",
            "       24.53       0.00      0.00      0.00        31\n",
            "       24.76       0.00      0.00      0.00        49\n",
            "       24.99       0.00      0.00      0.00        98\n",
            "       25.32       0.00      0.00      0.00        19\n",
            "       25.55       0.00      0.00      0.00        33\n",
            "       25.78       0.00      0.00      0.00        56\n",
            "       26.01       0.00      0.00      0.00        65\n",
            "       28.55       0.00      0.00      0.00       124\n",
            "       28.74       0.00      0.00      0.00       633\n",
            "       28.93       0.00      0.00      0.00       596\n",
            "       29.12       0.14      1.00      0.24       863\n",
            "       29.31       0.00      0.00      0.00       838\n",
            "        29.5       0.00      0.00      0.00       574\n",
            "       29.69       0.00      0.00      0.00       592\n",
            "       29.88       0.00      0.00      0.00       380\n",
            "       30.07       0.00      0.00      0.00        19\n",
            "       30.26       0.00      0.00      0.00        26\n",
            "       30.46       0.00      0.00      0.00        28\n",
            "       30.58       0.00      0.00      0.00        21\n",
            "       30.77       0.00      0.00      0.00        22\n",
            "       30.89       0.00      0.00      0.00        15\n",
            "       31.01       0.00      0.00      0.00        11\n",
            "       31.13       0.00      0.00      0.00        24\n",
            "       31.25       0.00      0.00      0.00        15\n",
            "       31.37       0.00      0.00      0.00         5\n",
            "       31.49       0.00      0.00      0.00         2\n",
            "       31.61       0.00      0.00      0.00         7\n",
            "       31.73       0.00      0.00      0.00         7\n",
            "       32.12       0.00      0.00      0.00         9\n",
            "       32.33       0.00      0.00      0.00         6\n",
            "       32.37       0.00      0.00      0.00        37\n",
            "         7.3       0.00      0.00      0.00       330\n",
            "        7.36       0.31      0.76      0.44       637\n",
            "        7.69       0.00      0.00      0.00       176\n",
            "        7.72       0.00      0.00      0.00       281\n",
            "        8.05       0.00      0.00      0.00       486\n",
            "        8.38       0.00      0.00      0.00       274\n",
            "        8.41       0.00      0.00      0.00       240\n",
            "        8.74       0.00      0.00      0.00        32\n",
            "        9.07       0.00      0.00      0.00       258\n",
            "         9.4       0.00      0.00      0.00       349\n",
            "        9.73       0.00      0.00      0.00       431\n",
            "\n",
            "    accuracy                           0.13     18201\n",
            "   macro avg       0.01      0.04      0.01     18201\n",
            "weighted avg       0.03      0.13      0.04     18201\n",
            "\n",
            "The confusion matrix for Fish Length is: [[443   0   0 ...   0   0   0]\n",
            " [240   0   0 ...   0   0   0]\n",
            " [224   0   0 ...   0   0   0]\n",
            " ...\n",
            " [204   0   0 ...   0   0   0]\n",
            " [218   0   0 ...   0   0   0]\n",
            " [287   0   0 ...   0   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "        10.5       0.00      0.00      0.00       349\n",
            "       103.4       0.00      0.00      0.00        19\n",
            "      107.53       0.00      0.00      0.00         6\n",
            "        11.4       0.00      0.00      0.00       431\n",
            "      110.66       0.00      0.00      0.00        18\n",
            "      114.79       0.00      0.00      0.00        39\n",
            "       118.0       0.00      0.00      0.00         5\n",
            "      118.66       0.00      0.00      0.00       417\n",
            "      119.32       0.00      0.00      0.00       474\n",
            "      119.98       0.00      0.00      0.00       300\n",
            "        12.3       0.10      0.66      0.18       671\n",
            "      120.64       0.00      0.00      0.00        56\n",
            "      122.58       0.00      0.00      0.00         4\n",
            "      123.24       0.00      0.00      0.00        60\n",
            "       127.2       0.00      0.00      0.00        31\n",
            "      130.98       0.00      0.00      0.00        49\n",
            "      134.76       0.00      0.00      0.00        98\n",
            "      138.54       0.00      0.00      0.00        19\n",
            "      142.32       0.00      0.00      0.00        33\n",
            "       146.1       0.00      0.00      0.00        56\n",
            "      149.88       0.00      0.00      0.00        65\n",
            "        15.8       0.00      0.00      0.00       505\n",
            "       17.68       0.00      0.00      0.00       389\n",
            "       19.56       0.00      0.00      0.00         3\n",
            "      200.46       0.00      0.00      0.00       124\n",
            "      205.55       0.00      0.00      0.00       633\n",
            "       21.44       0.00      0.00      0.00       266\n",
            "      210.64       0.00      0.00      0.00       596\n",
            "      215.73       0.14      1.00      0.24       863\n",
            "      220.82       0.00      0.00      0.00       838\n",
            "      225.91       0.00      0.00      0.00       574\n",
            "       23.32       0.00      0.00      0.00       138\n",
            "       231.0       0.00      0.00      0.00       592\n",
            "      236.09       0.00      0.00      0.00       380\n",
            "      241.18       0.00      0.00      0.00        19\n",
            "      246.27       0.00      0.00      0.00        26\n",
            "        25.2       0.00      0.00      0.00       190\n",
            "       251.4       0.00      0.00      0.00        28\n",
            "       253.9       0.00      0.00      0.00        21\n",
            "       256.4       0.00      0.00      0.00        22\n",
            "       258.9       0.00      0.00      0.00        15\n",
            "       261.4       0.00      0.00      0.00        11\n",
            "       263.9       0.00      0.00      0.00        24\n",
            "       266.4       0.00      0.00      0.00        15\n",
            "       268.9       0.00      0.00      0.00         5\n",
            "       27.08       0.00      0.00      0.00       319\n",
            "       271.4       0.00      0.00      0.00         2\n",
            "       273.9       0.00      0.00      0.00         7\n",
            "       276.4       0.00      0.00      0.00         7\n",
            "       28.96       0.00      0.00      0.00       301\n",
            "       286.4       0.00      0.00      0.00         9\n",
            "      295.58       0.00      0.00      0.00        37\n",
            "         3.2       0.00      0.00      0.00       330\n",
            "         3.3       0.31      0.76      0.44       637\n",
            "       30.84       0.00      0.00      0.00       256\n",
            "      304.76       0.00      0.00      0.00         6\n",
            "       32.72       0.00      0.00      0.00       358\n",
            "        34.6       0.00      0.00      0.00       308\n",
            "       36.48       0.00      0.00      0.00       206\n",
            "       38.36       0.00      0.00      0.00        89\n",
            "         4.2       0.00      0.00      0.00       176\n",
            "        42.1       0.00      0.00      0.00       217\n",
            "       43.39       0.00      0.00      0.00       182\n",
            "       45.27       0.00      0.00      0.00       385\n",
            "       46.56       0.00      0.00      0.00       387\n",
            "       47.85       0.13      0.99      0.23       631\n",
            "       49.14       0.00      0.00      0.00       596\n",
            "       49.43       0.00      0.00      0.00       325\n",
            "         5.1       0.00      0.00      0.00       281\n",
            "       51.72       0.00      0.00      0.00       382\n",
            "       53.01       0.00      0.00      0.00       275\n",
            "        54.3       0.00      0.00      0.00        63\n",
            "       55.59       0.00      0.00      0.00        35\n",
            "       56.88       0.00      0.00      0.00        15\n",
            "       58.17       0.00      0.00      0.00        15\n",
            "       59.46       0.00      0.00      0.00       241\n",
            "         6.0       0.00      0.00      0.00       486\n",
            "         6.9       0.00      0.00      0.00       274\n",
            "        60.2       0.00      0.00      0.00       234\n",
            "       64.33       0.00      0.00      0.00         3\n",
            "         7.8       0.00      0.00      0.00       240\n",
            "       76.72       0.00      0.00      0.00         6\n",
            "         8.7       0.00      0.00      0.00        32\n",
            "       80.85       0.00      0.00      0.00        28\n",
            "       89.01       0.00      0.00      0.00         9\n",
            "         9.6       0.00      0.00      0.00       258\n",
            "       93.14       0.00      0.00      0.00        13\n",
            "       97.27       0.00      0.00      0.00        63\n",
            "\n",
            "    accuracy                           0.13     18201\n",
            "   macro avg       0.01      0.04      0.01     18201\n",
            "weighted avg       0.03      0.13      0.04     18201\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    }
  ]
}