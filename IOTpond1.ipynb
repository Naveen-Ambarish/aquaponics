{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "As the initial step, import the required libraries that we require to perform the tasks like preprocessing, training our model and predicting the accuracy score of our model"
      ],
      "metadata": {
        "id": "p8jFb88Xo0xS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZVaxO9jx4DiS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,precision_score,recall_score,f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the dataset to the simulation software and to view the first 5 rows of our dataset we used head function in pandas dataframe"
      ],
      "metadata": {
        "id": "v8gyXhxfo8cJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/aquaponics/IoTpond1.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "JWdYLsey7oNk",
        "outputId": "70710ce6-e67a-4616-d621-1e748c03cf54"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                created_at  entry_id  Temperature (C)  Turbidity(NTU)  \\\n",
              "0  2021-06-19 00:00:05 CET      1889          24.8750             100   \n",
              "1  2021-06-19 00:01:02 CET      1890          24.9375             100   \n",
              "2  2021-06-19 00:01:22 CET      1891          24.8750             100   \n",
              "3  2021-06-19 00:01:44 CET      1892          24.9375             100   \n",
              "4  2021-06-19 00:02:07 CET      1893          24.9375             100   \n",
              "\n",
              "   Dissolved Oxygen(g/ml)       PH  Ammonia(g/ml)  Nitrate(g/ml)  Population  \\\n",
              "0                   4.505  8.43365        0.45842            193          50   \n",
              "1                   6.601  8.43818        0.45842            194          50   \n",
              "2                  15.797  8.42457        0.45842            192          50   \n",
              "3                   5.046  8.43365        0.45842            193          50   \n",
              "4                  38.407  8.40641        0.45842            192          50   \n",
              "\n",
              "   Fish_Length(cm)  Fish_Weight(g)  \n",
              "0             7.11            2.91  \n",
              "1             7.11            2.91  \n",
              "2             7.11            2.91  \n",
              "3             7.11            2.91  \n",
              "4             7.11            2.91  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a345da9b-af3f-4ad2-802c-405a26823a7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>entry_id</th>\n",
              "      <th>Temperature (C)</th>\n",
              "      <th>Turbidity(NTU)</th>\n",
              "      <th>Dissolved Oxygen(g/ml)</th>\n",
              "      <th>PH</th>\n",
              "      <th>Ammonia(g/ml)</th>\n",
              "      <th>Nitrate(g/ml)</th>\n",
              "      <th>Population</th>\n",
              "      <th>Fish_Length(cm)</th>\n",
              "      <th>Fish_Weight(g)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-06-19 00:00:05 CET</td>\n",
              "      <td>1889</td>\n",
              "      <td>24.8750</td>\n",
              "      <td>100</td>\n",
              "      <td>4.505</td>\n",
              "      <td>8.43365</td>\n",
              "      <td>0.45842</td>\n",
              "      <td>193</td>\n",
              "      <td>50</td>\n",
              "      <td>7.11</td>\n",
              "      <td>2.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-19 00:01:02 CET</td>\n",
              "      <td>1890</td>\n",
              "      <td>24.9375</td>\n",
              "      <td>100</td>\n",
              "      <td>6.601</td>\n",
              "      <td>8.43818</td>\n",
              "      <td>0.45842</td>\n",
              "      <td>194</td>\n",
              "      <td>50</td>\n",
              "      <td>7.11</td>\n",
              "      <td>2.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-06-19 00:01:22 CET</td>\n",
              "      <td>1891</td>\n",
              "      <td>24.8750</td>\n",
              "      <td>100</td>\n",
              "      <td>15.797</td>\n",
              "      <td>8.42457</td>\n",
              "      <td>0.45842</td>\n",
              "      <td>192</td>\n",
              "      <td>50</td>\n",
              "      <td>7.11</td>\n",
              "      <td>2.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-06-19 00:01:44 CET</td>\n",
              "      <td>1892</td>\n",
              "      <td>24.9375</td>\n",
              "      <td>100</td>\n",
              "      <td>5.046</td>\n",
              "      <td>8.43365</td>\n",
              "      <td>0.45842</td>\n",
              "      <td>193</td>\n",
              "      <td>50</td>\n",
              "      <td>7.11</td>\n",
              "      <td>2.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-06-19 00:02:07 CET</td>\n",
              "      <td>1893</td>\n",
              "      <td>24.9375</td>\n",
              "      <td>100</td>\n",
              "      <td>38.407</td>\n",
              "      <td>8.40641</td>\n",
              "      <td>0.45842</td>\n",
              "      <td>192</td>\n",
              "      <td>50</td>\n",
              "      <td>7.11</td>\n",
              "      <td>2.91</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a345da9b-af3f-4ad2-802c-405a26823a7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a345da9b-af3f-4ad2-802c-405a26823a7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a345da9b-af3f-4ad2-802c-405a26823a7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "37G02guTILGp",
        "outputId": "23cbaa4b-0365-480a-ebf8-b6545dca2dea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            entry_id  Temperature (C)  Turbidity(NTU)  Dissolved Oxygen(g/ml)  \\\n",
              "count   83126.000000     83126.000000    83126.000000            83126.000000   \n",
              "mean    84018.144516        24.573376       87.490160               12.390251   \n",
              "std     53579.484245         0.861532       25.859375               12.518253   \n",
              "min      1889.000000      -127.000000        1.000000                0.007000   \n",
              "25%     24902.250000        24.125000       91.000000                3.440000   \n",
              "50%    103478.500000        24.562500      100.000000                7.133000   \n",
              "75%    131074.750000        24.937500      100.000000               15.819000   \n",
              "max    247405.000000        27.750000      100.000000               41.046000   \n",
              "\n",
              "                 PH  Ammonia(g/ml)  Nitrate(g/ml)  Population  \\\n",
              "count  83126.000000   8.307400e+04   83126.000000     83126.0   \n",
              "mean       7.518329   2.030817e+08     458.294408        50.0   \n",
              "std        0.534787   7.866231e+09     338.313206         0.0   \n",
              "min       -0.586270   6.770000e-03      45.000000        50.0   \n",
              "25%        7.153520   4.584200e-01     146.000000        50.0   \n",
              "50%        7.357790   6.116600e-01     347.000000        50.0   \n",
              "75%        7.838980   1.558803e+01     823.000000        50.0   \n",
              "max        8.551670   4.270000e+11    1936.000000        50.0   \n",
              "\n",
              "       Fish_Length(cm)  Fish_Weight(g)  \n",
              "count     83124.000000     83124.00000  \n",
              "mean         16.414686        44.56847  \n",
              "std           5.272244        33.21549  \n",
              "min           7.110000         2.91000  \n",
              "25%          11.790000        14.19000  \n",
              "50%          18.080000        54.70000  \n",
              "75%          21.000000        67.52000  \n",
              "max          33.450000       318.64000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36a14a6f-12de-43b4-b5bd-dd334b445d30\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entry_id</th>\n",
              "      <th>Temperature (C)</th>\n",
              "      <th>Turbidity(NTU)</th>\n",
              "      <th>Dissolved Oxygen(g/ml)</th>\n",
              "      <th>PH</th>\n",
              "      <th>Ammonia(g/ml)</th>\n",
              "      <th>Nitrate(g/ml)</th>\n",
              "      <th>Population</th>\n",
              "      <th>Fish_Length(cm)</th>\n",
              "      <th>Fish_Weight(g)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>83126.000000</td>\n",
              "      <td>83126.000000</td>\n",
              "      <td>83126.000000</td>\n",
              "      <td>83126.000000</td>\n",
              "      <td>83126.000000</td>\n",
              "      <td>8.307400e+04</td>\n",
              "      <td>83126.000000</td>\n",
              "      <td>83126.0</td>\n",
              "      <td>83124.000000</td>\n",
              "      <td>83124.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>84018.144516</td>\n",
              "      <td>24.573376</td>\n",
              "      <td>87.490160</td>\n",
              "      <td>12.390251</td>\n",
              "      <td>7.518329</td>\n",
              "      <td>2.030817e+08</td>\n",
              "      <td>458.294408</td>\n",
              "      <td>50.0</td>\n",
              "      <td>16.414686</td>\n",
              "      <td>44.56847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>53579.484245</td>\n",
              "      <td>0.861532</td>\n",
              "      <td>25.859375</td>\n",
              "      <td>12.518253</td>\n",
              "      <td>0.534787</td>\n",
              "      <td>7.866231e+09</td>\n",
              "      <td>338.313206</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.272244</td>\n",
              "      <td>33.21549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1889.000000</td>\n",
              "      <td>-127.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.007000</td>\n",
              "      <td>-0.586270</td>\n",
              "      <td>6.770000e-03</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>50.0</td>\n",
              "      <td>7.110000</td>\n",
              "      <td>2.91000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>24902.250000</td>\n",
              "      <td>24.125000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>3.440000</td>\n",
              "      <td>7.153520</td>\n",
              "      <td>4.584200e-01</td>\n",
              "      <td>146.000000</td>\n",
              "      <td>50.0</td>\n",
              "      <td>11.790000</td>\n",
              "      <td>14.19000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>103478.500000</td>\n",
              "      <td>24.562500</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>7.133000</td>\n",
              "      <td>7.357790</td>\n",
              "      <td>6.116600e-01</td>\n",
              "      <td>347.000000</td>\n",
              "      <td>50.0</td>\n",
              "      <td>18.080000</td>\n",
              "      <td>54.70000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>131074.750000</td>\n",
              "      <td>24.937500</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>15.819000</td>\n",
              "      <td>7.838980</td>\n",
              "      <td>1.558803e+01</td>\n",
              "      <td>823.000000</td>\n",
              "      <td>50.0</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>67.52000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>247405.000000</td>\n",
              "      <td>27.750000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>41.046000</td>\n",
              "      <td>8.551670</td>\n",
              "      <td>4.270000e+11</td>\n",
              "      <td>1936.000000</td>\n",
              "      <td>50.0</td>\n",
              "      <td>33.450000</td>\n",
              "      <td>318.64000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36a14a6f-12de-43b4-b5bd-dd334b445d30')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-36a14a6f-12de-43b4-b5bd-dd334b445d30 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-36a14a6f-12de-43b4-b5bd-dd334b445d30');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check for the null values present in our dataset we use isnull() function"
      ],
      "metadata": {
        "id": "Sd1lbg8ApCvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "660RTHky79-V",
        "outputId": "4fac37d9-dcbf-4920-a7cc-952fff376652"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "created_at                 0\n",
              "entry_id                   0\n",
              "Temperature (C)            0\n",
              "Turbidity(NTU)             0\n",
              "Dissolved Oxygen(g/ml)     0\n",
              "PH                         0\n",
              "Ammonia(g/ml)             52\n",
              "Nitrate(g/ml)              0\n",
              "Population                 0\n",
              "Fish_Length(cm)            2\n",
              "Fish_Weight(g)             2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From our model we find that the fish length and fish weight are the output parameters and the rest are to be taken as input. So, the null values in the fish length and fish weight columns, their corresponding rows are being removed and for ammonia the null value rows are filled with their mean values"
      ],
      "metadata": {
        "id": "BauxwhhEpLY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df[df['Fish_Weight(g)'].notna()]\n",
        "df=df[df['Fish_Length(cm)'].notna()]\n",
        "df=df.fillna(df.mean())"
      ],
      "metadata": {
        "id": "RyKVVCpM8v3J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed88e9e5-995d-46f7-e207-c6a20efc43c3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-335d705a341e>:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  df=df.fillna(df.mean())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop all the unnecessary columns from the dataset"
      ],
      "metadata": {
        "id": "lLq6Kz-cpZfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(columns='Population')\n",
        "df=df.drop(columns='created_at')\n",
        "df=df.drop(columns='entry_id')"
      ],
      "metadata": {
        "id": "N8DHs81t99jU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the datatype of each columns in our dataset"
      ],
      "metadata": {
        "id": "ytSW47kww7Y1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "QzKlBUUI_rLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28e3bb77-c851-4753-870f-4ddaf4c78d8b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 83124 entries, 0 to 83125\n",
            "Data columns (total 8 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   Temperature (C)         83124 non-null  float64\n",
            " 1   Turbidity(NTU)          83124 non-null  int64  \n",
            " 2   Dissolved Oxygen(g/ml)  83124 non-null  float64\n",
            " 3   PH                      83124 non-null  float64\n",
            " 4   Ammonia(g/ml)           83124 non-null  float64\n",
            " 5   Nitrate(g/ml)           83124 non-null  int64  \n",
            " 6   Fish_Length(cm)         83124 non-null  float64\n",
            " 7   Fish_Weight(g)          83124 non-null  float64\n",
            "dtypes: float64(6), int64(2)\n",
            "memory usage: 5.7 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that our classifications labels fish_length and fish_weight are in float variables and we need to convert them to string."
      ],
      "metadata": {
        "id": "lGDu9kXBMBh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.astype({\"Fish_Length(cm)\":'str',\"Fish_Weight(g)\":'str'})"
      ],
      "metadata": {
        "id": "L57CYLv6MPnW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the corelation between the input variables"
      ],
      "metadata": {
        "id": "2eqSfczBi-4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "NaIbaUxyjHk_",
        "outputId": "1786db04-7ada-42e7-9c7a-7c461310898b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Temperature (C)  Turbidity(NTU)  \\\n",
              "Temperature (C)                1.000000        0.074850   \n",
              "Turbidity(NTU)                 0.074850        1.000000   \n",
              "Dissolved Oxygen(g/ml)         0.098474       -0.623254   \n",
              "PH                             0.302397        0.222368   \n",
              "Ammonia(g/ml)                  0.004518        0.012494   \n",
              "Nitrate(g/ml)                 -0.372848       -0.124813   \n",
              "\n",
              "                        Dissolved Oxygen(g/ml)        PH  Ammonia(g/ml)  \\\n",
              "Temperature (C)                       0.098474  0.302397       0.004518   \n",
              "Turbidity(NTU)                       -0.623254  0.222368       0.012494   \n",
              "Dissolved Oxygen(g/ml)                1.000000  0.005328      -0.008907   \n",
              "PH                                    0.005328  1.000000       0.011411   \n",
              "Ammonia(g/ml)                        -0.008907  0.011411       1.000000   \n",
              "Nitrate(g/ml)                        -0.101527 -0.695458      -0.024748   \n",
              "\n",
              "                        Nitrate(g/ml)  \n",
              "Temperature (C)             -0.372848  \n",
              "Turbidity(NTU)              -0.124813  \n",
              "Dissolved Oxygen(g/ml)      -0.101527  \n",
              "PH                          -0.695458  \n",
              "Ammonia(g/ml)               -0.024748  \n",
              "Nitrate(g/ml)                1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df5106ca-9361-4906-b6e8-2ee5bb144876\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temperature (C)</th>\n",
              "      <th>Turbidity(NTU)</th>\n",
              "      <th>Dissolved Oxygen(g/ml)</th>\n",
              "      <th>PH</th>\n",
              "      <th>Ammonia(g/ml)</th>\n",
              "      <th>Nitrate(g/ml)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Temperature (C)</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.074850</td>\n",
              "      <td>0.098474</td>\n",
              "      <td>0.302397</td>\n",
              "      <td>0.004518</td>\n",
              "      <td>-0.372848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Turbidity(NTU)</th>\n",
              "      <td>0.074850</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.623254</td>\n",
              "      <td>0.222368</td>\n",
              "      <td>0.012494</td>\n",
              "      <td>-0.124813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dissolved Oxygen(g/ml)</th>\n",
              "      <td>0.098474</td>\n",
              "      <td>-0.623254</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.005328</td>\n",
              "      <td>-0.008907</td>\n",
              "      <td>-0.101527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PH</th>\n",
              "      <td>0.302397</td>\n",
              "      <td>0.222368</td>\n",
              "      <td>0.005328</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.011411</td>\n",
              "      <td>-0.695458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ammonia(g/ml)</th>\n",
              "      <td>0.004518</td>\n",
              "      <td>0.012494</td>\n",
              "      <td>-0.008907</td>\n",
              "      <td>0.011411</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.024748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nitrate(g/ml)</th>\n",
              "      <td>-0.372848</td>\n",
              "      <td>-0.124813</td>\n",
              "      <td>-0.101527</td>\n",
              "      <td>-0.695458</td>\n",
              "      <td>-0.024748</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df5106ca-9361-4906-b6e8-2ee5bb144876')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df5106ca-9361-4906-b6e8-2ee5bb144876 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df5106ca-9361-4906-b6e8-2ee5bb144876');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=df.drop(columns=['Fish_Length(cm)','Fish_Weight(g)'])\n",
        "y=df.drop(columns=['Temperature (C)','Turbidity(NTU)','Dissolved Oxygen(g/ml)','PH','Ammonia(g/ml)','Nitrate(g/ml)'])\n",
        "y1=y['Fish_Length(cm)']\n",
        "y2=y['Fish_Weight(g)']"
      ],
      "metadata": {
        "id": "QW3eHLD3fkb8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y1 corresponds to the model for fish length label and Y2 corresponds to the model for fish weight label. Splitting the data for training and testing"
      ],
      "metadata": {
        "id": "cvH6KEn3M6sQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,Y1_train,Y1_test=train_test_split(x,y1,test_size=0.2,random_state=0)\n",
        "X_train,X_test,Y2_train,Y2_test=train_test_split(x,y2,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "_6wf5X9wInwD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling of data"
      ],
      "metadata": {
        "id": "1UZgkelHVO-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "eLxHuXzyVOeV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Logistic regression"
      ],
      "metadata": {
        "id": "Gv4uNLSCIV-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=LogisticRegression(multi_class='multinomial')\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57aMezx4SC5W",
        "outputId": "c0358ab6-a38e-4e29-e3ba-cdfa40a18e7b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.62       0.00      0.00      0.00       180\n",
            "       11.01       0.27      0.87      0.42       770\n",
            "        11.4       0.00      0.00      0.00       454\n",
            "       11.79       0.16      0.42      0.23       811\n",
            "       12.09       0.00      0.00      0.00        39\n",
            "       12.18       0.20      0.10      0.14       631\n",
            "       14.16       0.00      0.00      0.00       121\n",
            "       14.39       0.00      0.00      0.00       271\n",
            "       14.62       0.00      0.00      0.00       197\n",
            "       14.85       0.00      0.00      0.00       314\n",
            "       15.31       0.00      0.00      0.00       137\n",
            "       15.54       0.00      0.00      0.00        49\n",
            "       15.73       0.00      0.00      0.00       202\n",
            "       15.96       0.00      0.00      0.00       150\n",
            "       16.19       0.00      0.00      0.00       163\n",
            "       16.42       0.00      0.00      0.00        75\n",
            "       16.65       0.00      0.00      0.00        23\n",
            "       16.88       0.00      0.00      0.00        66\n",
            "       17.11       0.00      0.00      0.00       113\n",
            "       17.34       0.00      0.00      0.00       136\n",
            "       17.57       0.14      0.29      0.19       180\n",
            "        17.8       0.00      0.00      0.00       165\n",
            "       18.03       0.00      0.00      0.00       176\n",
            "       18.08       0.00      0.00      0.00       274\n",
            "       18.26       0.26      0.62      0.37       256\n",
            "       18.49       0.92      0.71      0.80       250\n",
            "       18.72       0.59      0.67      0.63       681\n",
            "       18.92       0.48      0.55      0.51       542\n",
            "       19.18       0.00      0.00      0.00       145\n",
            "       19.44       0.60      0.68      0.64       339\n",
            "        19.7       0.56      0.62      0.59       437\n",
            "       19.96       0.46      0.40      0.42       364\n",
            "       20.22       0.50      0.42      0.46       566\n",
            "       20.48       0.00      0.00      0.00         2\n",
            "       20.74       0.00      0.00      0.00       279\n",
            "        21.0       0.57      0.33      0.42       456\n",
            "       21.26       0.26      0.37      0.31       385\n",
            "       21.52       0.23      0.55      0.32       759\n",
            "       21.78       0.35      0.62      0.45       608\n",
            "       22.04       0.28      0.14      0.19       564\n",
            "        22.3       0.00      0.00      0.00       525\n",
            "       22.52       0.30      0.44      0.36       526\n",
            "       22.63       0.00      0.00      0.00       162\n",
            "       22.74       0.00      0.00      0.00        52\n",
            "       22.85       0.00      0.00      0.00        58\n",
            "       22.96       0.00      0.00      0.00        17\n",
            "       23.18       0.00      0.00      0.00         7\n",
            "        23.4       0.00      0.00      0.00        21\n",
            "       23.93       0.00      0.00      0.00        15\n",
            "       23.95       0.00      0.00      0.00        18\n",
            "       24.09       0.00      0.00      0.00        39\n",
            "       24.35       0.00      0.00      0.00        32\n",
            "        24.6       0.00      0.00      0.00        65\n",
            "       24.85       0.00      0.00      0.00        15\n",
            "        25.1       0.00      0.00      0.00         7\n",
            "        25.6       0.00      0.00      0.00        14\n",
            "       25.85       0.00      0.00      0.00        33\n",
            "        28.8       0.00      0.00      0.00         4\n",
            "       29.07       0.00      0.00      0.00         2\n",
            "       29.34       0.00      0.00      0.00         4\n",
            "       29.61       0.00      0.00      0.00        12\n",
            "       29.87       0.00      0.00      0.00         6\n",
            "       31.23       0.00      0.00      0.00         3\n",
            "       31.57       0.00      0.00      0.00         1\n",
            "       31.82       0.00      0.00      0.00         1\n",
            "       31.93       0.00      0.00      0.00         1\n",
            "       33.31       0.00      0.00      0.00         6\n",
            "       33.38       0.47      0.76      0.58        34\n",
            "       33.45       0.00      0.00      0.00         3\n",
            "        7.11       0.66      0.68      0.67       613\n",
            "         7.5       0.32      0.65      0.43       602\n",
            "        7.89       0.00      0.00      0.00       237\n",
            "        8.28       0.00      0.00      0.00       224\n",
            "        8.67       0.52      0.73      0.61       489\n",
            "        9.06       0.00      0.00      0.00       273\n",
            "        9.45       0.00      0.00      0.00       174\n",
            "\n",
            "    accuracy                           0.34     16625\n",
            "   macro avg       0.12      0.15      0.13     16625\n",
            "weighted avg       0.26      0.34      0.28     16625\n",
            "\n",
            "The confusion matrix for Fish Length is: [[  0  74   0 ...   0   0   0]\n",
            " [  0 673   0 ...   0   0   0]\n",
            " [  0 245   0 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ... 357   0   0]\n",
            " [  0   9   0 ...  89   0   0]\n",
            " [  0  33   0 ...  89   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "      101.57       0.00      0.00      0.00        21\n",
            "       11.37       0.00      0.00      0.00       180\n",
            "       12.31       0.27      0.87      0.42       770\n",
            "      121.17       0.00      0.00      0.00        18\n",
            "       125.2       0.00      0.00      0.00        39\n",
            "      128.55       0.00      0.00      0.00        32\n",
            "       13.25       0.00      0.00      0.00       454\n",
            "       131.9       0.00      0.00      0.00        65\n",
            "      135.25       0.00      0.00      0.00        15\n",
            "       138.6       0.00      0.00      0.00         7\n",
            "       14.19       0.16      0.42      0.23       811\n",
            "       145.3       0.00      0.00      0.00        14\n",
            "      148.65       0.00      0.00      0.00        33\n",
            "       15.13       0.20      0.10      0.14       631\n",
            "       152.0       0.00      0.00      0.00        39\n",
            "      198.42       0.00      0.00      0.00         4\n",
            "        2.91       0.66      0.68      0.67       613\n",
            "       205.0       0.00      0.00      0.00         2\n",
            "      211.58       0.00      0.00      0.00         4\n",
            "      218.16       0.00      0.00      0.00        12\n",
            "      224.74       0.00      0.00      0.00         6\n",
            "       23.73       0.00      0.00      0.00       121\n",
            "       24.82       0.00      0.00      0.00       271\n",
            "       25.91       0.00      0.00      0.00       197\n",
            "      257.64       0.00      0.00      0.00         3\n",
            "       26.97       0.00      0.00      0.00       314\n",
            "      267.39       0.00      0.00      0.00         1\n",
            "      273.77       0.00      0.00      0.00         1\n",
            "      276.96       0.00      0.00      0.00         1\n",
            "       28.03       0.00      0.00      0.00       274\n",
            "       29.12       0.00      0.00      0.00       137\n",
            "        3.85       0.32      0.65      0.43       602\n",
            "       30.21       0.00      0.00      0.00        49\n",
            "        31.4       0.00      0.00      0.00       202\n",
            "      313.72       0.00      0.00      0.00         6\n",
            "      316.18       0.47      0.76      0.58        34\n",
            "      318.64       0.00      0.00      0.00         3\n",
            "       33.73       0.00      0.00      0.00       150\n",
            "       36.06       0.00      0.00      0.00       163\n",
            "       38.39       0.00      0.00      0.00        75\n",
            "        4.79       0.00      0.00      0.00       237\n",
            "       40.72       0.00      0.00      0.00        23\n",
            "       43.05       0.00      0.00      0.00        66\n",
            "       43.38       0.00      0.00      0.00       113\n",
            "       47.71       0.00      0.00      0.00       136\n",
            "        5.73       0.00      0.00      0.00       224\n",
            "       50.04       0.14      0.29      0.19       180\n",
            "       52.37       0.00      0.00      0.00       165\n",
            "        54.7       0.00      0.00      0.00       176\n",
            "       57.03       0.26      0.62      0.37       256\n",
            "       59.36       0.92      0.71      0.80       250\n",
            "        6.67       0.52      0.73      0.61       489\n",
            "       61.69       0.59      0.67      0.63       681\n",
            "        64.0       0.48      0.55      0.51       542\n",
            "       64.44       0.00      0.00      0.00       145\n",
            "       64.88       0.60      0.68      0.64       339\n",
            "       65.32       0.56      0.62      0.59       437\n",
            "       65.76       0.46      0.40      0.42       364\n",
            "        66.2       0.50      0.42      0.46       566\n",
            "       66.64       0.00      0.00      0.00         2\n",
            "       67.08       0.00      0.00      0.00       279\n",
            "       67.52       0.57      0.33      0.42       456\n",
            "       67.96       0.26      0.37      0.31       385\n",
            "        68.4       0.23      0.55      0.32       759\n",
            "       68.84       0.35      0.62      0.45       608\n",
            "       69.28       0.28      0.14      0.19       564\n",
            "       69.72       0.00      0.00      0.00       525\n",
            "        7.61       0.00      0.00      0.00       273\n",
            "        70.2       0.30      0.44      0.36       526\n",
            "       74.13       0.00      0.00      0.00       162\n",
            "       78.05       0.00      0.00      0.00        52\n",
            "        8.55       0.00      0.00      0.00       174\n",
            "       81.97       0.00      0.00      0.00        58\n",
            "       85.89       0.00      0.00      0.00        17\n",
            "       93.75       0.00      0.00      0.00         7\n",
            "       97.65       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.34     16625\n",
            "   macro avg       0.12      0.15      0.13     16625\n",
            "weighted avg       0.26      0.34      0.28     16625\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[  0   0   0 ...   0   0   0]\n",
            " [  0   0  74 ...   0   0   0]\n",
            " [  0   0 673 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Decision Tree Classifier"
      ],
      "metadata": {
        "id": "6rlTWW9Sk2cT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=DecisionTreeClassifier()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-uP1Esr_AoX",
        "outputId": "d87dd01f-c9c9-4376-a442-123e73a1f37e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.62       0.98      0.98      0.98       180\n",
            "       11.01       0.96      0.96      0.96       770\n",
            "        11.4       0.88      0.87      0.88       454\n",
            "       11.79       0.92      0.92      0.92       811\n",
            "       12.09       0.82      0.85      0.84        39\n",
            "       12.18       0.94      0.94      0.94       631\n",
            "       14.16       0.95      0.98      0.96       121\n",
            "       14.39       0.91      0.89      0.90       271\n",
            "       14.62       0.87      0.90      0.89       197\n",
            "       14.85       0.88      0.90      0.89       314\n",
            "       15.31       0.78      0.74      0.76       137\n",
            "       15.54       0.93      0.82      0.87        49\n",
            "       15.73       0.89      0.90      0.90       202\n",
            "       15.96       0.81      0.77      0.79       150\n",
            "       16.19       0.75      0.75      0.75       163\n",
            "       16.42       0.81      0.87      0.84        75\n",
            "       16.65       0.74      0.74      0.74        23\n",
            "       16.88       0.90      0.92      0.91        66\n",
            "       17.11       0.95      0.92      0.93       113\n",
            "       17.34       0.95      0.96      0.95       136\n",
            "       17.57       0.89      0.91      0.90       180\n",
            "        17.8       0.86      0.87      0.86       165\n",
            "       18.03       0.85      0.82      0.84       176\n",
            "       18.08       0.85      0.84      0.85       274\n",
            "       18.26       0.88      0.91      0.89       256\n",
            "       18.49       0.94      0.93      0.94       250\n",
            "       18.72       0.99      0.97      0.98       681\n",
            "       18.92       0.95      0.98      0.96       542\n",
            "       19.18       0.95      0.92      0.94       145\n",
            "       19.44       0.98      0.98      0.98       339\n",
            "        19.7       0.97      0.95      0.96       437\n",
            "       19.96       0.95      0.98      0.96       364\n",
            "       20.22       1.00      1.00      1.00       566\n",
            "       20.48       1.00      0.50      0.67         2\n",
            "       20.74       0.98      0.96      0.97       279\n",
            "        21.0       0.95      0.97      0.96       456\n",
            "       21.26       0.92      0.91      0.92       385\n",
            "       21.52       0.91      0.91      0.91       759\n",
            "       21.78       0.87      0.89      0.88       608\n",
            "       22.04       0.91      0.91      0.91       564\n",
            "        22.3       0.87      0.86      0.87       525\n",
            "       22.52       0.96      0.95      0.96       526\n",
            "       22.63       0.91      0.90      0.91       162\n",
            "       22.74       0.91      0.92      0.91        52\n",
            "       22.85       0.86      0.88      0.87        58\n",
            "       22.96       0.56      0.59      0.57        17\n",
            "       23.18       0.88      1.00      0.93         7\n",
            "        23.4       0.91      0.95      0.93        21\n",
            "       23.93       0.71      0.67      0.69        15\n",
            "       23.95       0.75      0.67      0.71        18\n",
            "       24.09       0.74      0.74      0.74        39\n",
            "       24.35       0.76      0.81      0.79        32\n",
            "        24.6       0.78      0.83      0.81        65\n",
            "       24.85       0.93      0.87      0.90        15\n",
            "        25.1       1.00      0.57      0.73         7\n",
            "        25.6       0.65      0.79      0.71        14\n",
            "       25.85       0.76      0.67      0.71        33\n",
            "        28.8       0.40      0.50      0.44         4\n",
            "       29.07       0.67      1.00      0.80         2\n",
            "       29.34       0.33      0.25      0.29         4\n",
            "       29.61       0.82      0.75      0.78        12\n",
            "       29.87       0.67      0.67      0.67         6\n",
            "       31.23       0.00      0.00      0.00         3\n",
            "       31.57       1.00      1.00      1.00         1\n",
            "       31.82       0.00      0.00      0.00         1\n",
            "       31.93       0.00      0.00      0.00         1\n",
            "       33.31       1.00      1.00      1.00         6\n",
            "       33.38       1.00      1.00      1.00        34\n",
            "       33.45       1.00      1.00      1.00         3\n",
            "        7.11       0.97      0.97      0.97       613\n",
            "         7.5       0.96      0.97      0.96       602\n",
            "        7.89       0.98      0.97      0.98       237\n",
            "        8.28       0.96      0.96      0.96       224\n",
            "        8.67       0.97      0.97      0.97       489\n",
            "        9.06       0.95      0.97      0.96       273\n",
            "        9.45       0.97      0.94      0.95       174\n",
            "\n",
            "    accuracy                           0.93     16625\n",
            "   macro avg       0.84      0.83      0.83     16625\n",
            "weighted avg       0.93      0.93      0.93     16625\n",
            "\n",
            "The confusion matrix for Fish Length is: [[176   3   0 ...   0   0   1]\n",
            " [  3 737  27 ...   0   0   0]\n",
            " [  0  27 397 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ... 473   5   0]\n",
            " [  0   0   0 ...   4 265   4]\n",
            " [  0   0   0 ...   2   9 163]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "      101.57       0.87      0.95      0.91        21\n",
            "       11.37       0.98      0.98      0.98       180\n",
            "       12.31       0.96      0.96      0.96       770\n",
            "      121.17       0.83      0.83      0.83        18\n",
            "       125.2       0.82      0.79      0.81        39\n",
            "      128.55       0.81      0.81      0.81        32\n",
            "       13.25       0.89      0.87      0.88       454\n",
            "       131.9       0.79      0.83      0.81        65\n",
            "      135.25       1.00      1.00      1.00        15\n",
            "       138.6       0.80      0.57      0.67         7\n",
            "       14.19       0.92      0.92      0.92       811\n",
            "       145.3       0.71      0.86      0.77        14\n",
            "      148.65       0.77      0.70      0.73        33\n",
            "       15.13       0.94      0.95      0.94       631\n",
            "       152.0       0.85      0.85      0.85        39\n",
            "      198.42       0.50      0.50      0.50         4\n",
            "        2.91       0.97      0.96      0.97       613\n",
            "       205.0       0.67      1.00      0.80         2\n",
            "      211.58       0.50      0.25      0.33         4\n",
            "      218.16       0.75      0.75      0.75        12\n",
            "      224.74       0.57      0.67      0.62         6\n",
            "       23.73       0.97      0.97      0.97       121\n",
            "       24.82       0.91      0.89      0.90       271\n",
            "       25.91       0.87      0.92      0.90       197\n",
            "      257.64       0.00      0.00      0.00         3\n",
            "       26.97       0.89      0.89      0.89       314\n",
            "      267.39       1.00      1.00      1.00         1\n",
            "      270.58       0.00      0.00      0.00         0\n",
            "      273.77       0.00      0.00      0.00         1\n",
            "      276.96       0.00      0.00      0.00         1\n",
            "       28.03       0.83      0.84      0.84       274\n",
            "       29.12       0.78      0.75      0.77       137\n",
            "        3.85       0.96      0.97      0.96       602\n",
            "       30.21       0.93      0.84      0.88        49\n",
            "        31.4       0.87      0.89      0.88       202\n",
            "      313.72       1.00      1.00      1.00         6\n",
            "      316.18       1.00      1.00      1.00        34\n",
            "      318.64       1.00      1.00      1.00         3\n",
            "       33.73       0.81      0.79      0.80       150\n",
            "       36.06       0.77      0.74      0.76       163\n",
            "       38.39       0.82      0.85      0.84        75\n",
            "        4.79       0.98      0.97      0.98       237\n",
            "       40.72       0.78      0.78      0.78        23\n",
            "       43.05       0.89      0.89      0.89        66\n",
            "       43.38       0.93      0.92      0.92       113\n",
            "       47.71       0.95      0.95      0.95       136\n",
            "        5.73       0.93      0.96      0.94       224\n",
            "       50.04       0.90      0.91      0.90       180\n",
            "       52.37       0.87      0.88      0.88       165\n",
            "        54.7       0.86      0.82      0.84       176\n",
            "       57.03       0.88      0.91      0.89       256\n",
            "       59.36       0.94      0.92      0.93       250\n",
            "        6.67       0.97      0.96      0.96       489\n",
            "       61.69       0.99      0.97      0.98       681\n",
            "        64.0       0.95      0.97      0.96       542\n",
            "       64.44       0.92      0.93      0.92       145\n",
            "       64.88       0.97      0.99      0.98       339\n",
            "       65.32       0.98      0.95      0.97       437\n",
            "       65.76       0.95      0.98      0.97       364\n",
            "        66.2       1.00      0.99      1.00       566\n",
            "       66.64       1.00      0.50      0.67         2\n",
            "       67.08       0.98      0.96      0.97       279\n",
            "       67.52       0.95      0.96      0.96       456\n",
            "       67.96       0.91      0.90      0.91       385\n",
            "        68.4       0.91      0.91      0.91       759\n",
            "       68.84       0.87      0.87      0.87       608\n",
            "       69.28       0.91      0.91      0.91       564\n",
            "       69.72       0.86      0.86      0.86       525\n",
            "        7.61       0.95      0.97      0.96       273\n",
            "        70.2       0.96      0.95      0.96       526\n",
            "       74.13       0.91      0.90      0.90       162\n",
            "       78.05       0.90      0.90      0.90        52\n",
            "        8.55       0.97      0.95      0.96       174\n",
            "       81.97       0.85      0.88      0.86        58\n",
            "       85.89       0.56      0.59      0.57        17\n",
            "       93.75       0.88      1.00      0.93         7\n",
            "       97.65       0.69      0.60      0.64        15\n",
            "\n",
            "    accuracy                           0.93     16625\n",
            "   macro avg       0.83      0.83      0.83     16625\n",
            "weighted avg       0.93      0.93      0.92     16625\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[ 20   0   0 ...   0   0   1]\n",
            " [  0 177   2 ...   0   0   0]\n",
            " [  0   3 740 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ...  10   0   1]\n",
            " [  0   0   0 ...   0   7   0]\n",
            " [  3   0   0 ...   1   1   9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Support Vector Machines"
      ],
      "metadata": {
        "id": "OMoNq2gBofEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=SVC()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9q7TNCOem0S",
        "outputId": "fe65b14b-a5a0-4c27-af57-c83287baab74"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.62       0.00      0.00      0.00       180\n",
            "       11.01       0.44      0.88      0.58       770\n",
            "        11.4       0.00      0.00      0.00       454\n",
            "       11.79       0.39      0.55      0.45       811\n",
            "       12.09       0.00      0.00      0.00        39\n",
            "       12.18       0.36      0.09      0.14       631\n",
            "       14.16       0.00      0.00      0.00       121\n",
            "       14.39       0.14      0.72      0.24       271\n",
            "       14.62       0.29      0.17      0.22       197\n",
            "       14.85       0.33      0.59      0.43       314\n",
            "       15.31       0.00      0.00      0.00       137\n",
            "       15.54       0.00      0.00      0.00        49\n",
            "       15.73       0.00      0.00      0.00       202\n",
            "       15.96       0.00      0.00      0.00       150\n",
            "       16.19       1.00      0.01      0.01       163\n",
            "       16.42       0.00      0.00      0.00        75\n",
            "       16.65       0.00      0.00      0.00        23\n",
            "       16.88       0.00      0.00      0.00        66\n",
            "       17.11       0.79      0.53      0.63       113\n",
            "       17.34       0.00      0.00      0.00       136\n",
            "       17.57       0.36      0.05      0.09       180\n",
            "        17.8       0.00      0.00      0.00       165\n",
            "       18.03       1.00      0.01      0.01       176\n",
            "       18.08       0.00      0.00      0.00       274\n",
            "       18.26       0.26      0.96      0.41       256\n",
            "       18.49       0.94      0.77      0.84       250\n",
            "       18.72       0.67      0.64      0.65       681\n",
            "       18.92       0.52      0.67      0.59       542\n",
            "       19.18       0.00      0.00      0.00       145\n",
            "       19.44       0.84      0.90      0.87       339\n",
            "        19.7       0.74      0.70      0.72       437\n",
            "       19.96       0.70      0.77      0.74       364\n",
            "       20.22       0.91      0.90      0.91       566\n",
            "       20.48       0.00      0.00      0.00         2\n",
            "       20.74       0.00      0.00      0.00       279\n",
            "        21.0       0.61      0.63      0.62       456\n",
            "       21.26       0.37      0.83      0.51       385\n",
            "       21.52       0.27      0.51      0.36       759\n",
            "       21.78       0.36      0.72      0.48       608\n",
            "       22.04       0.45      0.14      0.22       564\n",
            "        22.3       0.00      0.00      0.00       525\n",
            "       22.52       0.40      0.39      0.40       526\n",
            "       22.63       0.00      0.00      0.00       162\n",
            "       22.74       0.00      0.00      0.00        52\n",
            "       22.85       0.00      0.00      0.00        58\n",
            "       22.96       0.00      0.00      0.00        17\n",
            "       23.18       0.00      0.00      0.00         7\n",
            "        23.4       0.00      0.00      0.00        21\n",
            "       23.93       0.00      0.00      0.00        15\n",
            "       23.95       0.00      0.00      0.00        18\n",
            "       24.09       0.00      0.00      0.00        39\n",
            "       24.35       0.00      0.00      0.00        32\n",
            "        24.6       0.00      0.00      0.00        65\n",
            "       24.85       0.00      0.00      0.00        15\n",
            "        25.1       0.00      0.00      0.00         7\n",
            "        25.6       0.00      0.00      0.00        14\n",
            "       25.85       0.27      0.09      0.14        33\n",
            "        28.8       0.00      0.00      0.00         4\n",
            "       29.07       0.00      0.00      0.00         2\n",
            "       29.34       0.00      0.00      0.00         4\n",
            "       29.61       0.00      0.00      0.00        12\n",
            "       29.87       0.00      0.00      0.00         6\n",
            "       31.23       0.00      0.00      0.00         3\n",
            "       31.57       0.00      0.00      0.00         1\n",
            "       31.82       0.00      0.00      0.00         1\n",
            "       31.93       0.00      0.00      0.00         1\n",
            "       33.31       0.00      0.00      0.00         6\n",
            "       33.38       0.44      1.00      0.61        34\n",
            "       33.45       0.00      0.00      0.00         3\n",
            "        7.11       0.58      0.42      0.49       613\n",
            "         7.5       0.40      0.74      0.52       602\n",
            "        7.89       0.00      0.00      0.00       237\n",
            "        8.28       0.08      0.04      0.06       224\n",
            "        8.67       0.54      0.87      0.67       489\n",
            "        9.06       0.58      0.22      0.32       273\n",
            "        9.45       0.00      0.00      0.00       174\n",
            "\n",
            "    accuracy                           0.44     16625\n",
            "   macro avg       0.21      0.22      0.18     16625\n",
            "weighted avg       0.38      0.44      0.37     16625\n",
            "\n",
            "The confusion matrix for Fish Length is: [[  0 100   0 ...   0   0   0]\n",
            " [  0 677   0 ...   0   0   0]\n",
            " [  0 222   0 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ... 424  20   0]\n",
            " [  0   0   0 ... 109  59   0]\n",
            " [  0  18   0 ... 115  22   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "      101.57       0.00      0.00      0.00        21\n",
            "       11.37       0.00      0.00      0.00       180\n",
            "       12.31       0.44      0.88      0.58       770\n",
            "      121.17       0.00      0.00      0.00        18\n",
            "       125.2       0.00      0.00      0.00        39\n",
            "      128.55       0.00      0.00      0.00        32\n",
            "       13.25       0.00      0.00      0.00       454\n",
            "       131.9       0.00      0.00      0.00        65\n",
            "      135.25       0.00      0.00      0.00        15\n",
            "       138.6       0.00      0.00      0.00         7\n",
            "       14.19       0.39      0.55      0.45       811\n",
            "       145.3       0.00      0.00      0.00        14\n",
            "      148.65       0.25      0.12      0.16        33\n",
            "       15.13       0.36      0.09      0.14       631\n",
            "       152.0       0.00      0.00      0.00        39\n",
            "      198.42       0.00      0.00      0.00         4\n",
            "        2.91       0.58      0.42      0.49       613\n",
            "       205.0       0.00      0.00      0.00         2\n",
            "      211.58       0.00      0.00      0.00         4\n",
            "      218.16       0.00      0.00      0.00        12\n",
            "      224.74       0.00      0.00      0.00         6\n",
            "       23.73       0.00      0.00      0.00       121\n",
            "       24.82       0.14      0.72      0.24       271\n",
            "       25.91       0.29      0.17      0.22       197\n",
            "      257.64       0.00      0.00      0.00         3\n",
            "       26.97       0.33      0.59      0.43       314\n",
            "      267.39       0.00      0.00      0.00         1\n",
            "      273.77       0.00      0.00      0.00         1\n",
            "      276.96       0.00      0.00      0.00         1\n",
            "       28.03       0.00      0.00      0.00       274\n",
            "       29.12       0.00      0.00      0.00       137\n",
            "        3.85       0.40      0.74      0.52       602\n",
            "       30.21       0.00      0.00      0.00        49\n",
            "        31.4       0.00      0.00      0.00       202\n",
            "      313.72       0.00      0.00      0.00         6\n",
            "      316.18       0.44      1.00      0.61        34\n",
            "      318.64       0.00      0.00      0.00         3\n",
            "       33.73       0.00      0.00      0.00       150\n",
            "       36.06       1.00      0.01      0.01       163\n",
            "       38.39       0.00      0.00      0.00        75\n",
            "        4.79       0.00      0.00      0.00       237\n",
            "       40.72       0.00      0.00      0.00        23\n",
            "       43.05       0.00      0.00      0.00        66\n",
            "       43.38       0.79      0.53      0.63       113\n",
            "       47.71       0.00      0.00      0.00       136\n",
            "        5.73       0.08      0.04      0.06       224\n",
            "       50.04       0.36      0.05      0.09       180\n",
            "       52.37       0.00      0.00      0.00       165\n",
            "        54.7       1.00      0.01      0.01       176\n",
            "       57.03       0.26      0.96      0.41       256\n",
            "       59.36       0.94      0.77      0.84       250\n",
            "        6.67       0.54      0.87      0.67       489\n",
            "       61.69       0.67      0.64      0.65       681\n",
            "        64.0       0.52      0.67      0.59       542\n",
            "       64.44       0.00      0.00      0.00       145\n",
            "       64.88       0.84      0.90      0.87       339\n",
            "       65.32       0.74      0.70      0.72       437\n",
            "       65.76       0.70      0.77      0.74       364\n",
            "        66.2       0.91      0.90      0.91       566\n",
            "       66.64       0.00      0.00      0.00         2\n",
            "       67.08       0.00      0.00      0.00       279\n",
            "       67.52       0.61      0.63      0.62       456\n",
            "       67.96       0.37      0.83      0.51       385\n",
            "        68.4       0.27      0.51      0.36       759\n",
            "       68.84       0.36      0.72      0.48       608\n",
            "       69.28       0.45      0.14      0.22       564\n",
            "       69.72       0.00      0.00      0.00       525\n",
            "        7.61       0.58      0.22      0.32       273\n",
            "        70.2       0.41      0.39      0.40       526\n",
            "       74.13       0.00      0.00      0.00       162\n",
            "       78.05       0.00      0.00      0.00        52\n",
            "        8.55       0.00      0.00      0.00       174\n",
            "       81.97       0.00      0.00      0.00        58\n",
            "       85.89       0.00      0.00      0.00        17\n",
            "       93.75       0.00      0.00      0.00         7\n",
            "       97.65       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.44     16625\n",
            "   macro avg       0.21      0.22      0.18     16625\n",
            "weighted avg       0.38      0.44      0.37     16625\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[  0   0   0 ...   0   0   0]\n",
            " [  0   0 100 ...   0   0   0]\n",
            " [  0   0 677 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Random Forest Classifier"
      ],
      "metadata": {
        "id": "d0nA1n-6oi9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=RandomForestClassifier()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VRdFwE6fEsh",
        "outputId": "fdc9a8c9-2f6a-467d-8d7e-3fbe0e9805fb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.62       0.99      0.98      0.99       180\n",
            "       11.01       0.96      0.98      0.97       770\n",
            "        11.4       0.91      0.89      0.90       454\n",
            "       11.79       0.93      0.94      0.93       811\n",
            "       12.09       0.81      0.87      0.84        39\n",
            "       12.18       0.96      0.94      0.95       631\n",
            "       14.16       0.99      0.98      0.99       121\n",
            "       14.39       0.91      0.95      0.93       271\n",
            "       14.62       0.94      0.91      0.93       197\n",
            "       14.85       0.90      0.94      0.92       314\n",
            "       15.31       0.84      0.78      0.81       137\n",
            "       15.54       0.94      0.90      0.92        49\n",
            "       15.73       0.93      0.93      0.93       202\n",
            "       15.96       0.83      0.87      0.85       150\n",
            "       16.19       0.83      0.80      0.82       163\n",
            "       16.42       0.92      0.91      0.91        75\n",
            "       16.65       0.83      0.87      0.85        23\n",
            "       16.88       0.95      0.89      0.92        66\n",
            "       17.11       0.95      0.95      0.95       113\n",
            "       17.34       0.96      0.98      0.97       136\n",
            "       17.57       0.90      0.94      0.92       180\n",
            "        17.8       0.87      0.89      0.88       165\n",
            "       18.03       0.92      0.82      0.87       176\n",
            "       18.08       0.89      0.88      0.88       274\n",
            "       18.26       0.90      0.93      0.92       256\n",
            "       18.49       0.95      0.95      0.95       250\n",
            "       18.72       0.98      0.99      0.98       681\n",
            "       18.92       0.97      0.98      0.97       542\n",
            "       19.18       0.98      0.92      0.95       145\n",
            "       19.44       0.99      0.99      0.99       339\n",
            "        19.7       0.99      0.99      0.99       437\n",
            "       19.96       0.99      0.99      0.99       364\n",
            "       20.22       1.00      1.00      1.00       566\n",
            "       20.48       0.00      0.00      0.00         2\n",
            "       20.74       0.98      0.98      0.98       279\n",
            "        21.0       0.97      0.99      0.98       456\n",
            "       21.26       0.97      0.93      0.95       385\n",
            "       21.52       0.93      0.95      0.94       759\n",
            "       21.78       0.91      0.92      0.91       608\n",
            "       22.04       0.95      0.92      0.94       564\n",
            "        22.3       0.90      0.92      0.91       525\n",
            "       22.52       0.99      0.97      0.98       526\n",
            "       22.63       0.93      0.93      0.93       162\n",
            "       22.74       0.88      0.96      0.92        52\n",
            "       22.85       0.86      0.97      0.91        58\n",
            "       22.96       0.78      0.41      0.54        17\n",
            "       23.18       0.78      1.00      0.88         7\n",
            "        23.4       0.90      0.90      0.90        21\n",
            "       23.93       0.83      0.67      0.74        15\n",
            "       23.95       0.86      0.67      0.75        18\n",
            "       24.09       0.76      0.79      0.77        39\n",
            "       24.35       0.89      0.78      0.83        32\n",
            "        24.6       0.82      0.92      0.87        65\n",
            "       24.85       1.00      1.00      1.00        15\n",
            "        25.1       1.00      0.86      0.92         7\n",
            "        25.6       1.00      0.79      0.88        14\n",
            "       25.85       0.81      0.79      0.80        33\n",
            "        28.8       0.50      0.25      0.33         4\n",
            "       29.07       1.00      1.00      1.00         2\n",
            "       29.34       1.00      0.75      0.86         4\n",
            "       29.61       0.73      0.92      0.81        12\n",
            "       29.87       0.67      1.00      0.80         6\n",
            "       31.23       1.00      0.67      0.80         3\n",
            "       31.57       1.00      1.00      1.00         1\n",
            "       31.82       0.00      0.00      0.00         1\n",
            "       31.93       0.00      0.00      0.00         1\n",
            "       33.31       1.00      1.00      1.00         6\n",
            "       33.38       0.97      1.00      0.99        34\n",
            "       33.45       1.00      0.67      0.80         3\n",
            "        7.11       0.97      0.98      0.97       613\n",
            "         7.5       0.98      0.97      0.97       602\n",
            "        7.89       0.99      0.99      0.99       237\n",
            "        8.28       0.96      0.96      0.96       224\n",
            "        8.67       0.97      0.98      0.98       489\n",
            "        9.06       0.97      0.97      0.97       273\n",
            "        9.45       0.98      0.97      0.98       174\n",
            "\n",
            "    accuracy                           0.95     16625\n",
            "   macro avg       0.88      0.86      0.87     16625\n",
            "weighted avg       0.95      0.95      0.95     16625\n",
            "\n",
            "The confusion matrix for Fish Length is: [[177   3   0 ...   0   0   0]\n",
            " [  2 751  15 ...   0   0   0]\n",
            " [  0  25 403 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ... 478   4   0]\n",
            " [  0   0   0 ...   4 266   3]\n",
            " [  0   0   0 ...   0   5 169]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "      101.57       0.91      0.95      0.93        21\n",
            "       11.37       0.99      0.98      0.99       180\n",
            "       12.31       0.96      0.98      0.97       770\n",
            "      121.17       0.87      0.72      0.79        18\n",
            "       125.2       0.73      0.85      0.79        39\n",
            "      128.55       0.92      0.75      0.83        32\n",
            "       13.25       0.91      0.89      0.90       454\n",
            "       131.9       0.83      0.91      0.87        65\n",
            "      135.25       1.00      1.00      1.00        15\n",
            "       138.6       1.00      0.86      0.92         7\n",
            "       14.19       0.93      0.94      0.93       811\n",
            "       145.3       1.00      0.79      0.88        14\n",
            "      148.65       0.81      0.79      0.80        33\n",
            "       15.13       0.96      0.95      0.95       631\n",
            "       152.0       0.83      0.90      0.86        39\n",
            "      198.42       0.67      0.50      0.57         4\n",
            "        2.91       0.97      0.98      0.98       613\n",
            "       205.0       1.00      1.00      1.00         2\n",
            "      211.58       1.00      0.75      0.86         4\n",
            "      218.16       0.85      0.92      0.88        12\n",
            "      224.74       0.67      1.00      0.80         6\n",
            "       23.73       0.98      0.98      0.98       121\n",
            "       24.82       0.91      0.95      0.93       271\n",
            "       25.91       0.94      0.92      0.93       197\n",
            "      257.64       1.00      0.67      0.80         3\n",
            "       26.97       0.91      0.94      0.92       314\n",
            "      267.39       1.00      1.00      1.00         1\n",
            "      270.58       0.00      0.00      0.00         0\n",
            "      273.77       0.00      0.00      0.00         1\n",
            "      276.96       0.00      0.00      0.00         1\n",
            "       28.03       0.88      0.88      0.88       274\n",
            "       29.12       0.84      0.75      0.80       137\n",
            "        3.85       0.98      0.97      0.97       602\n",
            "       30.21       0.94      0.90      0.92        49\n",
            "        31.4       0.94      0.95      0.94       202\n",
            "      313.72       1.00      1.00      1.00         6\n",
            "      316.18       0.97      1.00      0.99        34\n",
            "      318.64       1.00      0.67      0.80         3\n",
            "       33.73       0.83      0.89      0.86       150\n",
            "       36.06       0.85      0.77      0.81       163\n",
            "       38.39       0.92      0.91      0.91        75\n",
            "        4.79       0.99      0.99      0.99       237\n",
            "       40.72       0.80      0.87      0.83        23\n",
            "       43.05       0.95      0.91      0.93        66\n",
            "       43.38       0.95      0.96      0.95       113\n",
            "       47.71       0.96      0.98      0.97       136\n",
            "        5.73       0.96      0.96      0.96       224\n",
            "       50.04       0.92      0.93      0.93       180\n",
            "       52.37       0.88      0.92      0.90       165\n",
            "        54.7       0.91      0.85      0.88       176\n",
            "       57.03       0.90      0.93      0.91       256\n",
            "       59.36       0.95      0.94      0.94       250\n",
            "        6.67       0.97      0.98      0.98       489\n",
            "       61.69       0.98      0.99      0.98       681\n",
            "        64.0       0.97      0.97      0.97       542\n",
            "       64.44       0.97      0.93      0.95       145\n",
            "       64.88       0.99      1.00      0.99       339\n",
            "       65.32       0.99      0.99      0.99       437\n",
            "       65.76       0.99      0.99      0.99       364\n",
            "        66.2       1.00      1.00      1.00       566\n",
            "       66.64       0.00      0.00      0.00         2\n",
            "       67.08       0.98      0.98      0.98       279\n",
            "       67.52       0.97      0.99      0.98       456\n",
            "       67.96       0.97      0.93      0.95       385\n",
            "        68.4       0.93      0.95      0.94       759\n",
            "       68.84       0.91      0.92      0.92       608\n",
            "       69.28       0.95      0.92      0.94       564\n",
            "       69.72       0.90      0.92      0.91       525\n",
            "        7.61       0.97      0.97      0.97       273\n",
            "        70.2       0.99      0.97      0.98       526\n",
            "       74.13       0.94      0.94      0.94       162\n",
            "       78.05       0.86      0.96      0.91        52\n",
            "        8.55       0.98      0.98      0.98       174\n",
            "       81.97       0.87      0.95      0.91        58\n",
            "       85.89       0.80      0.47      0.59        17\n",
            "       93.75       0.88      1.00      0.93         7\n",
            "       97.65       0.91      0.67      0.77        15\n",
            "\n",
            "    accuracy                           0.95     16625\n",
            "   macro avg       0.88      0.86      0.86     16625\n",
            "weighted avg       0.95      0.95      0.95     16625\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[ 20   0   0 ...   0   0   0]\n",
            " [  0 177   3 ...   0   0   0]\n",
            " [  0   2 751 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ...   8   0   0]\n",
            " [  0   0   0 ...   0   7   0]\n",
            " [  2   0   0 ...   1   1  10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) K Nearest Neighbours"
      ],
      "metadata": {
        "id": "9Yuya5hFoq0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=KNeighborsClassifier()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLwQft8uf9B8",
        "outputId": "682416fb-a9b2-4c2e-8165-79fe615817e7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.62       0.92      0.87      0.89       180\n",
            "       11.01       0.87      0.95      0.91       770\n",
            "        11.4       0.73      0.62      0.67       454\n",
            "       11.79       0.76      0.81      0.79       811\n",
            "       12.09       0.46      0.54      0.49        39\n",
            "       12.18       0.87      0.82      0.84       631\n",
            "       14.16       0.63      0.70      0.67       121\n",
            "       14.39       0.58      0.65      0.61       271\n",
            "       14.62       0.64      0.65      0.64       197\n",
            "       14.85       0.65      0.78      0.71       314\n",
            "       15.31       0.37      0.25      0.30       137\n",
            "       15.54       0.50      0.31      0.38        49\n",
            "       15.73       0.69      0.66      0.67       202\n",
            "       15.96       0.51      0.62      0.56       150\n",
            "       16.19       0.53      0.50      0.51       163\n",
            "       16.42       0.77      0.55      0.64        75\n",
            "       16.65       0.46      0.48      0.47        23\n",
            "       16.88       0.74      0.44      0.55        66\n",
            "       17.11       0.72      0.81      0.76       113\n",
            "       17.34       0.74      0.54      0.63       136\n",
            "       17.57       0.54      0.71      0.62       180\n",
            "        17.8       0.53      0.73      0.61       165\n",
            "       18.03       0.57      0.44      0.50       176\n",
            "       18.08       0.69      0.59      0.64       274\n",
            "       18.26       0.80      0.67      0.73       256\n",
            "       18.49       0.88      0.89      0.88       250\n",
            "       18.72       0.94      0.95      0.95       681\n",
            "       18.92       0.94      0.94      0.94       542\n",
            "       19.18       0.89      0.83      0.86       145\n",
            "       19.44       0.93      0.97      0.95       339\n",
            "        19.7       0.91      0.91      0.91       437\n",
            "       19.96       0.95      0.86      0.90       364\n",
            "       20.22       0.95      0.99      0.97       566\n",
            "       20.48       0.00      0.00      0.00         2\n",
            "       20.74       0.78      0.80      0.79       279\n",
            "        21.0       0.77      0.85      0.81       456\n",
            "       21.26       0.80      0.85      0.82       385\n",
            "       21.52       0.62      0.66      0.64       759\n",
            "       21.78       0.57      0.68      0.62       608\n",
            "       22.04       0.69      0.61      0.65       564\n",
            "        22.3       0.60      0.54      0.57       525\n",
            "       22.52       0.74      0.65      0.69       526\n",
            "       22.63       0.49      0.41      0.45       162\n",
            "       22.74       0.40      0.60      0.48        52\n",
            "       22.85       0.58      0.38      0.46        58\n",
            "       22.96       0.33      0.06      0.10        17\n",
            "       23.18       0.00      0.00      0.00         7\n",
            "        23.4       0.40      0.29      0.33        21\n",
            "       23.93       0.17      0.07      0.10        15\n",
            "       23.95       0.47      0.39      0.42        18\n",
            "       24.09       0.40      0.41      0.41        39\n",
            "       24.35       0.20      0.12      0.15        32\n",
            "        24.6       0.46      0.63      0.53        65\n",
            "       24.85       0.20      0.07      0.10        15\n",
            "        25.1       0.14      0.14      0.14         7\n",
            "        25.6       0.55      0.43      0.48        14\n",
            "       25.85       0.59      0.58      0.58        33\n",
            "        28.8       0.50      0.25      0.33         4\n",
            "       29.07       1.00      0.50      0.67         2\n",
            "       29.34       0.67      0.50      0.57         4\n",
            "       29.61       0.50      0.58      0.54        12\n",
            "       29.87       0.60      0.50      0.55         6\n",
            "       31.23       0.00      0.00      0.00         3\n",
            "       31.45       0.00      0.00      0.00         0\n",
            "       31.57       0.25      1.00      0.40         1\n",
            "       31.69       0.00      0.00      0.00         0\n",
            "       31.82       0.00      0.00      0.00         1\n",
            "       31.93       0.00      0.00      0.00         1\n",
            "       33.31       0.67      0.33      0.44         6\n",
            "       33.38       0.79      0.91      0.85        34\n",
            "       33.45       0.75      1.00      0.86         3\n",
            "        7.11       0.94      0.91      0.93       613\n",
            "         7.5       0.85      0.93      0.89       602\n",
            "        7.89       0.93      0.78      0.85       237\n",
            "        8.28       0.85      0.90      0.87       224\n",
            "        8.67       0.92      0.88      0.90       489\n",
            "        9.06       0.81      0.87      0.84       273\n",
            "        9.45       0.88      0.80      0.84       174\n",
            "\n",
            "    accuracy                           0.77     16625\n",
            "   macro avg       0.60      0.58      0.57     16625\n",
            "weighted avg       0.77      0.77      0.77     16625\n",
            "\n",
            "The confusion matrix for Fish Length is: [[156  22   0 ...   0   0   1]\n",
            " [  5 730  28 ...   0   0   0]\n",
            " [  4  73 283 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ... 432  23   0]\n",
            " [  0   0   0 ...  16 238  18]\n",
            " [  2   0   0 ...   0  33 139]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "      101.57       0.35      0.38      0.36        21\n",
            "       11.37       0.92      0.87      0.89       180\n",
            "       12.31       0.87      0.95      0.91       770\n",
            "      121.17       0.39      0.39      0.39        18\n",
            "       125.2       0.40      0.41      0.41        39\n",
            "      128.55       0.18      0.12      0.15        32\n",
            "       13.25       0.73      0.62      0.67       454\n",
            "       131.9       0.44      0.65      0.53        65\n",
            "      135.25       0.17      0.07      0.10        15\n",
            "       138.6       0.12      0.14      0.13         7\n",
            "       14.19       0.76      0.81      0.79       811\n",
            "       145.3       0.43      0.43      0.43        14\n",
            "      148.65       0.50      0.64      0.56        33\n",
            "       15.13       0.87      0.82      0.84       631\n",
            "       152.0       0.46      0.33      0.39        39\n",
            "      198.42       0.50      0.25      0.33         4\n",
            "        2.91       0.94      0.91      0.93       613\n",
            "       205.0       1.00      0.50      0.67         2\n",
            "      211.58       0.67      0.50      0.57         4\n",
            "      218.16       0.50      0.58      0.54        12\n",
            "      224.74       0.60      0.50      0.55         6\n",
            "       23.73       0.63      0.70      0.67       121\n",
            "       24.82       0.58      0.65      0.61       271\n",
            "       25.91       0.64      0.65      0.64       197\n",
            "      257.64       0.00      0.00      0.00         3\n",
            "       26.97       0.65      0.78      0.71       314\n",
            "       264.2       0.00      0.00      0.00         0\n",
            "      267.39       0.25      1.00      0.40         1\n",
            "      270.58       0.00      0.00      0.00         0\n",
            "      273.77       0.00      0.00      0.00         1\n",
            "      276.96       0.00      0.00      0.00         1\n",
            "       28.03       0.66      0.64      0.65       274\n",
            "       29.12       0.41      0.23      0.29       137\n",
            "        3.85       0.85      0.93      0.89       602\n",
            "       30.21       0.44      0.24      0.32        49\n",
            "        31.4       0.70      0.66      0.68       202\n",
            "      313.72       0.67      0.33      0.44         6\n",
            "      316.18       0.79      0.91      0.85        34\n",
            "      318.64       0.75      1.00      0.86         3\n",
            "       33.73       0.53      0.61      0.57       150\n",
            "       36.06       0.53      0.50      0.51       163\n",
            "       38.39       0.77      0.55      0.64        75\n",
            "        4.79       0.93      0.78      0.85       237\n",
            "       40.72       0.46      0.48      0.47        23\n",
            "       43.05       0.74      0.44      0.55        66\n",
            "       43.38       0.72      0.81      0.76       113\n",
            "       47.71       0.74      0.54      0.63       136\n",
            "        5.73       0.85      0.90      0.87       224\n",
            "       50.04       0.54      0.71      0.62       180\n",
            "       52.37       0.53      0.73      0.61       165\n",
            "        54.7       0.57      0.44      0.50       176\n",
            "       57.03       0.80      0.67      0.73       256\n",
            "       59.36       0.88      0.89      0.88       250\n",
            "        6.67       0.92      0.88      0.90       489\n",
            "       61.69       0.94      0.95      0.95       681\n",
            "        64.0       0.94      0.94      0.94       542\n",
            "       64.44       0.89      0.83      0.86       145\n",
            "       64.88       0.93      0.97      0.95       339\n",
            "       65.32       0.91      0.91      0.91       437\n",
            "       65.76       0.95      0.86      0.90       364\n",
            "        66.2       0.95      0.99      0.97       566\n",
            "       66.64       0.00      0.00      0.00         2\n",
            "       67.08       0.78      0.80      0.79       279\n",
            "       67.52       0.77      0.85      0.81       456\n",
            "       67.96       0.81      0.85      0.83       385\n",
            "        68.4       0.62      0.66      0.64       759\n",
            "       68.84       0.57      0.68      0.62       608\n",
            "       69.28       0.69      0.61      0.65       564\n",
            "       69.72       0.60      0.54      0.57       525\n",
            "        7.61       0.81      0.87      0.84       273\n",
            "        70.2       0.74      0.64      0.69       526\n",
            "       74.13       0.49      0.41      0.45       162\n",
            "       78.05       0.41      0.60      0.48        52\n",
            "        8.55       0.88      0.80      0.84       174\n",
            "       81.97       0.56      0.33      0.41        58\n",
            "       85.89       0.33      0.06      0.10        17\n",
            "       93.75       0.00      0.00      0.00         7\n",
            "       97.65       0.25      0.07      0.11        15\n",
            "\n",
            "    accuracy                           0.77     16625\n",
            "   macro avg       0.59      0.57      0.57     16625\n",
            "weighted avg       0.77      0.77      0.77     16625\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[  8   0   0 ...   0   0   0]\n",
            " [  0 156  22 ...   0   0   0]\n",
            " [  0   5 730 ...   0   0   0]\n",
            " ...\n",
            " [  4   0   0 ...   1   0   1]\n",
            " [  0   0   0 ...   0   0   1]\n",
            " [  3   0   0 ...   1   0   1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Adam Boost Classifier"
      ],
      "metadata": {
        "id": "HIXxDcIGot15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=AdaBoostClassifier()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nfY_m1OfpKA",
        "outputId": "45305829-97fc-4317-a7bb-a9976ebaf76c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.62       0.00      0.00      0.00       180\n",
            "       11.01       0.00      0.00      0.00       770\n",
            "        11.4       0.00      0.00      0.00       454\n",
            "       11.79       0.20      1.00      0.34       811\n",
            "       12.09       0.00      0.00      0.00        39\n",
            "       12.18       0.00      0.00      0.00       631\n",
            "       14.16       0.00      0.00      0.00       121\n",
            "       14.39       0.00      0.00      0.00       271\n",
            "       14.62       0.00      0.00      0.00       197\n",
            "       14.85       0.00      0.00      0.00       314\n",
            "       15.31       0.00      0.00      0.00       137\n",
            "       15.54       0.00      0.00      0.00        49\n",
            "       15.73       0.00      0.00      0.00       202\n",
            "       15.96       0.00      0.00      0.00       150\n",
            "       16.19       0.00      0.00      0.00       163\n",
            "       16.42       0.00      0.00      0.00        75\n",
            "       16.65       0.00      0.00      0.00        23\n",
            "       16.88       0.00      0.00      0.00        66\n",
            "       17.11       0.00      0.00      0.00       113\n",
            "       17.34       0.00      0.00      0.00       136\n",
            "       17.57       0.00      0.00      0.00       180\n",
            "        17.8       0.00      0.00      0.00       165\n",
            "       18.03       0.00      0.00      0.00       176\n",
            "       18.08       0.00      0.00      0.00       274\n",
            "       18.26       0.00      0.00      0.00       256\n",
            "       18.49       0.00      0.00      0.00       250\n",
            "       18.72       0.00      0.00      0.00       681\n",
            "       18.92       0.00      0.00      0.00       542\n",
            "       19.18       0.00      0.00      0.00       145\n",
            "       19.44       0.00      0.00      0.00       339\n",
            "        19.7       0.00      0.00      0.00       437\n",
            "       19.96       0.00      0.00      0.00       364\n",
            "       20.22       0.00      0.00      0.00       566\n",
            "       20.48       0.00      0.00      0.00         2\n",
            "       20.74       0.00      0.00      0.00       279\n",
            "        21.0       0.00      0.00      0.00       456\n",
            "       21.26       0.00      0.00      0.00       385\n",
            "       21.52       0.07      1.00      0.13       759\n",
            "       21.78       0.00      0.00      0.00       608\n",
            "       22.04       0.00      0.00      0.00       564\n",
            "        22.3       0.00      0.00      0.00       525\n",
            "       22.52       0.00      0.00      0.00       526\n",
            "       22.63       0.00      0.00      0.00       162\n",
            "       22.74       0.00      0.00      0.00        52\n",
            "       22.85       0.00      0.00      0.00        58\n",
            "       22.96       0.00      0.00      0.00        17\n",
            "       23.18       0.00      0.00      0.00         7\n",
            "        23.4       0.00      0.00      0.00        21\n",
            "       23.93       0.00      0.00      0.00        15\n",
            "       23.95       0.00      0.00      0.00        18\n",
            "       24.09       0.00      0.00      0.00        39\n",
            "       24.35       0.00      0.00      0.00        32\n",
            "        24.6       0.00      0.00      0.00        65\n",
            "       24.85       0.00      0.00      0.00        15\n",
            "        25.1       0.00      0.00      0.00         7\n",
            "        25.6       0.00      0.00      0.00        14\n",
            "       25.85       0.00      0.00      0.00        33\n",
            "        28.8       0.00      0.00      0.00         4\n",
            "       29.07       0.00      0.00      0.00         2\n",
            "       29.34       0.00      0.00      0.00         4\n",
            "       29.61       0.00      0.00      0.00        12\n",
            "       29.87       0.00      0.00      0.00         6\n",
            "       31.23       0.00      0.00      0.00         3\n",
            "       31.57       0.00      0.00      0.00         1\n",
            "       31.82       0.00      0.00      0.00         1\n",
            "       31.93       0.00      0.00      0.00         1\n",
            "       33.31       0.00      0.00      0.00         6\n",
            "       33.38       0.44      1.00      0.61        34\n",
            "       33.45       0.00      0.00      0.00         3\n",
            "        7.11       0.00      0.00      0.00       613\n",
            "         7.5       0.40      0.99      0.57       602\n",
            "        7.89       0.00      0.00      0.00       237\n",
            "        8.28       0.00      0.00      0.00       224\n",
            "        8.67       0.00      0.00      0.00       489\n",
            "        9.06       0.00      0.00      0.00       273\n",
            "        9.45       0.00      0.00      0.00       174\n",
            "\n",
            "    accuracy                           0.13     16625\n",
            "   macro avg       0.01      0.05      0.02     16625\n",
            "weighted avg       0.03      0.13      0.04     16625\n",
            "\n",
            "The confusion matrix for Fish Length is: [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "      101.57       0.00      0.00      0.00        21\n",
            "       11.37       0.00      0.00      0.00       180\n",
            "       12.31       0.00      0.00      0.00       770\n",
            "      121.17       0.00      0.00      0.00        18\n",
            "       125.2       0.00      0.00      0.00        39\n",
            "      128.55       0.00      0.00      0.00        32\n",
            "       13.25       0.00      0.00      0.00       454\n",
            "       131.9       0.00      0.00      0.00        65\n",
            "      135.25       0.00      0.00      0.00        15\n",
            "       138.6       0.00      0.00      0.00         7\n",
            "       14.19       0.20      1.00      0.34       811\n",
            "       145.3       0.00      0.00      0.00        14\n",
            "      148.65       0.00      0.00      0.00        33\n",
            "       15.13       0.00      0.00      0.00       631\n",
            "       152.0       0.00      0.00      0.00        39\n",
            "      198.42       0.00      0.00      0.00         4\n",
            "        2.91       0.00      0.00      0.00       613\n",
            "       205.0       0.00      0.00      0.00         2\n",
            "      211.58       0.00      0.00      0.00         4\n",
            "      218.16       0.00      0.00      0.00        12\n",
            "      224.74       0.00      0.00      0.00         6\n",
            "       23.73       0.00      0.00      0.00       121\n",
            "       24.82       0.00      0.00      0.00       271\n",
            "       25.91       0.00      0.00      0.00       197\n",
            "      257.64       0.00      0.00      0.00         3\n",
            "       26.97       0.00      0.00      0.00       314\n",
            "      267.39       0.00      0.00      0.00         1\n",
            "      273.77       0.00      0.00      0.00         1\n",
            "      276.96       0.00      0.00      0.00         1\n",
            "       28.03       0.00      0.00      0.00       274\n",
            "       29.12       0.00      0.00      0.00       137\n",
            "        3.85       0.40      0.99      0.57       602\n",
            "       30.21       0.00      0.00      0.00        49\n",
            "        31.4       0.00      0.00      0.00       202\n",
            "      313.72       0.00      0.00      0.00         6\n",
            "      316.18       0.44      1.00      0.61        34\n",
            "      318.64       0.00      0.00      0.00         3\n",
            "       33.73       0.00      0.00      0.00       150\n",
            "       36.06       0.00      0.00      0.00       163\n",
            "       38.39       0.00      0.00      0.00        75\n",
            "        4.79       0.00      0.00      0.00       237\n",
            "       40.72       0.00      0.00      0.00        23\n",
            "       43.05       0.00      0.00      0.00        66\n",
            "       43.38       0.00      0.00      0.00       113\n",
            "       47.71       0.00      0.00      0.00       136\n",
            "        5.73       0.00      0.00      0.00       224\n",
            "       50.04       0.00      0.00      0.00       180\n",
            "       52.37       0.00      0.00      0.00       165\n",
            "        54.7       0.00      0.00      0.00       176\n",
            "       57.03       0.00      0.00      0.00       256\n",
            "       59.36       0.00      0.00      0.00       250\n",
            "        6.67       0.00      0.00      0.00       489\n",
            "       61.69       0.00      0.00      0.00       681\n",
            "        64.0       0.00      0.00      0.00       542\n",
            "       64.44       0.00      0.00      0.00       145\n",
            "       64.88       0.00      0.00      0.00       339\n",
            "       65.32       0.00      0.00      0.00       437\n",
            "       65.76       0.00      0.00      0.00       364\n",
            "        66.2       0.00      0.00      0.00       566\n",
            "       66.64       0.00      0.00      0.00         2\n",
            "       67.08       0.00      0.00      0.00       279\n",
            "       67.52       0.00      0.00      0.00       456\n",
            "       67.96       0.00      0.00      0.00       385\n",
            "        68.4       0.07      1.00      0.13       759\n",
            "       68.84       0.00      0.00      0.00       608\n",
            "       69.28       0.00      0.00      0.00       564\n",
            "       69.72       0.00      0.00      0.00       525\n",
            "        7.61       0.00      0.00      0.00       273\n",
            "        70.2       0.00      0.00      0.00       526\n",
            "       74.13       0.00      0.00      0.00       162\n",
            "       78.05       0.00      0.00      0.00        52\n",
            "        8.55       0.00      0.00      0.00       174\n",
            "       81.97       0.00      0.00      0.00        58\n",
            "       85.89       0.00      0.00      0.00        17\n",
            "       93.75       0.00      0.00      0.00         7\n",
            "       97.65       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.13     16625\n",
            "   macro avg       0.01      0.05      0.02     16625\n",
            "weighted avg       0.03      0.13      0.04     16625\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7) Extra Trees Classifier"
      ],
      "metadata": {
        "id": "gLGtmT1aozKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=ExtraTreesClassifier()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "id": "jnsRT9x4G-bm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30f084a5-7d36-46ae-8567-05ca2a5cf62e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.62       0.99      0.98      0.99       180\n",
            "       11.01       0.96      0.98      0.97       770\n",
            "        11.4       0.91      0.89      0.90       454\n",
            "       11.79       0.93      0.95      0.94       811\n",
            "       12.09       0.81      0.87      0.84        39\n",
            "       12.18       0.97      0.95      0.96       631\n",
            "       14.16       0.99      1.00      1.00       121\n",
            "       14.39       0.91      0.95      0.93       271\n",
            "       14.62       0.93      0.92      0.93       197\n",
            "       14.85       0.90      0.93      0.92       314\n",
            "       15.31       0.86      0.72      0.79       137\n",
            "       15.54       0.94      0.90      0.92        49\n",
            "       15.73       0.93      0.94      0.93       202\n",
            "       15.96       0.84      0.87      0.85       150\n",
            "       16.19       0.82      0.82      0.82       163\n",
            "       16.42       0.94      0.91      0.93        75\n",
            "       16.65       0.80      0.87      0.83        23\n",
            "       16.88       0.95      0.91      0.93        66\n",
            "       17.11       0.95      0.95      0.95       113\n",
            "       17.34       0.96      0.98      0.97       136\n",
            "       17.57       0.92      0.93      0.92       180\n",
            "        17.8       0.89      0.90      0.89       165\n",
            "       18.03       0.89      0.85      0.87       176\n",
            "       18.08       0.87      0.87      0.87       274\n",
            "       18.26       0.92      0.92      0.92       256\n",
            "       18.49       0.94      0.96      0.95       250\n",
            "       18.72       0.97      0.98      0.98       681\n",
            "       18.92       0.97      0.96      0.96       542\n",
            "       19.18       0.94      0.92      0.93       145\n",
            "       19.44       0.99      1.00      0.99       339\n",
            "        19.7       0.99      0.98      0.99       437\n",
            "       19.96       0.99      0.98      0.99       364\n",
            "       20.22       1.00      1.00      1.00       566\n",
            "       20.48       0.00      0.00      0.00         2\n",
            "       20.74       0.98      0.99      0.99       279\n",
            "        21.0       0.98      1.00      0.99       456\n",
            "       21.26       0.96      0.95      0.95       385\n",
            "       21.52       0.94      0.94      0.94       759\n",
            "       21.78       0.91      0.92      0.92       608\n",
            "       22.04       0.95      0.92      0.94       564\n",
            "        22.3       0.90      0.92      0.91       525\n",
            "       22.52       0.99      0.97      0.98       526\n",
            "       22.63       0.93      0.94      0.93       162\n",
            "       22.74       0.88      0.94      0.91        52\n",
            "       22.85       0.85      0.97      0.90        58\n",
            "       22.96       0.78      0.41      0.54        17\n",
            "       23.18       0.88      1.00      0.93         7\n",
            "        23.4       0.87      0.95      0.91        21\n",
            "       23.93       0.90      0.60      0.72        15\n",
            "       23.95       0.86      0.67      0.75        18\n",
            "       24.09       0.68      0.77      0.72        39\n",
            "       24.35       0.88      0.66      0.75        32\n",
            "        24.6       0.78      0.91      0.84        65\n",
            "       24.85       1.00      1.00      1.00        15\n",
            "        25.1       1.00      0.71      0.83         7\n",
            "        25.6       0.92      0.79      0.85        14\n",
            "       25.85       0.87      0.82      0.84        33\n",
            "        28.8       0.67      0.50      0.57         4\n",
            "       29.07       1.00      1.00      1.00         2\n",
            "       29.34       1.00      0.75      0.86         4\n",
            "       29.61       0.92      0.92      0.92        12\n",
            "       29.87       0.75      1.00      0.86         6\n",
            "       31.23       1.00      0.67      0.80         3\n",
            "       31.45       0.00      0.00      0.00         0\n",
            "       31.57       1.00      1.00      1.00         1\n",
            "       31.69       0.00      0.00      0.00         0\n",
            "       31.82       0.00      0.00      0.00         1\n",
            "       31.93       1.00      1.00      1.00         1\n",
            "       33.31       1.00      1.00      1.00         6\n",
            "       33.38       1.00      1.00      1.00        34\n",
            "       33.45       1.00      1.00      1.00         3\n",
            "        7.11       0.98      0.97      0.98       613\n",
            "         7.5       0.97      0.98      0.97       602\n",
            "        7.89       0.99      0.98      0.99       237\n",
            "        8.28       0.94      0.96      0.95       224\n",
            "        8.67       0.97      0.97      0.97       489\n",
            "        9.06       0.97      0.97      0.97       273\n",
            "        9.45       0.98      0.98      0.98       174\n",
            "\n",
            "    accuracy                           0.95     16625\n",
            "   macro avg       0.88      0.86      0.86     16625\n",
            "weighted avg       0.95      0.95      0.95     16625\n",
            "\n",
            "The confusion matrix for Fish Length is: [[176   4   0 ...   0   0   0]\n",
            " [  1 751  16 ...   0   0   0]\n",
            " [  0  23 404 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ... 472   6   0]\n",
            " [  0   0   0 ...   5 265   3]\n",
            " [  0   0   0 ...   0   3 171]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "      101.57       0.91      1.00      0.95        21\n",
            "       11.37       0.99      0.97      0.98       180\n",
            "       12.31       0.96      0.98      0.97       770\n",
            "      121.17       0.87      0.72      0.79        18\n",
            "       125.2       0.74      0.79      0.77        39\n",
            "      128.55       0.92      0.69      0.79        32\n",
            "       13.25       0.91      0.88      0.90       454\n",
            "       131.9       0.79      0.94      0.86        65\n",
            "      135.25       1.00      1.00      1.00        15\n",
            "       138.6       1.00      0.71      0.83         7\n",
            "       14.19       0.93      0.94      0.93       811\n",
            "       145.3       1.00      0.86      0.92        14\n",
            "      148.65       0.84      0.82      0.83        33\n",
            "       15.13       0.96      0.95      0.96       631\n",
            "       152.0       0.80      0.85      0.83        39\n",
            "      198.42       0.33      0.25      0.29         4\n",
            "        2.91       0.98      0.97      0.97       613\n",
            "       205.0       1.00      1.00      1.00         2\n",
            "      211.58       1.00      0.75      0.86         4\n",
            "      218.16       0.83      0.83      0.83        12\n",
            "      224.74       0.75      1.00      0.86         6\n",
            "       23.73       0.98      0.98      0.98       121\n",
            "       24.82       0.91      0.94      0.92       271\n",
            "       25.91       0.92      0.92      0.92       197\n",
            "      257.64       1.00      0.67      0.80         3\n",
            "       26.97       0.90      0.93      0.91       314\n",
            "       264.2       0.00      0.00      0.00         0\n",
            "      267.39       1.00      1.00      1.00         1\n",
            "      270.58       0.00      0.00      0.00         0\n",
            "      273.77       0.00      0.00      0.00         1\n",
            "      276.96       1.00      1.00      1.00         1\n",
            "       28.03       0.87      0.85      0.86       274\n",
            "       29.12       0.83      0.73      0.78       137\n",
            "        3.85       0.97      0.98      0.97       602\n",
            "       30.21       0.94      0.90      0.92        49\n",
            "        31.4       0.93      0.94      0.93       202\n",
            "      313.72       1.00      1.00      1.00         6\n",
            "      316.18       1.00      1.00      1.00        34\n",
            "      318.64       1.00      1.00      1.00         3\n",
            "       33.73       0.84      0.87      0.86       150\n",
            "       36.06       0.84      0.82      0.83       163\n",
            "       38.39       0.93      0.91      0.92        75\n",
            "        4.79       0.99      1.00      0.99       237\n",
            "       40.72       0.83      0.87      0.85        23\n",
            "       43.05       0.95      0.89      0.92        66\n",
            "       43.38       0.94      0.96      0.95       113\n",
            "       47.71       0.96      0.97      0.97       136\n",
            "        5.73       0.95      0.96      0.96       224\n",
            "       50.04       0.91      0.92      0.92       180\n",
            "       52.37       0.86      0.91      0.88       165\n",
            "        54.7       0.89      0.84      0.87       176\n",
            "       57.03       0.92      0.91      0.92       256\n",
            "       59.36       0.95      0.95      0.95       250\n",
            "        6.67       0.98      0.97      0.97       489\n",
            "       61.69       0.98      0.98      0.98       681\n",
            "        64.0       0.97      0.96      0.96       542\n",
            "       64.44       0.94      0.93      0.94       145\n",
            "       64.88       0.99      1.00      0.99       339\n",
            "       65.32       0.99      0.98      0.99       437\n",
            "       65.76       0.99      0.98      0.99       364\n",
            "        66.2       1.00      1.00      1.00       566\n",
            "       66.64       0.00      0.00      0.00         2\n",
            "       67.08       0.98      0.99      0.98       279\n",
            "       67.52       0.97      0.99      0.98       456\n",
            "       67.96       0.97      0.94      0.95       385\n",
            "        68.4       0.94      0.94      0.94       759\n",
            "       68.84       0.92      0.92      0.92       608\n",
            "       69.28       0.96      0.92      0.94       564\n",
            "       69.72       0.90      0.94      0.92       525\n",
            "        7.61       0.97      0.97      0.97       273\n",
            "        70.2       0.99      0.97      0.98       526\n",
            "       74.13       0.94      0.94      0.94       162\n",
            "       78.05       0.88      0.94      0.91        52\n",
            "        8.55       0.98      0.98      0.98       174\n",
            "       81.97       0.82      0.97      0.89        58\n",
            "       85.89       0.86      0.35      0.50        17\n",
            "       93.75       0.88      1.00      0.93         7\n",
            "       97.65       1.00      0.67      0.80        15\n",
            "\n",
            "    accuracy                           0.95     16625\n",
            "   macro avg       0.88      0.86      0.86     16625\n",
            "weighted avg       0.95      0.95      0.95     16625\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[ 21   0   0 ...   0   0   0]\n",
            " [  0 175   5 ...   0   0   0]\n",
            " [  0   1 753 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ...   6   0   0]\n",
            " [  0   0   0 ...   0   7   0]\n",
            " [  2   0   0 ...   0   1  10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8) Gradient Boosting Classifier"
      ],
      "metadata": {
        "id": "cig-bnhWpFFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=GradientBoostingClassifier()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "id": "2WyqS3qVXhnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a57893d9-f2a1-4c0a-fce8-4dc5f4e52c07"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.62       0.99      0.98      0.99       180\n",
            "       11.01       0.97      0.97      0.97       770\n",
            "        11.4       0.89      0.89      0.89       454\n",
            "       11.79       0.92      0.92      0.92       811\n",
            "       12.09       0.00      0.00      0.00        39\n",
            "       12.18       0.95      0.95      0.95       631\n",
            "       14.16       0.97      0.97      0.97       121\n",
            "       14.39       0.90      0.92      0.91       271\n",
            "       14.62       0.93      0.92      0.92       197\n",
            "       14.85       0.89      0.76      0.82       314\n",
            "       15.31       0.79      0.71      0.75       137\n",
            "       15.54       0.88      0.94      0.91        49\n",
            "       15.73       0.89      0.63      0.74       202\n",
            "       15.96       0.79      0.84      0.81       150\n",
            "       16.19       0.70      0.76      0.73       163\n",
            "       16.42       0.67      0.13      0.22        75\n",
            "       16.65       0.70      0.83      0.76        23\n",
            "       16.88       0.89      0.88      0.89        66\n",
            "       17.11       0.95      0.92      0.93       113\n",
            "       17.34       0.95      0.95      0.95       136\n",
            "       17.57       0.89      0.93      0.91       180\n",
            "        17.8       0.85      0.85      0.85       165\n",
            "       18.03       0.83      0.60      0.70       176\n",
            "       18.08       0.85      0.87      0.86       274\n",
            "       18.26       0.44      0.89      0.59       256\n",
            "       18.49       0.95      0.96      0.95       250\n",
            "       18.72       0.98      0.98      0.98       681\n",
            "       18.92       0.96      0.97      0.97       542\n",
            "       19.18       0.97      0.91      0.94       145\n",
            "       19.44       0.98      0.99      0.98       339\n",
            "        19.7       0.42      0.96      0.59       437\n",
            "       19.96       0.98      0.97      0.98       364\n",
            "       20.22       1.00      1.00      1.00       566\n",
            "       20.48       0.00      0.00      0.00         2\n",
            "       20.74       0.98      0.98      0.98       279\n",
            "        21.0       0.97      0.99      0.98       456\n",
            "       21.26       0.95      0.91      0.93       385\n",
            "       21.52       0.89      0.72      0.80       759\n",
            "       21.78       0.88      0.43      0.58       608\n",
            "       22.04       0.53      0.28      0.37       564\n",
            "        22.3       0.38      0.46      0.42       525\n",
            "       22.52       0.94      0.92      0.93       526\n",
            "       22.63       0.87      0.77      0.82       162\n",
            "       22.74       0.79      0.52      0.63        52\n",
            "       22.85       0.65      0.22      0.33        58\n",
            "       22.96       0.17      0.29      0.21        17\n",
            "       23.18       0.50      1.00      0.67         7\n",
            "        23.4       0.86      0.57      0.69        21\n",
            "       23.93       0.03      0.13      0.05        15\n",
            "       23.95       0.00      0.00      0.00        18\n",
            "       24.09       0.40      0.21      0.27        39\n",
            "       24.35       0.38      0.34      0.36        32\n",
            "        24.6       0.00      0.00      0.00        65\n",
            "       24.85       0.10      0.67      0.17        15\n",
            "        25.1       0.05      0.86      0.09         7\n",
            "        25.6       0.00      0.00      0.00        14\n",
            "       25.85       0.00      0.00      0.00        33\n",
            "        28.8       0.00      0.00      0.00         4\n",
            "       29.07       0.00      0.00      0.00         2\n",
            "       29.34       0.00      0.00      0.00         4\n",
            "       29.61       0.00      0.00      0.00        12\n",
            "       29.87       0.00      0.00      0.00         6\n",
            "       31.23       0.00      0.00      0.00         3\n",
            "       31.57       0.00      0.00      0.00         1\n",
            "       31.82       0.00      0.00      0.00         1\n",
            "       31.93       0.00      0.00      0.00         1\n",
            "       33.31       0.00      0.00      0.00         6\n",
            "       33.38       0.00      0.00      0.00        34\n",
            "       33.45       0.00      0.00      0.00         3\n",
            "        7.11       0.98      0.98      0.98       613\n",
            "         7.5       0.98      0.98      0.98       602\n",
            "        7.89       0.99      0.97      0.98       237\n",
            "        8.28       0.96      0.94      0.95       224\n",
            "        8.67       0.97      0.98      0.97       489\n",
            "        9.06       0.95      0.95      0.95       273\n",
            "        9.45       0.97      0.94      0.96       174\n",
            "\n",
            "    accuracy                           0.84     16625\n",
            "   macro avg       0.60      0.60      0.58     16625\n",
            "weighted avg       0.86      0.84      0.84     16625\n",
            "\n",
            "The confusion matrix for Fish Length is: [[177   2   0 ...   0   0   1]\n",
            " [  1 750  17 ...   0   0   0]\n",
            " [  0  19 404 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ... 479   4   0]\n",
            " [  0   0   0 ...   4 258   4]\n",
            " [  0   0   0 ...   0  10 164]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "      101.57       0.86      0.57      0.69        21\n",
            "       11.37       0.99      0.98      0.99       180\n",
            "       12.31       0.97      0.97      0.97       770\n",
            "      121.17       0.00      0.00      0.00        18\n",
            "       125.2       0.40      0.21      0.27        39\n",
            "      128.55       0.38      0.34      0.36        32\n",
            "       13.25       0.89      0.89      0.89       454\n",
            "       131.9       0.00      0.00      0.00        65\n",
            "      135.25       0.10      0.67      0.17        15\n",
            "       138.6       0.05      0.86      0.09         7\n",
            "       14.19       0.92      0.92      0.92       811\n",
            "       145.3       0.00      0.00      0.00        14\n",
            "      148.65       0.00      0.00      0.00        33\n",
            "       15.13       0.95      0.95      0.95       631\n",
            "       152.0       0.00      0.00      0.00        39\n",
            "      198.42       0.00      0.00      0.00         4\n",
            "        2.91       0.98      0.98      0.98       613\n",
            "       205.0       0.00      0.00      0.00         2\n",
            "      211.58       0.00      0.00      0.00         4\n",
            "      218.16       0.00      0.00      0.00        12\n",
            "      224.74       0.00      0.00      0.00         6\n",
            "       23.73       0.97      0.97      0.97       121\n",
            "       24.82       0.90      0.92      0.91       271\n",
            "       25.91       0.93      0.92      0.92       197\n",
            "      257.64       0.00      0.00      0.00         3\n",
            "       26.97       0.89      0.76      0.82       314\n",
            "      267.39       0.00      0.00      0.00         1\n",
            "      273.77       0.00      0.00      0.00         1\n",
            "      276.96       0.00      0.00      0.00         1\n",
            "       28.03       0.85      0.87      0.86       274\n",
            "       29.12       0.79      0.71      0.75       137\n",
            "        3.85       0.98      0.98      0.98       602\n",
            "       30.21       0.88      0.94      0.91        49\n",
            "        31.4       0.89      0.63      0.74       202\n",
            "      313.72       0.00      0.00      0.00         6\n",
            "      316.18       0.00      0.00      0.00        34\n",
            "      318.64       0.00      0.00      0.00         3\n",
            "       33.73       0.79      0.84      0.81       150\n",
            "       36.06       0.70      0.76      0.73       163\n",
            "       38.39       0.67      0.13      0.22        75\n",
            "        4.79       0.99      0.97      0.98       237\n",
            "       40.72       0.70      0.83      0.76        23\n",
            "       43.05       0.89      0.88      0.89        66\n",
            "       43.38       0.95      0.92      0.93       113\n",
            "       47.71       0.95      0.95      0.95       136\n",
            "        5.73       0.96      0.94      0.95       224\n",
            "       50.04       0.89      0.93      0.91       180\n",
            "       52.37       0.85      0.85      0.85       165\n",
            "        54.7       0.83      0.60      0.70       176\n",
            "       57.03       0.44      0.89      0.59       256\n",
            "       59.36       0.95      0.96      0.95       250\n",
            "        6.67       0.97      0.98      0.97       489\n",
            "       61.69       0.98      0.98      0.98       681\n",
            "        64.0       0.96      0.97      0.97       542\n",
            "       64.44       0.97      0.91      0.94       145\n",
            "       64.88       0.98      0.99      0.98       339\n",
            "       65.32       0.42      0.96      0.59       437\n",
            "       65.76       0.98      0.97      0.98       364\n",
            "        66.2       1.00      1.00      1.00       566\n",
            "       66.64       0.00      0.00      0.00         2\n",
            "       67.08       0.98      0.98      0.98       279\n",
            "       67.52       0.97      0.99      0.98       456\n",
            "       67.96       0.95      0.91      0.93       385\n",
            "        68.4       0.89      0.72      0.80       759\n",
            "       68.84       0.88      0.43      0.58       608\n",
            "       69.28       0.53      0.28      0.37       564\n",
            "       69.72       0.38      0.46      0.42       525\n",
            "        7.61       0.95      0.95      0.95       273\n",
            "        70.2       0.94      0.92      0.93       526\n",
            "       74.13       0.87      0.77      0.82       162\n",
            "       78.05       0.79      0.52      0.63        52\n",
            "        8.55       0.97      0.94      0.96       174\n",
            "       81.97       0.65      0.22      0.33        58\n",
            "       85.89       0.17      0.29      0.21        17\n",
            "       93.75       0.50      1.00      0.67         7\n",
            "       97.65       0.03      0.13      0.05        15\n",
            "\n",
            "    accuracy                           0.84     16625\n",
            "   macro avg       0.60      0.60      0.58     16625\n",
            "weighted avg       0.86      0.84      0.84     16625\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[ 12   0   0 ...   1   4   3]\n",
            " [  0 177   2 ...   0   0   0]\n",
            " [  0   1 750 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ...   5   1   4]\n",
            " [  0   0   0 ...   0   7   0]\n",
            " [  2   0   0 ...   0   2   2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9) Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "D1uQTNCCpICD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=MultinomialNB()\n",
        "data=model.fit(X_train,Y1_train)\n",
        "Y1_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Length is:\",classification_report(Y1_test,Y1_predict))\n",
        "print(\"The confusion matrix for Fish Length is:\",confusion_matrix(Y1_test,Y1_predict))\n",
        "data=model.fit(X_train,Y2_train)\n",
        "Y2_predict=data.predict(X_test)\n",
        "print(\"The classification report for Fish Weight is:\",classification_report(Y2_test,Y2_predict))\n",
        "print(\"The confusion matrix for Fish Weight is:\",confusion_matrix(Y2_test,Y2_predict))"
      ],
      "metadata": {
        "id": "OYF5Dtg1Xx2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4429cfca-e1d5-4ba6-8586-e124c944ea1d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Length is:               precision    recall  f1-score   support\n",
            "\n",
            "       10.62       0.00      0.00      0.00       180\n",
            "       11.01       0.13      0.56      0.22       770\n",
            "        11.4       0.00      0.00      0.00       454\n",
            "       11.79       0.10      0.67      0.17       811\n",
            "       12.09       0.00      0.00      0.00        39\n",
            "       12.18       0.00      0.00      0.00       631\n",
            "       14.16       0.00      0.00      0.00       121\n",
            "       14.39       0.00      0.00      0.00       271\n",
            "       14.62       0.00      0.00      0.00       197\n",
            "       14.85       0.00      0.00      0.00       314\n",
            "       15.31       0.00      0.00      0.00       137\n",
            "       15.54       0.00      0.00      0.00        49\n",
            "       15.73       0.00      0.00      0.00       202\n",
            "       15.96       0.00      0.00      0.00       150\n",
            "       16.19       0.00      0.00      0.00       163\n",
            "       16.42       0.00      0.00      0.00        75\n",
            "       16.65       0.00      0.00      0.00        23\n",
            "       16.88       0.00      0.00      0.00        66\n",
            "       17.11       0.00      0.00      0.00       113\n",
            "       17.34       0.00      0.00      0.00       136\n",
            "       17.57       0.00      0.00      0.00       180\n",
            "        17.8       0.00      0.00      0.00       165\n",
            "       18.03       0.00      0.00      0.00       176\n",
            "       18.08       0.00      0.00      0.00       274\n",
            "       18.26       0.00      0.00      0.00       256\n",
            "       18.49       0.00      0.00      0.00       250\n",
            "       18.72       0.46      1.00      0.63       681\n",
            "       18.92       0.00      0.00      0.00       542\n",
            "       19.18       0.00      0.00      0.00       145\n",
            "       19.44       0.00      0.00      0.00       339\n",
            "        19.7       0.46      0.20      0.28       437\n",
            "       19.96       0.00      0.00      0.00       364\n",
            "       20.22       0.28      0.46      0.35       566\n",
            "       20.48       0.00      0.00      0.00         2\n",
            "       20.74       0.00      0.00      0.00       279\n",
            "        21.0       0.00      0.00      0.00       456\n",
            "       21.26       0.00      0.00      0.00       385\n",
            "       21.52       0.14      1.00      0.25       759\n",
            "       21.78       0.00      0.00      0.00       608\n",
            "       22.04       0.00      0.00      0.00       564\n",
            "        22.3       0.00      0.00      0.00       525\n",
            "       22.52       0.00      0.00      0.00       526\n",
            "       22.63       0.00      0.00      0.00       162\n",
            "       22.74       0.00      0.00      0.00        52\n",
            "       22.85       0.00      0.00      0.00        58\n",
            "       22.96       0.00      0.00      0.00        17\n",
            "       23.18       0.00      0.00      0.00         7\n",
            "        23.4       0.00      0.00      0.00        21\n",
            "       23.93       0.00      0.00      0.00        15\n",
            "       23.95       0.00      0.00      0.00        18\n",
            "       24.09       0.00      0.00      0.00        39\n",
            "       24.35       0.00      0.00      0.00        32\n",
            "        24.6       0.00      0.00      0.00        65\n",
            "       24.85       0.00      0.00      0.00        15\n",
            "        25.1       0.00      0.00      0.00         7\n",
            "        25.6       0.00      0.00      0.00        14\n",
            "       25.85       0.00      0.00      0.00        33\n",
            "        28.8       0.00      0.00      0.00         4\n",
            "       29.07       0.00      0.00      0.00         2\n",
            "       29.34       0.00      0.00      0.00         4\n",
            "       29.61       0.00      0.00      0.00        12\n",
            "       29.87       0.00      0.00      0.00         6\n",
            "       31.23       0.00      0.00      0.00         3\n",
            "       31.57       0.00      0.00      0.00         1\n",
            "       31.82       0.00      0.00      0.00         1\n",
            "       31.93       0.00      0.00      0.00         1\n",
            "       33.31       0.00      0.00      0.00         6\n",
            "       33.38       0.00      0.00      0.00        34\n",
            "       33.45       0.00      0.00      0.00         3\n",
            "        7.11       0.00      0.00      0.00       613\n",
            "         7.5       0.00      0.00      0.00       602\n",
            "        7.89       0.00      0.00      0.00       237\n",
            "        8.28       0.00      0.00      0.00       224\n",
            "        8.67       0.00      0.00      0.00       489\n",
            "        9.06       0.00      0.00      0.00       273\n",
            "        9.45       0.00      0.00      0.00       174\n",
            "\n",
            "    accuracy                           0.17     16625\n",
            "   macro avg       0.02      0.05      0.02     16625\n",
            "weighted avg       0.06      0.17      0.07     16625\n",
            "\n",
            "The confusion matrix for Fish Length is: [[  0  13   0 ...   0   0   0]\n",
            " [  0 428   0 ...   0   0   0]\n",
            " [  0 164   0 ...   0   0   0]\n",
            " ...\n",
            " [  0 242   0 ...   0   0   0]\n",
            " [  0  69   0 ...   0   0   0]\n",
            " [  0  94   0 ...   0   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The classification report for Fish Weight is:               precision    recall  f1-score   support\n",
            "\n",
            "      101.57       0.00      0.00      0.00        21\n",
            "       11.37       0.00      0.00      0.00       180\n",
            "       12.31       0.13      0.56      0.22       770\n",
            "      121.17       0.00      0.00      0.00        18\n",
            "       125.2       0.00      0.00      0.00        39\n",
            "      128.55       0.00      0.00      0.00        32\n",
            "       13.25       0.00      0.00      0.00       454\n",
            "       131.9       0.00      0.00      0.00        65\n",
            "      135.25       0.00      0.00      0.00        15\n",
            "       138.6       0.00      0.00      0.00         7\n",
            "       14.19       0.10      0.67      0.17       811\n",
            "       145.3       0.00      0.00      0.00        14\n",
            "      148.65       0.00      0.00      0.00        33\n",
            "       15.13       0.00      0.00      0.00       631\n",
            "       152.0       0.00      0.00      0.00        39\n",
            "      198.42       0.00      0.00      0.00         4\n",
            "        2.91       0.00      0.00      0.00       613\n",
            "       205.0       0.00      0.00      0.00         2\n",
            "      211.58       0.00      0.00      0.00         4\n",
            "      218.16       0.00      0.00      0.00        12\n",
            "      224.74       0.00      0.00      0.00         6\n",
            "       23.73       0.00      0.00      0.00       121\n",
            "       24.82       0.00      0.00      0.00       271\n",
            "       25.91       0.00      0.00      0.00       197\n",
            "      257.64       0.00      0.00      0.00         3\n",
            "       26.97       0.00      0.00      0.00       314\n",
            "      267.39       0.00      0.00      0.00         1\n",
            "      273.77       0.00      0.00      0.00         1\n",
            "      276.96       0.00      0.00      0.00         1\n",
            "       28.03       0.00      0.00      0.00       274\n",
            "       29.12       0.00      0.00      0.00       137\n",
            "        3.85       0.00      0.00      0.00       602\n",
            "       30.21       0.00      0.00      0.00        49\n",
            "        31.4       0.00      0.00      0.00       202\n",
            "      313.72       0.00      0.00      0.00         6\n",
            "      316.18       0.00      0.00      0.00        34\n",
            "      318.64       0.00      0.00      0.00         3\n",
            "       33.73       0.00      0.00      0.00       150\n",
            "       36.06       0.00      0.00      0.00       163\n",
            "       38.39       0.00      0.00      0.00        75\n",
            "        4.79       0.00      0.00      0.00       237\n",
            "       40.72       0.00      0.00      0.00        23\n",
            "       43.05       0.00      0.00      0.00        66\n",
            "       43.38       0.00      0.00      0.00       113\n",
            "       47.71       0.00      0.00      0.00       136\n",
            "        5.73       0.00      0.00      0.00       224\n",
            "       50.04       0.00      0.00      0.00       180\n",
            "       52.37       0.00      0.00      0.00       165\n",
            "        54.7       0.00      0.00      0.00       176\n",
            "       57.03       0.00      0.00      0.00       256\n",
            "       59.36       0.00      0.00      0.00       250\n",
            "        6.67       0.00      0.00      0.00       489\n",
            "       61.69       0.46      1.00      0.63       681\n",
            "        64.0       0.00      0.00      0.00       542\n",
            "       64.44       0.00      0.00      0.00       145\n",
            "       64.88       0.00      0.00      0.00       339\n",
            "       65.32       0.46      0.20      0.28       437\n",
            "       65.76       0.00      0.00      0.00       364\n",
            "        66.2       0.28      0.46      0.35       566\n",
            "       66.64       0.00      0.00      0.00         2\n",
            "       67.08       0.00      0.00      0.00       279\n",
            "       67.52       0.00      0.00      0.00       456\n",
            "       67.96       0.00      0.00      0.00       385\n",
            "        68.4       0.14      1.00      0.25       759\n",
            "       68.84       0.00      0.00      0.00       608\n",
            "       69.28       0.00      0.00      0.00       564\n",
            "       69.72       0.00      0.00      0.00       525\n",
            "        7.61       0.00      0.00      0.00       273\n",
            "        70.2       0.00      0.00      0.00       526\n",
            "       74.13       0.00      0.00      0.00       162\n",
            "       78.05       0.00      0.00      0.00        52\n",
            "        8.55       0.00      0.00      0.00       174\n",
            "       81.97       0.00      0.00      0.00        58\n",
            "       85.89       0.00      0.00      0.00        17\n",
            "       93.75       0.00      0.00      0.00         7\n",
            "       97.65       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.17     16625\n",
            "   macro avg       0.02      0.05      0.02     16625\n",
            "weighted avg       0.06      0.17      0.07     16625\n",
            "\n",
            "The confusion matrix for Fish Weight is: [[  0   0   0 ...   0   0   0]\n",
            " [  0   0  13 ...   0   0   0]\n",
            " [  0   0 428 ...   0   0   0]\n",
            " ...\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}